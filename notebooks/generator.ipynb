{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lacykaltgr/continual-learning-ait/blob/main/notebooks/generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-05-14 11:58:58--  https://github.com/lacykaltgr/continual-learning-ait/archive/refs/heads/experiment.zip\n",
            "Resolving github.com (github.com)... 20.27.177.113\n",
            "Connecting to github.com (github.com)|20.27.177.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://codeload.github.com/lacykaltgr/continual-learning-ait/zip/refs/heads/experiment [following]\n",
            "--2023-05-14 11:58:58--  https://codeload.github.com/lacykaltgr/continual-learning-ait/zip/refs/heads/experiment\n",
            "Resolving codeload.github.com (codeload.github.com)... 20.27.177.114\n",
            "Connecting to codeload.github.com (codeload.github.com)|20.27.177.114|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘experiment.zip’\n",
            "\n",
            "experiment.zip          [  <=>               ]   1.58M  4.51MB/s    in 0.4s    \n",
            "\n",
            "2023-05-14 11:58:59 (4.51 MB/s) - ‘experiment.zip’ saved [1659988]\n",
            "\n",
            "Archive:  experiment.zip\n",
            "14284730675b047d64453bf87dfeefdb10cc020d\n",
            "   creating: continual-learning-ait-experiment/\n",
            "  inflating: continual-learning-ait-experiment/README.md  \n",
            "  inflating: continual-learning-ait-experiment/classifier.py  \n",
            "  inflating: continual-learning-ait-experiment/constants.py  \n",
            "  inflating: continual-learning-ait-experiment/data_preparation.py  \n",
            "  inflating: continual-learning-ait-experiment/generator.py  \n",
            "  inflating: continual-learning-ait-experiment/img.png  \n",
            "  inflating: continual-learning-ait-experiment/main.ipynb  \n",
            "   creating: continual-learning-ait-experiment/models/\n",
            "  inflating: continual-learning-ait-experiment/models/classifier.h5  \n",
            "  inflating: continual-learning-ait-experiment/models/encoder.h5  \n",
            "   creating: continual-learning-ait-experiment/notebooks/\n",
            "  inflating: continual-learning-ait-experiment/notebooks/classifier.ipynb  \n",
            "  inflating: continual-learning-ait-experiment/notebooks/data_preparation.ipynb  \n",
            "  inflating: continual-learning-ait-experiment/notebooks/generator.ipynb  \n",
            "  inflating: continual-learning-ait-experiment/utils.py  \n",
            "rm: cannot remove 'models': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "'''Download the files '''\n",
        "'''Only for colab'''\n",
        "\n",
        "!wget https://github.com/lacykaltgr/continual-learning-ait/archive/refs/heads/experiment.zip\n",
        "!unzip experiment.zip\n",
        "!find continual-learning-ait-experiment -type f ! -name \"main.ipynb\" -exec cp {} . \\;\n",
        "\n",
        "!rm -r models\n",
        "!mkdir models"
      ],
      "metadata": {
        "id": "FBqbqiHlwppa",
        "outputId": "b9f99420-979a-4454-af18-43351bf559ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import numpy as np\n",
        "from keras.layers import Conv2D, Conv2DTranspose\n",
        "import math\n",
        "from constants import _ALPHAS_CUMPROD"
      ],
      "metadata": {
        "id": "qxtHOYA5wppb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "outputs": [],
      "source": [
        "def load_cifar_10():\n",
        "    (X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "    n_classes = 10\n",
        "    X_train = (X_train / 127.5) -1\n",
        "    X_test = (X_test / 127.5) -1\n",
        "    y_train = tf.keras.utils.to_categorical(y_train, n_classes)\n",
        "    y_test = tf.keras.utils.to_categorical(y_test, n_classes)\n",
        "    return (X_train, y_train), (X_test, y_test)"
      ],
      "metadata": {
        "id": "9cDXrVOHwppb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "collapsed": true,
        "id": "0MPVDCr_wppc",
        "outputId": "80d185d5-89a3-47e3-9100-d4ec67b3b041",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "encoder = load_model(\"encoder.h5\")\n",
        "classifier = load_model(\"classifier.h5\")\n",
        "\n",
        "encoder.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=5e-3),\n",
        "    loss=keras.losses.CategoricalCrossentropy(),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "classifier.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=5e-3),\n",
        "    loss=keras.losses.CategoricalCrossentropy(),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "input = keras.Input(shape=(32,32,3))\n",
        "enc = encoder(input)\n",
        "cls = classifier(enc)\n",
        "encoder_classifier = keras.Model(inputs=[input], outputs=[cls])\n",
        "\n",
        "encoder_classifier.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=5e-3),\n",
        "    loss=keras.losses.CategoricalCrossentropy(),\n",
        "    metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "outputs": [],
      "source": [
        "def apply_seq(x: object, layers: object) -> object:\n",
        "    for l in layers:\n",
        "        x = l(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "kBhHGv9jK6bb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "outputs": [],
      "source": [
        "class ResBlock(keras.layers.Layer):\n",
        "    def __init__(self, channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.in_layers = [\n",
        "            keras.layers.GroupNormalization(epsilon=1e-5),\n",
        "            keras.activations.swish,\n",
        "            Conv2D(out_channels, 3, strides=(1, 1), padding='same'),\n",
        "        ]\n",
        "        self.emb_layers = [\n",
        "            keras.activations.swish,\n",
        "            keras.layers.Dense(out_channels),\n",
        "        ]\n",
        "        self.out_layers = [\n",
        "            keras.layers.GroupNormalization(epsilon=1e-5),\n",
        "            keras.activations.swish,\n",
        "            Conv2D(out_channels, 3, strides=(1, 1), padding='same'),\n",
        "        ]\n",
        "        self.skip_connection = Conv2D(out_channels, 3, strides=(1, 1), padding='same') if channels != out_channels else lambda x: x\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x, emb = inputs\n",
        "        h = apply_seq(x, self.in_layers)\n",
        "        emb_out = apply_seq(emb, self.emb_layers)\n",
        "        h = h + emb_out[:, None, None]\n",
        "        h = apply_seq(h, self.out_layers)\n",
        "        skip_x = self.skip_connection(x)\n",
        "        ret = skip_x + h\n",
        "        return ret"
      ],
      "metadata": {
        "id": "4Z_JKL-kK6bc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "outputs": [],
      "source": [
        "class UNetModel(keras.Model):\n",
        "    def __init__(self):\n",
        "        print(\"UNetModel init\")\n",
        "        super().__init__()\n",
        "        self.img_height = 32\n",
        "        self.img_width = 32\n",
        "        self.ntype = tf.float32\n",
        "        self.time_embed = [\n",
        "            keras.layers.Dense(128),\n",
        "            keras.activations.swish,\n",
        "            keras.layers.Dense(128),\n",
        "        ]\n",
        "        self.input_blocks = [\n",
        "            Conv2D( 32, 3, strides=(1, 1), padding='same'),\n",
        "\n",
        "            ResBlock(32, 32),\n",
        "            ResBlock(32, 32),\n",
        "            Conv2D(64, 3, strides=(2, 2), padding='same'), #downsample\n",
        "\n",
        "            ResBlock(32, 64), \n",
        "            ResBlock(64, 64), \n",
        "            Conv2D(128, 3, strides=(2, 2), padding='same'), #downsample\n",
        "\n",
        "            ResBlock(64, 128),\n",
        "            ResBlock(128, 128),\n",
        "            Conv2D(128, 3, strides=(2, 2), padding='same'), #downsample\n",
        "\n",
        "            ResBlock(128, 128),\n",
        "            ResBlock(128, 128),\n",
        "        ]\n",
        "        self.middle_block = [\n",
        "            ResBlock(256, 128),\n",
        "            ResBlock(256, 128),\n",
        "        ]\n",
        "        self.output_blocks = [\n",
        "            [ResBlock(256, 128)],\n",
        "            [ResBlock(256, 128)],\n",
        "\n",
        "            [\n",
        "                ResBlock(256, 128),\n",
        "                Conv2DTranspose(128, 2, strides=(2,2)),\n",
        "                Conv2D(128, 3, strides=(1,1), padding='same')\n",
        "            ],\n",
        "            [ResBlock(256, 128)], \n",
        "            [ResBlock(256, 128)],\n",
        "\n",
        "            [\n",
        "                ResBlock(192, 128),\n",
        "                Conv2DTranspose(128, 2, strides=(2,2)),\n",
        "                Conv2D(64, 2, strides=(1,1), padding='same')\n",
        "            ],\n",
        "            [ResBlock(192, 64)], \n",
        "            [ResBlock(128, 64)], \n",
        "\n",
        "            [\n",
        "                ResBlock(96, 64),\n",
        "                Conv2DTranspose(64, 3, strides=(2,2)),\n",
        "                Conv2D(64, 2, strides=(1,1), padding='valid')\n",
        "            ],\n",
        "            [ResBlock(96, 32)], \n",
        "            [ResBlock(64, 32)],\n",
        "\n",
        "            [ResBlock(64, 32)],\n",
        "        ]\n",
        "        self.out = [\n",
        "            keras.layers.GroupNormalization(epsilon=1e-5),\n",
        "            keras.activations.swish,\n",
        "            Conv2D(3, 3, strides=(1,1), padding='same'),\n",
        "        ]\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x, t_emb = inputs\n",
        "        emb = apply_seq(t_emb, self.time_embed)\n",
        "\n",
        "        def apply(x, layer):\n",
        "            return layer([x, emb]) if isinstance(layer, ResBlock) else layer(x)\n",
        "\n",
        "        saved_inputs = []\n",
        "        for layer in self.input_blocks:\n",
        "            x = apply(x, layer)\n",
        "            saved_inputs.append(x)\n",
        "\n",
        "        for layer in self.middle_block:\n",
        "            x = apply(x, layer)\n",
        "\n",
        "        for b in self.output_blocks:\n",
        "            skip = saved_inputs.pop()\n",
        "            x = tf.concat([x, skip], axis=-1)\n",
        "            for layer in b:\n",
        "                x = apply(x, layer)\n",
        "\n",
        "        return apply_seq(x, self.out)\n",
        "\n",
        "    def initialize(self, params, input_latent=None, batch_size=64):\n",
        "        timesteps = np.arange(1, params['num_steps']+ 1)\n",
        "        input_lat_noise_t = timesteps[int(len(timesteps)* params[\"input_latent_strength\"])]\n",
        "        latent, alphas, alphas_prev = self.get_starting_parameters(\n",
        "            timesteps, batch_size, input_latent=input_latent, input_lat_noise_t=input_lat_noise_t\n",
        "        )\n",
        "        timesteps = timesteps[: int(len(timesteps)*params[\"input_latent_strength\"])]\n",
        "        return latent, alphas, alphas_prev, timesteps\n",
        "\n",
        "\n",
        "    def get_x_prev(self, x, e_t, a_t, a_prev, temperature):\n",
        "        sigma_t = 0\n",
        "        sqrt_one_minus_at = math.sqrt(1 - a_t)\n",
        "        pred_x0 = x - sqrt_one_minus_at * e_t / math.sqrt(a_t)\n",
        "\n",
        "        # Direction pointing to x_t\n",
        "        dir_xt = math.sqrt(1.0 - a_prev - sigma_t**2) * e_t\n",
        "        #noise = sigma_t * tf.random.normal(x.shape, seed=seed) * temperature\n",
        "        x_prev = math.sqrt(a_prev) * pred_x0 + dir_xt\n",
        "        return x_prev\n",
        "\n",
        "\n",
        "    def get_model_output(self, latent, timestep, batch_size):\n",
        "        timesteps = tf.convert_to_tensor([timestep], dtype=tf.float32)\n",
        "        t_emb = self.timestep_embedding(timesteps)\n",
        "        t_emb = tf.repeat(t_emb, repeats=batch_size, axis=0)\n",
        "        latent = self.call([latent, t_emb])\n",
        "        return latent\n",
        "\n",
        "\n",
        "    def timestep_embedding(self, timesteps, dim=320, max_period=10000):\n",
        "        half = dim // 2\n",
        "        freqs = np.exp(\n",
        "            -math.log(max_period) * np.arange(0, half, dtype=\"float32\") / half\n",
        "        )\n",
        "        args = np.array(timesteps) * freqs\n",
        "        embedding = np.concatenate([np.cos(args), np.sin(args)])\n",
        "        return tf.convert_to_tensor(embedding.reshape(1, -1), dtype=self.ntype)\n",
        "\n",
        "\n",
        "\n",
        "    # for model with input latent\n",
        "\n",
        "    def add_noise(self, x, t, noise=None):\n",
        "        if len(x.shape) == 3:\n",
        "            x = tf.expand_dims(x, axis=0)\n",
        "        batch_size, w, h, c = x.shape[0], x.shape[1], x.shape[2], x.shape[3]\n",
        "        if noise is None:\n",
        "            noise = tf.random.normal((batch_size, w, h, c), dtype=tf.float32)\n",
        "        sqrt_alpha_prod = tf.cast(_ALPHAS_CUMPROD[t] ** 0.5, tf.float32)\n",
        "        sqrt_one_minus_alpha_prod = (1 - _ALPHAS_CUMPROD[t]) ** 0.5\n",
        "\n",
        "        return sqrt_alpha_prod * x + sqrt_one_minus_alpha_prod * noise\n",
        "\n",
        "    def get_starting_parameters(self, timesteps, batch_size,  input_latent=None, input_lat_noise_t=None):\n",
        "        n_h = self.img_height\n",
        "        n_w = self.img_width\n",
        "        alphas = [_ALPHAS_CUMPROD[t] for t in timesteps]\n",
        "        alphas_prev = [1.0] + alphas[:-1]\n",
        "        if input_latent is None:\n",
        "            latent = tf.random.normal((batch_size, n_h, n_w, 3))\n",
        "        else:\n",
        "            input_latent = tf.cast(input_latent, self.ntype)\n",
        "            #latent = tf.repeat(input_latent , batch_size , axis=0)\n",
        "            latent = self.add_noise(input_latent, input_lat_noise_t)\n",
        "        return latent, alphas, alphas_prev\n"
      ],
      "metadata": {
        "id": "TY9yVQKwwppc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_one_hot_predictions(mem_pred):\n",
        "    maximum = np.argmax(mem_pred, axis=1)\n",
        "    num_classes = mem_pred.shape[1]\n",
        "    mem_true = np.zeros_like(mem_pred)\n",
        "    mem_true[np.arange(len(maximum)), maximum] = 1\n",
        "    return mem_true"
      ],
      "metadata": {
        "id": "OvZ3J9SG1kj0"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "outputs": [],
      "source": [
        "'''Generate samples and train the diffusion model at the same time'''\n",
        "\n",
        "#plusz lehetne itt még kritérium hogy ne menjen olyan messze az alaptól --- similarity loss\n",
        "#plusz még lehetne talán egy discriminator is, hogy valós reprezentációkat tanuljon meg\n",
        "\n",
        "\n",
        "def generate(cls=classifier, enc=encoder,  input_latent=None, train=True, coeff=1.0):\n",
        "\n",
        "    if len(input_latent.shape) == 3:\n",
        "        input_latent = tf.expand_dims(input_latent, axis=0)\n",
        "    batch_size = input_latent.shape[0] \n",
        "    batch_size = batch_size if batch_size is not None else 1\n",
        "    latent, alphas, alphas_prev, timesteps = model.initialize(params, input_latent, batch_size)\n",
        "\n",
        "\n",
        "    for index, timestep in reversed(list(enumerate(timesteps))):\n",
        "        if train:\n",
        "            with tf.GradientTape() as tape:\n",
        "                e_t = model.get_model_output(\n",
        "                    latent,\n",
        "                    timestep,\n",
        "                    batch_size,\n",
        "                )\n",
        "                a_t, a_prev = alphas[index], alphas_prev[index]\n",
        "                latent = model.get_x_prev(latent, e_t,  a_t, a_prev, params[\"temperature\"])\n",
        "                encoded = enc(latent)\n",
        "                pred = cls(encoded)\n",
        "                pred_true = pred#get_one_hot_predictions(pred) #ezt nem fixen kell mecsinálni\n",
        "                confidence_loss = coeff*tf.reduce_mean(tf.keras.losses.categorical_crossentropy(pred_true, pred))\n",
        "                #print(confidence_loss)\n",
        "                #similarity_loss = 0.1 * tf.reduce_mean(tf.square(latent - e_t))\n",
        "                #print(similarity_loss)\n",
        "                loss = confidence_loss #+ similarity_loss\n",
        "            grads = tape.gradient(loss, model.trainable_variables)\n",
        "            tf.keras.optimizers.legacy.Adam(learning_rate=params[\"gen_lr\"]).apply_gradients(zip(grads, model.trainable_variables))\n",
        "        else:\n",
        "            e_t = model.get_model_output(\n",
        "                latent,\n",
        "                timestep,\n",
        "                batch_size,\n",
        "            )\n",
        "            a_t, a_prev = alphas[index], alphas_prev[index]\n",
        "            latent = model.get_x_prev(latent, e_t,  a_t, a_prev, params[\"temperature\"])\n",
        "\n",
        "    return latent"
      ],
      "metadata": {
        "id": "n0nileU3wppd"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MOF8q3z4Z3kF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "UNetModel init\n"
          ]
        }
      ],
      "source": [
        "model = UNetModel()"
      ],
      "metadata": {
        "id": "8IXX3Srqwppe",
        "outputId": "4243d849-4b91-43c0-e87c-abe473fe10ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "outputs": [],
      "source": [
        "params = {\n",
        "    \"num_steps\": 10,\n",
        "    \"input_latent_strength\": 0.5,\n",
        "    \"temperature\": 0.9,\n",
        "    \"batch_size\": 256,\n",
        "    \"gen_lr\": 2e-5,\n",
        "    \"n_epoch\": 1,\n",
        "}"
      ],
      "metadata": {
        "id": "xI76KdNbwppe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 11s 0us/step\n"
          ]
        }
      ],
      "source": [
        "(X_train, y_train), (X_test, y_test) = load_cifar_10()"
      ],
      "metadata": {
        "id": "hAdxt2bYwppe",
        "outputId": "08107e26-1fa1-4833-ca4d-d6ea7401addf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwsk3EilLsA7",
        "outputId": "897659ad-050d-454c-9d39-df06a398a31b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_truck = np.argmax(y_train, axis=1)\n",
        "condition = np.logical_or(np.logical_or(y_truck == 1, y_truck == 2), y_truck == 3)\n",
        "X_truck = X_train[condition]\n",
        "X_truck.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7E_smdlELTZm",
        "outputId": "c9d4025b-29d3-42ac-e873-7ef2c852f28e"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15000, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.4242369\n",
            "0.33114964\n",
            "0.30617577\n",
            "0.20232084\n",
            "0.1963116\n",
            "0.1683407\n",
            "0.18010171\n",
            "0.11218709\n",
            "0.09894572\n",
            "0.051574066\n",
            "0.029566148\n",
            "0.03474347\n",
            "0.027091656\n",
            "0.02957435\n",
            "0.009589035\n",
            "0.0134067945\n",
            "0.0051059574\n",
            "0.008027151\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-72-c7d504477e50>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_truck\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"batch_size\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mX_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_truck\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"batch_size\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mmem_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_latent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mmem_enc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmem_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mmem_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmem_enc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-3bf56b6afe5c>\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(cls, enc, input_latent, train, coeff)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m                 e_t = model.get_model_output(\n\u001b[0m\u001b[1;32m     20\u001b[0m                     \u001b[0mlatent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                     \u001b[0mtimestep\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-fe3ceb3e5489>\u001b[0m in \u001b[0;36mget_model_output\u001b[0;34m(self, latent, timestep, batch_size)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mt_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimestep_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimesteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mt_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepeats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0mlatent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlatent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_emb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlatent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-fe3ceb3e5489>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mapply_seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-fe3ceb3e5489>\u001b[0m in \u001b[0;36mapply\u001b[0;34m(x, layer)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mResBlock\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0msaved_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1143\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m                 ):\n\u001b[0;32m-> 1145\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mbound_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_keras_call_info_injected\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-6fe4a5ffab9d>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0memb_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memb_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0memb_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mskip_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskip_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1174\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1176\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1177\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_slice_helper\u001b[0;34m(tensor, slice_spec, var)\u001b[0m\n\u001b[1;32m   1087\u001b[0m       skip_on_eager=False) as name:\n\u001b[1;32m   1088\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbegin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1089\u001b[0;31m       packed_begin, packed_end, packed_strides = (stack(begin), stack(end),\n\u001b[0m\u001b[1;32m   1090\u001b[0m                                                   stack(strides))\n\u001b[1;32m   1091\u001b[0m       \u001b[0;31m# TODO(mdan): Instead of implicitly casting, it's better to enforce the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1174\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1176\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1177\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mstack\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   1482\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1483\u001b[0m       \u001b[0;31m# If the input is a constant list, it can be converted to a constant op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1484\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1485\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1486\u001b[0m       \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Input list contains non-constant tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1641\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1642\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1644\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    342\u001b[0m                                          as_ref=False):\n\u001b[1;32m    343\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0mon\u001b[0m \u001b[0ma\u001b[0m \u001b[0msymbolic\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m   \"\"\"\n\u001b[0;32m--> 268\u001b[0;31m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0m\u001b[1;32m    269\u001b[0m                         allow_broadcast=True)\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    278\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tf.constant\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m   \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m   \u001b[0;34m\"\"\"Creates a constant on the current device.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m   \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    101\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "for epoch in range(params[\"n_epoch\"]):\n",
        "    loss = []\n",
        "    for i in range(0, X_truck.shape[0], params[\"batch_size\"]):\n",
        "        X_batch = X_truck[i:i+params[\"batch_size\"]]\n",
        "        mem_x = generate(input_latent=X_batch, train=True)\n",
        "        mem_enc = encoder(mem_x)\n",
        "        mem_pred = classifier(mem_enc)\n",
        "        mem_pred_true = get_one_hot_predictions(mem_pred)\n",
        "        mem_loss = tf.keras.losses.categorical_crossentropy(mem_pred_true, mem_pred)\n",
        "        loss.append(np.mean(mem_loss))\n",
        "        print(np.mean(mem_loss))\n",
        "    print(\"Loss on generate: \",  np.mean(loss))"
      ],
      "metadata": {
        "id": "-o1U9ShTwppe",
        "outputId": "8ac83c5d-5d1f-4e14-9de9-7f6bbead685b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 728
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def disp(image):\n",
        "    image = (image + 1)* 127.5\n",
        "\n",
        "    plt.imshow(image.astype(np.uint8))\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "6ZdXq-z3FRmb"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "disp(X_train[13])\n",
        "encoded = encoder(tf.expand_dims(X_train[12], axis=0))\n",
        "classified = classifier(encoded)\n",
        "print(np.argmax(classified))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "sYnxjanINAK4",
        "outputId": "56eaa796-933b-49d7-9584-260a7b636825"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image = generate(input_latent=X_train[13], train=False)\n",
        "disp(image[0].numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "M16EMP6Wn9tR",
        "outputId": "9e10a4bf-f0a1-4e4b-fed0-c301469a3d72"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded = encoder(image)\n",
        "classified = classifier(encoded)\n",
        "print(np.argmax(classified))\n",
        "np.max(classified)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i94V9lCgFHZn",
        "outputId": "1d0bb422-7723-4faa-829e-b88af341fb5e"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9624662"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4nTex8u7K66P",
        "outputId": "af44259d-300e-437f-b092-1d7ed7bd4f23"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image = generate(input_latent=X_train[13], train=False)\n",
        "disp(image[0].numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "moqFhumRKt8W",
        "outputId": "f09fa70b-04cf-4a50-f723-21d4032e117c"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded = encoder(image)\n",
        "classified = classifier(encoded)\n",
        "print(np.argmax(classified))\n",
        "np.max(classified)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BvVdgL1Vr3S",
        "outputId": "13024d59-0c12-4038-ed8b-1934550438d6"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.99973315"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0xx0H36jVvdH"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}