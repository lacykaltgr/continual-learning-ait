{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/lacykaltgr/continual-learning-ait/blob/experiment/generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--2023-05-11 14:25:26--  https://github.com/lacykaltgr/continual-learning-ait/archive/refs/heads/experiment.zip\n",
      "Resolving github.com (github.com)... 140.82.113.4\n",
      "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://codeload.github.com/lacykaltgr/continual-learning-ait/zip/refs/heads/experiment [following]\n",
      "--2023-05-11 14:25:26--  https://codeload.github.com/lacykaltgr/continual-learning-ait/zip/refs/heads/experiment\n",
      "Resolving codeload.github.com (codeload.github.com)... 140.82.112.9\n",
      "Connecting to codeload.github.com (codeload.github.com)|140.82.112.9|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [application/zip]\n",
      "Saving to: ‘experiment.zip’\n",
      "\n",
      "experiment.zip          [ <=>                ]   1.58M  --.-KB/s    in 0.1s    \n",
      "\n",
      "2023-05-11 14:25:26 (14.8 MB/s) - ‘experiment.zip’ saved [1659606]\n",
      "\n",
      "Archive:  experiment.zip\n",
      "6ab06d34a435387547f849642cd1aca6fb12d185\n",
      "   creating: continual-learning-ait-experiment/\n",
      "  inflating: continual-learning-ait-experiment/README.md  \n",
      "  inflating: continual-learning-ait-experiment/classifier.ipynb  \n",
      "  inflating: continual-learning-ait-experiment/classifier.py  \n",
      "  inflating: continual-learning-ait-experiment/data_preparation.ipynb  \n",
      "  inflating: continual-learning-ait-experiment/data_preparation.py  \n",
      "  inflating: continual-learning-ait-experiment/generator.ipynb  \n",
      "  inflating: continual-learning-ait-experiment/img.png  \n",
      "  inflating: continual-learning-ait-experiment/main.ipynb  \n",
      "   creating: continual-learning-ait-experiment/models/\n",
      "  inflating: continual-learning-ait-experiment/models/classifier.h5  \n",
      "  inflating: continual-learning-ait-experiment/models/encoder.h5  \n",
      "   creating: continual-learning-ait-experiment/stable_diffusion/\n",
      "  inflating: continual-learning-ait-experiment/stable_diffusion/autoencoder_kl.py  \n",
      "  inflating: continual-learning-ait-experiment/stable_diffusion/constants.py  \n",
      "  inflating: continual-learning-ait-experiment/stable_diffusion/diffusion_model.py  \n",
      "  inflating: continual-learning-ait-experiment/stable_diffusion/layers.py  \n",
      "  inflating: continual-learning-ait-experiment/stable_diffusion/stable_diffusion.py  \n",
      "  inflating: continual-learning-ait-experiment/utils.py  \n",
      "rm: cannot remove 'stable_diffusion': No such file or directory\n",
      "rm: cannot remove 'models': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "'''Download the files '''\n",
    "'''Only for colab'''\n",
    "\n",
    "!wget https://github.com/lacykaltgr/continual-learning-ait/archive/refs/heads/experiment.zip\n",
    "!unzip experiment.zip\n",
    "!find continual-learning-ait-experiment -type f ! -name \"main.ipynb\" -exec cp {} . \\;\n",
    "\n",
    "!rm -r stable_diffusion\n",
    "!rm -r models\n",
    "!mkdir stable_diffusion\n",
    "!mkdir models\n",
    "!mv diffusion_model.py stable_diffusion/\n",
    "!mv autoencoder_kl.py stable_diffusion/\n",
    "!mv layers.py stable_diffusion/\n",
    "!mv stable_diffusion.py stable_diffusion/\n",
    "!mv constants.py stable_diffusion/\n",
    "!mv encoder.h5 models/\n",
    "!mv classifier.h5 models/"
   ],
   "metadata": {
    "id": "FBqbqiHlwppa",
    "outputId": "03e88096-e1be-4792-9e6e-3c05d87b7b95",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "from keras.layers import Conv2D, Conv2DTranspose\n",
    "import math\n",
    "from stable_diffusion.constants import _ALPHAS_CUMPROD"
   ],
   "metadata": {
    "id": "qxtHOYA5wppb"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def load_cifar_10():\n",
    "    (X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "    n_classes = 10\n",
    "    X_train = (X_train / 127.5) -1\n",
    "    X_test = (X_test / 127.5) -1\n",
    "    y_train = tf.keras.utils.to_categorical(y_train, n_classes)\n",
    "    y_test = tf.keras.utils.to_categorical(y_test, n_classes)\n",
    "    return (X_train, y_train), (X_test, y_test)"
   ],
   "metadata": {
    "id": "9cDXrVOHwppb"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "id": "0MPVDCr_wppc",
    "outputId": "d0a7d94f-3e2e-4b49-8642-268d4d122344",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "encoder = load_model(\"models/encoder.h5\")\n",
    "classifier = load_model(\"models/classifier.h5\")\n",
    "\n",
    "encoder.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=5e-3),\n",
    "    loss=keras.losses.CategoricalCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "classifier.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=5e-3),\n",
    "    loss=keras.losses.CategoricalCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def apply_seq(x: object, layers: object) -> object:\n",
    "    for l in layers:\n",
    "        x = l(x)\n",
    "    return x"
   ],
   "metadata": {
    "id": "kBhHGv9jK6bb"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class ResBlock(keras.layers.Layer):\n",
    "    def __init__(self, channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.in_layers = [\n",
    "            keras.layers.GroupNormalization(epsilon=1e-5),\n",
    "            keras.activations.swish,\n",
    "            Conv2D(out_channels, 3, strides=(1, 1), padding='same'),\n",
    "        ]\n",
    "        self.emb_layers = [\n",
    "            keras.activations.swish,\n",
    "            keras.layers.Dense(out_channels),\n",
    "        ]\n",
    "        self.out_layers = [\n",
    "            keras.layers.GroupNormalization(epsilon=1e-5),\n",
    "            keras.activations.swish,\n",
    "            Conv2D(out_channels, 3, strides=(1, 1), padding='same'),\n",
    "        ]\n",
    "        self.skip_connection = (\n",
    "            Conv2D(out_channels, 3, strides=(1, 1), padding='same') if channels != out_channels else lambda x: x\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x, emb = inputs\n",
    "        h = apply_seq(x, self.in_layers)\n",
    "        emb_out = apply_seq(emb, self.emb_layers)\n",
    "        h = h + emb_out[:, None, None]\n",
    "        h = apply_seq(h, self.out_layers)\n",
    "        skip_x = self.skip_connection(x)\n",
    "        ret = skip_x + h\n",
    "        return ret"
   ],
   "metadata": {
    "id": "4Z_JKL-kK6bc"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "class UNetModel(keras.Model):\n",
    "    def __init__(self):\n",
    "        print(\"UNetModel init\")\n",
    "        super().__init__()\n",
    "        self.img_height = 32\n",
    "        self.img_width = 32\n",
    "        self.ntype = tf.float32\n",
    "        self.time_embed = [\n",
    "            keras.layers.Dense(128),\n",
    "            keras.activations.swish,\n",
    "            keras.layers.Dense(128),\n",
    "        ]\n",
    "        self.input_blocks = [\n",
    "            [Conv2D( 32, 3, strides=(1, 1), padding='same')],\n",
    "\n",
    "            [ResBlock(32, 32)],\n",
    "            [ResBlock(32, 32)],\n",
    "            [Conv2D(64, 3, strides=(2, 2), padding='same'),], #downsample\n",
    "\n",
    "            [ResBlock(32, 64)], \n",
    "            [ResBlock(64, 64)], \n",
    "            [Conv2D(128, 3, strides=(2, 2), padding='same'),], #downsample\n",
    "\n",
    "            [ResBlock(64, 128)],\n",
    "            [ResBlock(128, 128)],\n",
    "            [Conv2D(128, 3, strides=(2, 2), padding='same')], #downsample\n",
    "\n",
    "            [ResBlock(128, 128)],\n",
    "            [ResBlock(128, 128)],\n",
    "        ]\n",
    "        self.middle_block = [\n",
    "            ResBlock(128, 128),\n",
    "            ResBlock(128, 128),\n",
    "        ]\n",
    "        self.output_blocks = [\n",
    "            [ResBlock(256, 128)],\n",
    "            [ResBlock(256, 128)],\n",
    "\n",
    "            [\n",
    "                ResBlock(256, 128),\n",
    "                Conv2DTranspose(128, 2, strides=(2,2)),\n",
    "                Conv2D(128, 3, strides=(1,1), padding='same')\n",
    "            ],\n",
    "            [ResBlock(256, 128)], \n",
    "            [ResBlock(256, 128)],\n",
    "\n",
    "            [\n",
    "                ResBlock(192, 128),\n",
    "                Conv2DTranspose(128, 2, strides=(2,2)),\n",
    "                Conv2D(64, 2, strides=(1,1), padding='valid')\n",
    "            ],\n",
    "            [ResBlock(192, 64)], \n",
    "            [ResBlock(128, 64)], \n",
    "\n",
    "            [\n",
    "                ResBlock(96, 64),\n",
    "                Conv2DTranspose(64, 3, strides=(2,2)),\n",
    "                Conv2D(64, 2, strides=(1,1), padding='valid')\n",
    "            ],\n",
    "            [ResBlock(96, 32)], \n",
    "            [ResBlock(64, 32)],\n",
    "\n",
    "            [ResBlock(64, 32)],\n",
    "        ]\n",
    "        self.out = [\n",
    "            keras.layers.GroupNormalization(epsilon=1e-5),\n",
    "            keras.activations.swish,\n",
    "            Conv2D(8, 3, strides=(1,1), padding='same'),\n",
    "        ]\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x, t_emb = inputs\n",
    "        emb = apply_seq(t_emb, self.time_embed)\n",
    "\n",
    "        def apply(x, layer):\n",
    "            return layer([x, emb]) if isinstance(layer, ResBlock) else layer(x)\n",
    "\n",
    "        saved_inputs = []\n",
    "        for b in self.input_blocks:\n",
    "            for layer in b:\n",
    "                x = apply(x, layer)\n",
    "            saved_inputs.append(x)\n",
    "\n",
    "        for layer in self.middle_block:\n",
    "            x = apply(x, layer)\n",
    "\n",
    "        for b in self.output_blocks:\n",
    "            skip = saved_inputs.pop()\n",
    "            x = tf.concat([x, skip], axis=-1)\n",
    "            for layer in b:\n",
    "                x = apply(x, layer)\n",
    "\n",
    "        return apply_seq(x, self.out)\n",
    "\n",
    "    def initialize(self, params, input_latent=None, batch_size=64):\n",
    "        timesteps = np.arange(1, params['num_steps']+ 1)\n",
    "        input_lat_noise_t = timesteps[int(len(timesteps)* params[\"input_latent_strength\"])]\n",
    "        latent, alphas, alphas_prev = self.get_starting_parameters(\n",
    "            timesteps, batch_size, input_latent=input_latent, input_lat_noise_t=input_lat_noise_t\n",
    "        )\n",
    "        timesteps = timesteps[: int(len(timesteps)*params[\"input_latent_strength\"])]\n",
    "        return latent, alphas, alphas_prev, timesteps\n",
    "\n",
    "\n",
    "    def get_x_prev(self, x, e_t, a_t, a_prev, temperature):\n",
    "        sigma_t = 0\n",
    "        sqrt_one_minus_at = math.sqrt(1 - a_t)\n",
    "        pred_x0 = x - sqrt_one_minus_at * e_t / math.sqrt(a_t)\n",
    "\n",
    "        # Direction pointing to x_t\n",
    "        dir_xt = math.sqrt(1.0 - a_prev - sigma_t**2) * e_t\n",
    "        #noise = sigma_t * tf.random.normal(x.shape, seed=seed) * temperature\n",
    "        x_prev = math.sqrt(a_prev) * pred_x0 + dir_xt\n",
    "        return x_prev\n",
    "\n",
    "\n",
    "    def get_model_output(self, latent, timestep, batch_size):\n",
    "        timesteps = tf.convert_to_tensor([timestep], dtype=tf.float32)\n",
    "        t_emb = self.timestep_embedding(timesteps)\n",
    "        t_emb = tf.repeat(t_emb, repeats=batch_size, axis=0)\n",
    "        latent = self.call([latent, t_emb])\n",
    "        return latent\n",
    "\n",
    "\n",
    "    def timestep_embedding(self, timesteps, dim=320, max_period=10000):\n",
    "        half = dim // 2\n",
    "        freqs = np.exp(\n",
    "            -math.log(max_period) * np.arange(0, half, dtype=\"float32\") / half\n",
    "        )\n",
    "        args = np.array(timesteps) * freqs\n",
    "        embedding = np.concatenate([np.cos(args), np.sin(args)])\n",
    "        return tf.convert_to_tensor(embedding.reshape(1, -1), dtype=self.ntype)\n",
    "\n",
    "\n",
    "\n",
    "    # for model with input latent\n",
    "\n",
    "    def add_noise(self, x, t, noise=None):\n",
    "        if len(x.shape) == 3:\n",
    "            x = tf.expand_dims(x, axis=0)\n",
    "        batch_size, w, h, c = x.shape[0], x.shape[1], x.shape[2], x.shape[3]\n",
    "        if noise is None:\n",
    "            noise = tf.random.normal((batch_size, w, h, c), dtype=tf.float32)\n",
    "        sqrt_alpha_prod = tf.cast(_ALPHAS_CUMPROD[t] ** 0.5, tf.float32)\n",
    "        sqrt_one_minus_alpha_prod = (1 - _ALPHAS_CUMPROD[t]) ** 0.5\n",
    "\n",
    "        return sqrt_alpha_prod * x + sqrt_one_minus_alpha_prod * noise\n",
    "\n",
    "    def get_starting_parameters(self, timesteps, batch_size,  input_latent=None, input_lat_noise_t=None):\n",
    "        n_h = self.img_height // 8\n",
    "        n_w = self.img_width // 8\n",
    "        alphas = [_ALPHAS_CUMPROD[t] for t in timesteps]\n",
    "        alphas_prev = [1.0] + alphas[:-1]\n",
    "        if input_latent is None:\n",
    "            latent = tf.random.normal((batch_size, n_h, n_w, 8))\n",
    "        else:\n",
    "            input_latent = tf.cast(input_latent, self.ntype)\n",
    "            #latent = tf.repeat(input_latent , batch_size , axis=0)\n",
    "            latent = self.add_noise(input_latent, input_lat_noise_t)\n",
    "        return latent, alphas, alphas_prev\n"
   ],
   "metadata": {
    "id": "TY9yVQKwwppc"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def get_one_hot_predictions(mem_pred):\n",
    "    maximum = np.argmax(mem_pred, axis=1)\n",
    "    num_classes = mem_pred.shape[1]\n",
    "    mem_true = np.zeros_like(mem_pred)\n",
    "    mem_true[np.arange(len(maximum)), maximum] = 1\n",
    "    return mem_true"
   ],
   "metadata": {
    "id": "OvZ3J9SG1kj0"
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "'''Generate samples and train the diffusion model at the same time'''\n",
    "\n",
    "#plusz lehetne itt még kritérium hogy ne menjen olyan messze az alaptól --- similarity loss\n",
    "#plusz még lehetne talán egy discriminator is, hogy valós reprezentációkat tanuljon meg\n",
    "\n",
    "\n",
    "def generate(cls=classifier, input_latent=None, train=True, coeff=1.0):\n",
    "\n",
    "    batch_size = params['batch_size'] if train else 64\n",
    "    latent, alphas, alphas_prev, timesteps = model.initialize(params, input_latent, batch_size)\n",
    "\n",
    "\n",
    "    for index, timestep in reversed(list(enumerate(timesteps))):\n",
    "        if train:\n",
    "            with tf.GradientTape() as tape:\n",
    "                e_t = model.get_model_output(\n",
    "                    latent,\n",
    "                    timestep,\n",
    "                    batch_size,\n",
    "                )\n",
    "                a_t, a_prev = alphas[index], alphas_prev[index]\n",
    "                latent = model.get_x_prev(latent, e_t,  a_t, a_prev, params[\"temperature\"])\n",
    "\n",
    "                pred = cls(latent)\n",
    "                pred_true = get_one_hot_predictions(pred) #ezt nem fixen kell mecsinálni\n",
    "                confidence_loss = coeff*tf.reduce_mean(tf.keras.losses.categorical_crossentropy(pred_true, pred))\n",
    "                print(confidence_loss)\n",
    "                similarity_loss = 0.1 * tf.reduce_mean(tf.square(latent - e_t))\n",
    "                print(similarity_loss)\n",
    "                loss = confidence_loss + similarity_loss\n",
    "            grads = tape.gradient(loss, model.trainable_variables)\n",
    "            tf.keras.optimizers.legacy.Adam(learning_rate=params[\"gen_lr\"]).apply_gradients(zip(grads, model.trainable_variables))\n",
    "        else:\n",
    "            e_t = model.get_model_output(\n",
    "                latent,\n",
    "                timestep,\n",
    "                batch_size,\n",
    "            )\n",
    "            a_t, a_prev = alphas[index], alphas_prev[index]\n",
    "            latent = model.get_x_prev(latent, e_t,  a_t, a_prev, params[\"temperature\"])\n",
    "\n",
    "    return latent"
   ],
   "metadata": {
    "id": "n0nileU3wppd"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "UNetModel init\n"
     ]
    }
   ],
   "source": [
    "model = UNetModel()"
   ],
   "metadata": {
    "id": "8IXX3Srqwppe",
    "outputId": "20897906-39ce-4ede-89c7-e2cb0d0f0877",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"num_steps\": 3,\n",
    "    \"input_latent_strength\": 0.9,\n",
    "    \"temperature\": 0.9,\n",
    "    \"batch_size\": 256,\n",
    "    \"gen_lr\": 2e-3,\n",
    "    \"n_epoch\": 1,\n",
    "}"
   ],
   "metadata": {
    "id": "xI76KdNbwppe"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170498071/170498071 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = load_cifar_10()"
   ],
   "metadata": {
    "id": "hAdxt2bYwppe",
    "outputId": "d55087f4-fc71-4904-e4f3-590b7e667955",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tf.Tensor(0.13102618, shape=(), dtype=float32)\n",
      "tf.Tensor(0.05313134, shape=(), dtype=float32)\n",
      "tf.Tensor(0.11086766, shape=(), dtype=float32)\n",
      "tf.Tensor(0.03974482, shape=(), dtype=float32)\n",
      "Value: 0 Count: 16\n",
      "Value: 1 Count: 38\n",
      "Value: 2 Count: 24\n",
      "Value: 3 Count: 24\n",
      "Value: 4 Count: 23\n",
      "Value: 5 Count: 22\n",
      "Value: 6 Count: 33\n",
      "Value: 7 Count: 25\n",
      "Value: 8 Count: 22\n",
      "Value: 9 Count: 29\n",
      "0.11086766\n",
      "tf.Tensor(0.14926352, shape=(), dtype=float32)\n",
      "tf.Tensor(0.04855547, shape=(), dtype=float32)\n",
      "tf.Tensor(0.13393158, shape=(), dtype=float32)\n",
      "tf.Tensor(0.034818947, shape=(), dtype=float32)\n",
      "Value: 0 Count: 31\n",
      "Value: 1 Count: 30\n",
      "Value: 2 Count: 17\n",
      "Value: 3 Count: 21\n",
      "Value: 4 Count: 36\n",
      "Value: 5 Count: 21\n",
      "Value: 6 Count: 21\n",
      "Value: 7 Count: 25\n",
      "Value: 8 Count: 25\n",
      "Value: 9 Count: 29\n",
      "0.13393158\n",
      "tf.Tensor(0.17173126, shape=(), dtype=float32)\n",
      "tf.Tensor(0.029068053, shape=(), dtype=float32)\n",
      "tf.Tensor(0.17189915, shape=(), dtype=float32)\n",
      "tf.Tensor(0.041004803, shape=(), dtype=float32)\n",
      "Value: 0 Count: 27\n",
      "Value: 1 Count: 24\n",
      "Value: 2 Count: 22\n",
      "Value: 3 Count: 18\n",
      "Value: 4 Count: 27\n",
      "Value: 5 Count: 27\n",
      "Value: 6 Count: 30\n",
      "Value: 7 Count: 26\n",
      "Value: 8 Count: 26\n",
      "Value: 9 Count: 29\n",
      "0.17189917\n",
      "tf.Tensor(0.17015687, shape=(), dtype=float32)\n",
      "tf.Tensor(0.020422643, shape=(), dtype=float32)\n",
      "tf.Tensor(0.14671525, shape=(), dtype=float32)\n",
      "tf.Tensor(0.018608944, shape=(), dtype=float32)\n",
      "Value: 0 Count: 20\n",
      "Value: 1 Count: 28\n",
      "Value: 2 Count: 26\n",
      "Value: 3 Count: 34\n",
      "Value: 4 Count: 30\n",
      "Value: 5 Count: 23\n",
      "Value: 6 Count: 30\n",
      "Value: 7 Count: 22\n",
      "Value: 8 Count: 24\n",
      "Value: 9 Count: 19\n",
      "0.14671522\n",
      "tf.Tensor(0.14042269, shape=(), dtype=float32)\n",
      "tf.Tensor(0.020151446, shape=(), dtype=float32)\n",
      "tf.Tensor(0.1213226, shape=(), dtype=float32)\n",
      "tf.Tensor(0.01739411, shape=(), dtype=float32)\n",
      "Value: 0 Count: 30\n",
      "Value: 1 Count: 15\n",
      "Value: 2 Count: 20\n",
      "Value: 3 Count: 21\n",
      "Value: 4 Count: 18\n",
      "Value: 5 Count: 30\n",
      "Value: 6 Count: 36\n",
      "Value: 7 Count: 21\n",
      "Value: 8 Count: 26\n",
      "Value: 9 Count: 39\n",
      "0.1213226\n",
      "tf.Tensor(0.18178026, shape=(), dtype=float32)\n",
      "tf.Tensor(0.018320812, shape=(), dtype=float32)\n",
      "tf.Tensor(0.16701752, shape=(), dtype=float32)\n",
      "tf.Tensor(0.01760169, shape=(), dtype=float32)\n",
      "Value: 0 Count: 28\n",
      "Value: 1 Count: 25\n",
      "Value: 2 Count: 27\n",
      "Value: 3 Count: 27\n",
      "Value: 4 Count: 36\n",
      "Value: 5 Count: 21\n",
      "Value: 6 Count: 22\n",
      "Value: 7 Count: 19\n",
      "Value: 8 Count: 29\n",
      "Value: 9 Count: 22\n",
      "0.16701752\n",
      "tf.Tensor(0.16660847, shape=(), dtype=float32)\n",
      "tf.Tensor(0.014708503, shape=(), dtype=float32)\n",
      "tf.Tensor(0.14434792, shape=(), dtype=float32)\n",
      "tf.Tensor(0.013590795, shape=(), dtype=float32)\n",
      "Value: 0 Count: 23\n",
      "Value: 1 Count: 30\n",
      "Value: 2 Count: 13\n",
      "Value: 3 Count: 28\n",
      "Value: 4 Count: 34\n",
      "Value: 5 Count: 22\n",
      "Value: 6 Count: 27\n",
      "Value: 7 Count: 25\n",
      "Value: 8 Count: 25\n",
      "Value: 9 Count: 29\n",
      "0.1443479\n",
      "tf.Tensor(0.16794968, shape=(), dtype=float32)\n",
      "tf.Tensor(0.016900683, shape=(), dtype=float32)\n",
      "tf.Tensor(0.14078589, shape=(), dtype=float32)\n",
      "tf.Tensor(0.014011656, shape=(), dtype=float32)\n",
      "Value: 0 Count: 29\n",
      "Value: 1 Count: 17\n",
      "Value: 2 Count: 24\n",
      "Value: 3 Count: 26\n",
      "Value: 4 Count: 34\n",
      "Value: 5 Count: 29\n",
      "Value: 6 Count: 27\n",
      "Value: 7 Count: 32\n",
      "Value: 8 Count: 20\n",
      "Value: 9 Count: 18\n",
      "0.14078587\n",
      "tf.Tensor(0.14725494, shape=(), dtype=float32)\n",
      "tf.Tensor(0.016047224, shape=(), dtype=float32)\n",
      "tf.Tensor(0.12551996, shape=(), dtype=float32)\n",
      "tf.Tensor(0.01312311, shape=(), dtype=float32)\n",
      "Value: 0 Count: 20\n",
      "Value: 1 Count: 26\n",
      "Value: 2 Count: 23\n",
      "Value: 3 Count: 27\n",
      "Value: 4 Count: 35\n",
      "Value: 5 Count: 28\n",
      "Value: 6 Count: 27\n",
      "Value: 7 Count: 24\n",
      "Value: 8 Count: 22\n",
      "Value: 9 Count: 24\n",
      "0.12551995\n",
      "tf.Tensor(0.14951918, shape=(), dtype=float32)\n",
      "tf.Tensor(0.017690951, shape=(), dtype=float32)\n",
      "tf.Tensor(0.13093396, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0103672985, shape=(), dtype=float32)\n",
      "Value: 0 Count: 30\n",
      "Value: 1 Count: 24\n",
      "Value: 2 Count: 25\n",
      "Value: 3 Count: 31\n",
      "Value: 4 Count: 23\n",
      "Value: 5 Count: 21\n",
      "Value: 6 Count: 25\n",
      "Value: 7 Count: 27\n",
      "Value: 8 Count: 27\n",
      "Value: 9 Count: 23\n",
      "0.13093396\n",
      "tf.Tensor(0.12369504, shape=(), dtype=float32)\n",
      "tf.Tensor(0.019557985, shape=(), dtype=float32)\n",
      "tf.Tensor(0.10634329, shape=(), dtype=float32)\n",
      "tf.Tensor(0.010147592, shape=(), dtype=float32)\n",
      "Value: 0 Count: 24\n",
      "Value: 1 Count: 27\n",
      "Value: 2 Count: 26\n",
      "Value: 3 Count: 22\n",
      "Value: 4 Count: 22\n",
      "Value: 5 Count: 25\n",
      "Value: 6 Count: 33\n",
      "Value: 7 Count: 24\n",
      "Value: 8 Count: 30\n",
      "Value: 9 Count: 23\n",
      "0.10634328\n",
      "tf.Tensor(0.16556224, shape=(), dtype=float32)\n",
      "tf.Tensor(0.01541992, shape=(), dtype=float32)\n",
      "tf.Tensor(0.13938177, shape=(), dtype=float32)\n",
      "tf.Tensor(0.010181384, shape=(), dtype=float32)\n",
      "Value: 0 Count: 26\n",
      "Value: 1 Count: 26\n",
      "Value: 2 Count: 21\n",
      "Value: 3 Count: 19\n",
      "Value: 4 Count: 34\n",
      "Value: 5 Count: 30\n",
      "Value: 6 Count: 36\n",
      "Value: 7 Count: 17\n",
      "Value: 8 Count: 24\n",
      "Value: 9 Count: 23\n",
      "0.13938177\n",
      "tf.Tensor(0.17558262, shape=(), dtype=float32)\n",
      "tf.Tensor(0.017688183, shape=(), dtype=float32)\n",
      "tf.Tensor(0.14113912, shape=(), dtype=float32)\n",
      "tf.Tensor(0.011251172, shape=(), dtype=float32)\n",
      "Value: 0 Count: 23\n",
      "Value: 1 Count: 18\n",
      "Value: 2 Count: 21\n",
      "Value: 3 Count: 34\n",
      "Value: 4 Count: 28\n",
      "Value: 5 Count: 31\n",
      "Value: 6 Count: 25\n",
      "Value: 7 Count: 21\n",
      "Value: 8 Count: 25\n",
      "Value: 9 Count: 30\n",
      "0.14113912\n",
      "tf.Tensor(0.13532622, shape=(), dtype=float32)\n",
      "tf.Tensor(0.018803015, shape=(), dtype=float32)\n",
      "tf.Tensor(0.10783421, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0110282395, shape=(), dtype=float32)\n",
      "Value: 0 Count: 32\n",
      "Value: 1 Count: 19\n",
      "Value: 2 Count: 25\n",
      "Value: 3 Count: 32\n",
      "Value: 4 Count: 31\n",
      "Value: 5 Count: 28\n",
      "Value: 6 Count: 24\n",
      "Value: 7 Count: 20\n",
      "Value: 8 Count: 25\n",
      "Value: 9 Count: 20\n",
      "0.107834205\n",
      "tf.Tensor(0.13844675, shape=(), dtype=float32)\n",
      "tf.Tensor(0.019176146, shape=(), dtype=float32)\n",
      "tf.Tensor(0.1077176, shape=(), dtype=float32)\n",
      "tf.Tensor(0.010226364, shape=(), dtype=float32)\n",
      "Value: 0 Count: 21\n",
      "Value: 1 Count: 20\n",
      "Value: 2 Count: 16\n",
      "Value: 3 Count: 32\n",
      "Value: 4 Count: 30\n",
      "Value: 5 Count: 19\n",
      "Value: 6 Count: 34\n",
      "Value: 7 Count: 24\n",
      "Value: 8 Count: 24\n",
      "Value: 9 Count: 36\n",
      "0.1077176\n",
      "tf.Tensor(0.16667336, shape=(), dtype=float32)\n",
      "tf.Tensor(0.019128758, shape=(), dtype=float32)\n",
      "tf.Tensor(0.12759255, shape=(), dtype=float32)\n",
      "tf.Tensor(0.011522141, shape=(), dtype=float32)\n",
      "Value: 0 Count: 32\n",
      "Value: 1 Count: 25\n",
      "Value: 2 Count: 17\n",
      "Value: 3 Count: 23\n",
      "Value: 4 Count: 32\n",
      "Value: 5 Count: 22\n",
      "Value: 6 Count: 31\n",
      "Value: 7 Count: 24\n",
      "Value: 8 Count: 22\n",
      "Value: 9 Count: 28\n",
      "0.12759253\n",
      "tf.Tensor(0.14901498, shape=(), dtype=float32)\n",
      "tf.Tensor(0.02230218, shape=(), dtype=float32)\n",
      "tf.Tensor(0.11920811, shape=(), dtype=float32)\n",
      "tf.Tensor(0.01185138, shape=(), dtype=float32)\n",
      "Value: 0 Count: 27\n",
      "Value: 1 Count: 20\n",
      "Value: 2 Count: 21\n",
      "Value: 3 Count: 31\n",
      "Value: 4 Count: 34\n",
      "Value: 5 Count: 17\n",
      "Value: 6 Count: 30\n",
      "Value: 7 Count: 28\n",
      "Value: 8 Count: 26\n",
      "Value: 9 Count: 22\n",
      "0.11920811\n",
      "tf.Tensor(0.13537048, shape=(), dtype=float32)\n",
      "tf.Tensor(0.02061459, shape=(), dtype=float32)\n",
      "tf.Tensor(0.10372649, shape=(), dtype=float32)\n",
      "tf.Tensor(0.011603865, shape=(), dtype=float32)\n",
      "Value: 0 Count: 30\n",
      "Value: 1 Count: 31\n",
      "Value: 2 Count: 25\n",
      "Value: 3 Count: 30\n",
      "Value: 4 Count: 19\n",
      "Value: 5 Count: 27\n",
      "Value: 6 Count: 22\n",
      "Value: 7 Count: 25\n",
      "Value: 8 Count: 23\n",
      "Value: 9 Count: 24\n",
      "0.10372649\n",
      "tf.Tensor(0.14914641, shape=(), dtype=float32)\n",
      "tf.Tensor(0.01894751, shape=(), dtype=float32)\n",
      "tf.Tensor(0.117654555, shape=(), dtype=float32)\n",
      "tf.Tensor(0.01015852, shape=(), dtype=float32)\n",
      "Value: 0 Count: 24\n",
      "Value: 1 Count: 22\n",
      "Value: 2 Count: 25\n",
      "Value: 3 Count: 21\n",
      "Value: 4 Count: 24\n",
      "Value: 5 Count: 31\n",
      "Value: 6 Count: 29\n",
      "Value: 7 Count: 19\n",
      "Value: 8 Count: 33\n",
      "Value: 9 Count: 28\n",
      "0.117654555\n",
      "tf.Tensor(0.17290638, shape=(), dtype=float32)\n",
      "tf.Tensor(0.018735368, shape=(), dtype=float32)\n",
      "tf.Tensor(0.13787243, shape=(), dtype=float32)\n",
      "tf.Tensor(0.011085638, shape=(), dtype=float32)\n",
      "Value: 0 Count: 29\n",
      "Value: 1 Count: 23\n",
      "Value: 2 Count: 15\n",
      "Value: 3 Count: 31\n",
      "Value: 4 Count: 24\n",
      "Value: 5 Count: 22\n",
      "Value: 6 Count: 39\n",
      "Value: 7 Count: 30\n",
      "Value: 8 Count: 24\n",
      "Value: 9 Count: 19\n",
      "0.13787243\n",
      "tf.Tensor(0.16270109, shape=(), dtype=float32)\n",
      "tf.Tensor(0.021860236, shape=(), dtype=float32)\n",
      "tf.Tensor(0.11288394, shape=(), dtype=float32)\n",
      "tf.Tensor(0.012703982, shape=(), dtype=float32)\n",
      "Value: 0 Count: 20\n",
      "Value: 1 Count: 31\n",
      "Value: 2 Count: 24\n",
      "Value: 3 Count: 21\n",
      "Value: 4 Count: 27\n",
      "Value: 5 Count: 24\n",
      "Value: 6 Count: 28\n",
      "Value: 7 Count: 25\n",
      "Value: 8 Count: 24\n",
      "Value: 9 Count: 32\n",
      "0.11288394\n",
      "tf.Tensor(0.13878447, shape=(), dtype=float32)\n",
      "tf.Tensor(0.023941329, shape=(), dtype=float32)\n",
      "tf.Tensor(0.09650021, shape=(), dtype=float32)\n",
      "tf.Tensor(0.013343035, shape=(), dtype=float32)\n",
      "Value: 0 Count: 28\n",
      "Value: 1 Count: 21\n",
      "Value: 2 Count: 19\n",
      "Value: 3 Count: 33\n",
      "Value: 4 Count: 23\n",
      "Value: 5 Count: 27\n",
      "Value: 6 Count: 27\n",
      "Value: 7 Count: 25\n",
      "Value: 8 Count: 18\n",
      "Value: 9 Count: 35\n",
      "0.0965002\n",
      "tf.Tensor(0.19321632, shape=(), dtype=float32)\n",
      "tf.Tensor(0.018292082, shape=(), dtype=float32)\n",
      "tf.Tensor(0.12476214, shape=(), dtype=float32)\n",
      "tf.Tensor(0.014049522, shape=(), dtype=float32)\n",
      "Value: 0 Count: 28\n",
      "Value: 1 Count: 24\n",
      "Value: 2 Count: 22\n",
      "Value: 3 Count: 28\n",
      "Value: 4 Count: 26\n",
      "Value: 5 Count: 22\n",
      "Value: 6 Count: 26\n",
      "Value: 7 Count: 28\n",
      "Value: 8 Count: 26\n",
      "Value: 9 Count: 26\n",
      "0.12476213\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-68-d0cac1e26bc2>\u001B[0m in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      5\u001B[0m         \u001B[0my_batch\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0my_train\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m+\u001B[0m\u001B[0mparams\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"batch_size\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m         \u001B[0mlatent\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mencoder\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX_batch\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 7\u001B[0;31m         \u001B[0mmem_x\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgenerate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput_latent\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mlatent\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrain\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      8\u001B[0m         \u001B[0mmem_pred\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mclassifier\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmem_x\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      9\u001B[0m         \u001B[0munique_values\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcounts\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munique\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0margmax\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmem_pred\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreturn_counts\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-66-dedd0e100cbd>\u001B[0m in \u001B[0;36mgenerate\u001B[0;34m(cls, input_latent, train, coeff)\u001B[0m\n\u001B[1;32m     14\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mtrain\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     15\u001B[0m             \u001B[0;32mwith\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mGradientTape\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mtape\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 16\u001B[0;31m                 e_t = model.get_model_output(\n\u001B[0m\u001B[1;32m     17\u001B[0m                     \u001B[0mlatent\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     18\u001B[0m                     \u001B[0mtimestep\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-7-60cbd9c6ce8f>\u001B[0m in \u001B[0;36mget_model_output\u001B[0;34m(self, latent, timestep, batch_size)\u001B[0m\n\u001B[1;32m    119\u001B[0m         \u001B[0mt_emb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtimestep_embedding\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtimesteps\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    120\u001B[0m         \u001B[0mt_emb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrepeat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mt_emb\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrepeats\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mbatch_size\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 121\u001B[0;31m         \u001B[0mlatent\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcall\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mlatent\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mt_emb\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    122\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mlatent\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    123\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-7-60cbd9c6ce8f>\u001B[0m in \u001B[0;36mcall\u001B[0;34m(self, inputs)\u001B[0m\n\u001B[1;32m     89\u001B[0m             \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconcat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mskip\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     90\u001B[0m             \u001B[0;32mfor\u001B[0m \u001B[0mlayer\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mb\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 91\u001B[0;31m                 \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mapply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlayer\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     92\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     93\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mapply_seq\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-7-60cbd9c6ce8f>\u001B[0m in \u001B[0;36mapply\u001B[0;34m(x, layer)\u001B[0m\n\u001B[1;32m     74\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     75\u001B[0m         \u001B[0;32mdef\u001B[0m \u001B[0mapply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlayer\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 76\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mlayer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0memb\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlayer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mResBlock\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0mlayer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     77\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     78\u001B[0m         \u001B[0msaved_inputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     63\u001B[0m         \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     64\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 65\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     66\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     67\u001B[0m             \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/base_layer.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1143\u001B[0m                     \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_compute_dtype_object\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1144\u001B[0m                 ):\n\u001B[0;32m-> 1145\u001B[0;31m                     \u001B[0moutputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcall_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1146\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1147\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_activity_regularizer\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     94\u001B[0m         \u001B[0mbound_signature\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     95\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 96\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     97\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     98\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mhasattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"_keras_call_info_injected\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-6-2354deb16e2a>\u001B[0m in \u001B[0;36mcall\u001B[0;34m(self, inputs)\u001B[0m\n\u001B[1;32m     25\u001B[0m         \u001B[0memb_out\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mapply_seq\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0memb\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0memb_layers\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     26\u001B[0m         \u001B[0mh\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mh\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0memb_out\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 27\u001B[0;31m         \u001B[0mh\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mapply_seq\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mh\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mout_layers\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     28\u001B[0m         \u001B[0mskip_x\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mskip_connection\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     29\u001B[0m         \u001B[0mret\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mskip_x\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mh\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-5-841a5a3f5abd>\u001B[0m in \u001B[0;36mapply_seq\u001B[0;34m(x, layers)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mapply_seq\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mobject\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlayers\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mobject\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mobject\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m     \u001B[0;32mfor\u001B[0m \u001B[0ml\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mlayers\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m         \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0ml\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     63\u001B[0m         \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     64\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 65\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     66\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     67\u001B[0m             \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/base_layer.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1143\u001B[0m                     \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_compute_dtype_object\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1144\u001B[0m                 ):\n\u001B[0;32m-> 1145\u001B[0;31m                     \u001B[0moutputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcall_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1146\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1147\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_activity_regularizer\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     94\u001B[0m         \u001B[0mbound_signature\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     95\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 96\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     97\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     98\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mhasattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"_keras_call_info_injected\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/keras/layers/normalization/group_normalization.py\u001B[0m in \u001B[0;36mcall\u001B[0;34m(self, inputs)\u001B[0m\n\u001B[1;32m    162\u001B[0m         \u001B[0minput_shape\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    163\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 164\u001B[0;31m         \u001B[0mreshaped_inputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_reshape_into_groups\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    165\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    166\u001B[0m         normalized_inputs = self._apply_normalization(\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/keras/layers/normalization/group_normalization.py\u001B[0m in \u001B[0;36m_reshape_into_groups\u001B[0;34m(self, inputs)\u001B[0m\n\u001B[1;32m    174\u001B[0m         \u001B[0mgroup_shape\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0minput_shape\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrank\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    175\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 176\u001B[0;31m         \u001B[0mgroup_shape\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0maxis\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0minput_shape\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0maxis\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m//\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgroups\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    177\u001B[0m         \u001B[0mgroup_shape\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0minsert\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0maxis\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgroups\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    178\u001B[0m         \u001B[0mgroup_shape\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstack\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mgroup_shape\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m     \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    149\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 150\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    151\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    152\u001B[0m       \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py\u001B[0m in \u001B[0;36mop_dispatch_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m   1174\u001B[0m       \u001B[0;31m# Fallback dispatch system (dispatch v1):\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1175\u001B[0m       \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1176\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mdispatch_target\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1177\u001B[0m       \u001B[0;32mexcept\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mTypeError\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mValueError\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1178\u001B[0m         \u001B[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/array_ops.py\u001B[0m in \u001B[0;36m_slice_helper\u001B[0;34m(tensor, slice_spec, var)\u001B[0m\n\u001B[1;32m   1088\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mbegin\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1089\u001B[0m       packed_begin, packed_end, packed_strides = (stack(begin), stack(end),\n\u001B[0;32m-> 1090\u001B[0;31m                                                   stack(strides))\n\u001B[0m\u001B[1;32m   1091\u001B[0m       \u001B[0;31m# TODO(mdan): Instead of implicitly casting, it's better to enforce the\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1092\u001B[0m       \u001B[0;31m# same dtypes.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m     \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    149\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 150\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    151\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    152\u001B[0m       \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py\u001B[0m in \u001B[0;36mop_dispatch_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m   1174\u001B[0m       \u001B[0;31m# Fallback dispatch system (dispatch v1):\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1175\u001B[0m       \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1176\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mdispatch_target\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1177\u001B[0m       \u001B[0;32mexcept\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mTypeError\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mValueError\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1178\u001B[0m         \u001B[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/array_ops.py\u001B[0m in \u001B[0;36mstack\u001B[0;34m(values, axis, name)\u001B[0m\n\u001B[1;32m   1482\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1483\u001B[0m       \u001B[0;31m# If the input is a constant list, it can be converted to a constant op\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1484\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconvert_to_tensor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1485\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mTypeError\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mValueError\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mNotImplementedError\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1486\u001B[0m       \u001B[0;32mpass\u001B[0m  \u001B[0;31m# Input list contains non-constant tensors\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/profiler/trace.py\u001B[0m in \u001B[0;36mwrapped\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    181\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0mTrace\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrace_name\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mtrace_kwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    182\u001B[0m           \u001B[0;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 183\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    184\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    185\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mwrapped\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001B[0m in \u001B[0;36mconvert_to_tensor\u001B[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001B[0m\n\u001B[1;32m   1640\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1641\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mret\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1642\u001B[0;31m       \u001B[0mret\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mconversion_func\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvalue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mas_ref\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mas_ref\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1643\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1644\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mret\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0mNotImplemented\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\u001B[0m in \u001B[0;36m_constant_tensor_conversion_function\u001B[0;34m(v, dtype, name, as_ref)\u001B[0m\n\u001B[1;32m    342\u001B[0m                                          as_ref=False):\n\u001B[1;32m    343\u001B[0m   \u001B[0m_\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mas_ref\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 344\u001B[0;31m   \u001B[0;32mreturn\u001B[0m \u001B[0mconstant\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mv\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    345\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    346\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\u001B[0m in \u001B[0;36mconstant\u001B[0;34m(value, dtype, shape, name)\u001B[0m\n\u001B[1;32m    266\u001B[0m     \u001B[0mValueError\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mcalled\u001B[0m \u001B[0mon\u001B[0m \u001B[0ma\u001B[0m \u001B[0msymbolic\u001B[0m \u001B[0mtensor\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    267\u001B[0m   \"\"\"\n\u001B[0;32m--> 268\u001B[0;31m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001B[0m\u001B[1;32m    269\u001B[0m                         allow_broadcast=True)\n\u001B[1;32m    270\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\u001B[0m in \u001B[0;36m_constant_impl\u001B[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001B[0m\n\u001B[1;32m    278\u001B[0m       \u001B[0;32mwith\u001B[0m \u001B[0mtrace\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTrace\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"tf.constant\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    279\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0m_constant_eager_impl\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mctx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mshape\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mverify_shape\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 280\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0m_constant_eager_impl\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mctx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mshape\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mverify_shape\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    281\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    282\u001B[0m   \u001B[0mg\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_default_graph\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\u001B[0m in \u001B[0;36m_constant_eager_impl\u001B[0;34m(ctx, value, dtype, shape, verify_shape)\u001B[0m\n\u001B[1;32m    303\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0m_constant_eager_impl\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mctx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mshape\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mverify_shape\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    304\u001B[0m   \u001B[0;34m\"\"\"Creates a constant on the current device.\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 305\u001B[0;31m   \u001B[0mt\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mconvert_to_eager_tensor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvalue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mctx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    306\u001B[0m   \u001B[0;32mif\u001B[0m \u001B[0mshape\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    307\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mt\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\u001B[0m in \u001B[0;36mconvert_to_eager_tensor\u001B[0;34m(value, ctx, dtype)\u001B[0m\n\u001B[1;32m    101\u001B[0m       \u001B[0mdtype\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdtypes\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mas_dtype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mas_datatype_enum\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    102\u001B[0m   \u001B[0mctx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mensure_initialized\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 103\u001B[0;31m   \u001B[0;32mreturn\u001B[0m \u001B[0mops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mEagerTensor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvalue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mctx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdevice_name\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    104\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    105\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(params[\"n_epoch\"]):\n",
    "    loss = []\n",
    "    for i in range(0, X_train.shape[0], params[\"batch_size\"]):\n",
    "        X_batch = X_train[i:i+params[\"batch_size\"]]\n",
    "        y_batch = y_train[i:i+params[\"batch_size\"]]\n",
    "        latent = encoder(X_batch)\n",
    "        mem_x = generate(input_latent=latent, train=True)\n",
    "        mem_pred = classifier(mem_x)\n",
    "        unique_values, counts = np.unique(np.argmax(mem_pred, axis=1), return_counts=True)\n",
    "        for value, count in zip(unique_values, counts):\n",
    "            print(\"Value:\", value, \"Count:\", count)\n",
    "        #print(np.unique(np.argmax(mem_pred, axis=1)))\n",
    "        mem_pred_true = get_one_hot_predictions(mem_pred)\n",
    "        mem_loss = tf.keras.losses.categorical_crossentropy(mem_pred_true, mem_pred)\n",
    "        loss.append(np.mean(mem_loss))\n",
    "        print(np.mean(mem_loss))\n",
    "    print(\"Loss on generate: \",  np.mean(loss))"
   ],
   "metadata": {
    "id": "-o1U9ShTwppe",
    "outputId": "e7223841-642d-4c5f-b4fc-006062648c72",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    }
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "cUWTKjMAyv17"
   },
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": [],
   "machine_shape": "hm",
   "gpuType": "T4",
   "include_colab_link": true
  },
  "accelerator": "GPU",
  "gpuClass": "standard"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
