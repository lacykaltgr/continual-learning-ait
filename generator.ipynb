{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lacykaltgr/continual-learning-ait/blob/experiment/generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-05-10 13:48:43--  https://github.com/lacykaltgr/continual-learning-ait/archive/refs/heads/experiment.zip\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://codeload.github.com/lacykaltgr/continual-learning-ait/zip/refs/heads/experiment [following]\n",
            "--2023-05-10 13:48:43--  https://codeload.github.com/lacykaltgr/continual-learning-ait/zip/refs/heads/experiment\n",
            "Resolving codeload.github.com (codeload.github.com)... 20.205.243.165\n",
            "Connecting to codeload.github.com (codeload.github.com)|20.205.243.165|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘experiment.zip’\n",
            "\n",
            "experiment.zip          [       <=>          ]   1.58M  1.18MB/s    in 1.3s    \n",
            "\n",
            "2023-05-10 13:48:45 (1.18 MB/s) - ‘experiment.zip’ saved [1657860]\n",
            "\n",
            "Archive:  experiment.zip\n",
            "e7e6f0b439c19f52204ca7f0b7b16f0dfdb98b06\n",
            "   creating: continual-learning-ait-experiment/\n",
            "  inflating: continual-learning-ait-experiment/README.md  \n",
            "  inflating: continual-learning-ait-experiment/classifier.ipynb  \n",
            "  inflating: continual-learning-ait-experiment/classifier.py  \n",
            "  inflating: continual-learning-ait-experiment/data_preparation.ipynb  \n",
            "  inflating: continual-learning-ait-experiment/data_preparation.py  \n",
            "  inflating: continual-learning-ait-experiment/generator.ipynb  \n",
            "  inflating: continual-learning-ait-experiment/img.png  \n",
            "  inflating: continual-learning-ait-experiment/main.ipynb  \n",
            "   creating: continual-learning-ait-experiment/models/\n",
            "  inflating: continual-learning-ait-experiment/models/classifier.h5  \n",
            "  inflating: continual-learning-ait-experiment/models/encoder.h5  \n",
            "   creating: continual-learning-ait-experiment/stable_diffusion/\n",
            "  inflating: continual-learning-ait-experiment/stable_diffusion/autoencoder_kl.py  \n",
            "  inflating: continual-learning-ait-experiment/stable_diffusion/constants.py  \n",
            "  inflating: continual-learning-ait-experiment/stable_diffusion/diffusion_model.py  \n",
            "  inflating: continual-learning-ait-experiment/stable_diffusion/layers.py  \n",
            "  inflating: continual-learning-ait-experiment/stable_diffusion/stable_diffusion.py  \n",
            "  inflating: continual-learning-ait-experiment/utils.py  \n",
            "rm: cannot remove 'stable_diffusion': No such file or directory\n",
            "rm: cannot remove 'models': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "'''Download the files '''\n",
        "'''Only for colab'''\n",
        "\n",
        "!wget https://github.com/lacykaltgr/continual-learning-ait/archive/refs/heads/experiment.zip\n",
        "!unzip experiment.zip\n",
        "!find continual-learning-ait-experiment -type f ! -name \"main.ipynb\" -exec cp {} . \\;\n",
        "\n",
        "!rm -r stable_diffusion\n",
        "!rm -r models\n",
        "!mkdir stable_diffusion\n",
        "!mkdir models\n",
        "!mv diffusion_model.py stable_diffusion/\n",
        "!mv autoencoder_kl.py stable_diffusion/\n",
        "!mv layers.py stable_diffusion/\n",
        "!mv stable_diffusion.py stable_diffusion/\n",
        "!mv constants.py stable_diffusion/\n",
        "!mv encoder.h5 models/\n",
        "!mv classifier.h5 models/"
      ],
      "metadata": {
        "id": "FBqbqiHlwppa",
        "outputId": "7fccd050-1e1f-43d3-ea17-83af0798a7ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import numpy as np\n",
        "from stable_diffusion.layers import PaddedConv2D, apply_seq\n",
        "from stable_diffusion.diffusion_model import ResBlock, Downsample, Upsample\n",
        "import math\n",
        "from stable_diffusion.constants import _ALPHAS_CUMPROD, PYTORCH_CKPT_MAPPING"
      ],
      "metadata": {
        "id": "qxtHOYA5wppb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "outputs": [],
      "source": [
        "def load_cifar_10():\n",
        "    (X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "    n_classes = 10\n",
        "    X_train = (X_train / 127.5) -1\n",
        "    X_test = (X_test / 127.5) -1\n",
        "    y_train = tf.keras.utils.to_categorical(y_train, n_classes)\n",
        "    y_test = tf.keras.utils.to_categorical(y_test, n_classes)\n",
        "    return (X_train, y_train), (X_test, y_test)"
      ],
      "metadata": {
        "id": "9cDXrVOHwppb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "collapsed": true,
        "id": "0MPVDCr_wppc",
        "outputId": "ed07a447-b007-48f0-d15f-fab485aa3bcd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        }
      ],
      "source": [
        "encoder = load_model(\"models/encoder.h5\")\n",
        "classifier = load_model(\"models/classifier.h5\")\n",
        "\n",
        "encoder.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=5e-3),\n",
        "    loss=keras.losses.CategoricalCrossentropy(),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "classifier.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=5e-3),\n",
        "    loss=keras.losses.CategoricalCrossentropy(),\n",
        "    metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "outputs": [],
      "source": [
        "class UNetModel(keras.Model):\n",
        "    def __init__(self):\n",
        "        print(\"UNetModel init\")\n",
        "        super().__init__()\n",
        "        self.img_height = 32\n",
        "        self.img_width = 32\n",
        "        self.ntype = tf.float32\n",
        "        self.time_embed = [\n",
        "            keras.layers.Dense(128),\n",
        "            keras.activations.swish,\n",
        "            keras.layers.Dense(128),\n",
        "        ]\n",
        "        self.input_blocks = [\n",
        "            [PaddedConv2D(32, kernel_size=3, padding=1)],\n",
        "            [ResBlock(32, 32)],\n",
        "            [ResBlock(32, 32)],\n",
        "            [Downsample(32)],\n",
        "            [ResBlock(32, 64)], #, Conv2D(640, kernel_size=8, padding=\"same\")],\n",
        "            [ResBlock(64, 64)], #, Conv2D(640, kernel_size=8, padding=\"same\")],\n",
        "            [Downsample(64)],\n",
        "            [ResBlock(64, 128)], #, Conv2D(1280, kernel_size=8, padding=\"same\")],\n",
        "            [ResBlock(128, 128)], #, Conv2D(1280, kernel_size=8, padding=\"same\")],\n",
        "            [Downsample(128)],\n",
        "            [ResBlock(128, 128)],\n",
        "            [ResBlock(128, 128)],\n",
        "        ]\n",
        "        self.middle_block = [\n",
        "            ResBlock(64, 64),\n",
        "            #Conv2D(1280, kernel_size=8, padding=\"same\"),\n",
        "            ResBlock(64, 64),\n",
        "        ]\n",
        "        self.output_blocks = [\n",
        "            [ResBlock(256, 128)],\n",
        "            [ResBlock(256, 128)],\n",
        "            [ResBlock(256, 128), Upsample(128)],\n",
        "            [ResBlock(256, 128)], #, Conv2D(1280, kernel_size=8, padding=\"same\")],\n",
        "            [ResBlock(256, 128)], #, Conv2D(1280, kernel_size=8, padding=\"same\")],\n",
        "            [\n",
        "                ResBlock(192, 128),\n",
        "                #Conv2D(1280, kernel_size=8, padding=\"same\"),\n",
        "                Upsample(128),\n",
        "            ],\n",
        "            [ResBlock(192, 64)], #, Conv2D(640, kernel_size=8, padding=\"same\")],  # 6\n",
        "            [ResBlock(128, 64)], #, Conv2D(640, kernel_size=8, padding=\"same\")],\n",
        "            [\n",
        "                ResBlock(96, 64),\n",
        "                #Conv2D(640, kernel_size=8, padding=\"same\"),\n",
        "                Upsample(64),\n",
        "            ],\n",
        "            [ResBlock(96, 32)], #, Conv2D(320, kernel_size=8, padding=\"same\")],\n",
        "            [ResBlock(64, 32)], #, Conv2D(320, kernel_size=8, padding=\"same\")],\n",
        "            [ResBlock(64, 32)], #, Conv2D(320, kernel_size=8, padding=\"same\")],\n",
        "        ]\n",
        "        self.out = [\n",
        "            keras.layers.GroupNormalization(epsilon=1e-5),\n",
        "            keras.activations.swish,\n",
        "            PaddedConv2D(8, kernel_size=3, padding=1),\n",
        "        ]\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x, t_emb = inputs\n",
        "        emb = apply_seq(t_emb, self.time_embed)\n",
        "\n",
        "        def apply(x, layer):\n",
        "            return layer([x, emb]) if isinstance(layer, ResBlock) else layer(x)\n",
        "\n",
        "        saved_inputs = []\n",
        "        for b in self.input_blocks:\n",
        "            for layer in b:\n",
        "                x = apply(x, layer)\n",
        "            saved_inputs.append(x)\n",
        "\n",
        "        for layer in self.middle_block:\n",
        "            x = apply(x, layer)\n",
        "\n",
        "        for b in self.output_blocks:\n",
        "            x = tf.concat([x, saved_inputs.pop()], axis=-1)\n",
        "            for layer in b:\n",
        "                x = apply(x, layer)\n",
        "\n",
        "        return apply_seq(x, self.out)\n",
        "\n",
        "    def initialize(self, params, input_latent=None, batch_size=64):\n",
        "        timesteps = np.arange(1, params['num_steps']+ 1)\n",
        "        input_lat_noise_t = timesteps[int(len(timesteps)* params[\"input_latent_strength\"])]\n",
        "        latent, alphas, alphas_prev = self.get_starting_parameters(\n",
        "            timesteps, batch_size, input_latent=input_latent, input_lat_noise_t=input_lat_noise_t\n",
        "        )\n",
        "        timesteps = timesteps[: int(len(timesteps)*params[\"input_latent_strength\"])]\n",
        "        return latent, alphas, alphas_prev, timesteps\n",
        "\n",
        "\n",
        "    def get_x_prev(self, x, e_t, a_t, a_prev, temperature):\n",
        "        sigma_t = 0\n",
        "        sqrt_one_minus_at = math.sqrt(1 - a_t)\n",
        "        pred_x0 = x - sqrt_one_minus_at * e_t / math.sqrt(a_t)\n",
        "\n",
        "        # Direction pointing to x_t\n",
        "        dir_xt = math.sqrt(1.0 - a_prev - sigma_t**2) * e_t\n",
        "        #noise = sigma_t * tf.random.normal(x.shape, seed=seed) * temperature\n",
        "        x_prev = math.sqrt(a_prev) * pred_x0 + dir_xt\n",
        "        return x_prev\n",
        "\n",
        "\n",
        "    def get_model_output(self, latent, timestep, batch_size):\n",
        "        timesteps = tf.convert_to_tensor([timestep], dtype=tf.float32)\n",
        "        t_emb = self.timestep_embedding(timesteps)\n",
        "        t_emb = tf.repeat(t_emb, repeats=batch_size, axis=0)\n",
        "        latent = self.call([latent, t_emb])\n",
        "        return latent\n",
        "\n",
        "\n",
        "    def timestep_embedding(self, timesteps, dim=320, max_period=10000):\n",
        "        half = dim // 2\n",
        "        freqs = np.exp(\n",
        "            -math.log(max_period) * np.arange(0, half, dtype=\"float32\") / half\n",
        "        )\n",
        "        args = np.array(timesteps) * freqs\n",
        "        embedding = np.concatenate([np.cos(args), np.sin(args)])\n",
        "        return tf.convert_to_tensor(embedding.reshape(1, -1), dtype=self.ntype)\n",
        "\n",
        "\n",
        "\n",
        "    # for model with input latent\n",
        "\n",
        "    def add_noise(self, x, t, noise=None):\n",
        "        if len(x.shape) == 3:\n",
        "            x = tf.expand_dims(x, axis=0)\n",
        "        batch_size, w, h, c = x.shape[0], x.shape[1], x.shape[2], x.shape[3]\n",
        "        if noise is None:\n",
        "            noise = tf.random.normal((batch_size, w, h, c), dtype=tf.float32)\n",
        "        sqrt_alpha_prod = tf.cast(_ALPHAS_CUMPROD[t] ** 0.5, tf.float32)\n",
        "        sqrt_one_minus_alpha_prod = (1 - _ALPHAS_CUMPROD[t]) ** 0.5\n",
        "\n",
        "        return sqrt_alpha_prod * x + sqrt_one_minus_alpha_prod * noise\n",
        "\n",
        "    def get_starting_parameters(self, timesteps, batch_size,  input_latent=None, input_lat_noise_t=None):\n",
        "        n_h = self.img_height // 8\n",
        "        n_w = self.img_width // 8\n",
        "        alphas = [_ALPHAS_CUMPROD[t] for t in timesteps]\n",
        "        alphas_prev = [1.0] + alphas[:-1]\n",
        "        if input_latent is None:\n",
        "            latent = tf.random.normal((batch_size, n_h, n_w, 8))\n",
        "        else:\n",
        "            input_latent = tf.cast(input_latent, self.ntype)\n",
        "            #latent = tf.repeat(input_latent , batch_size , axis=0)\n",
        "            latent = self.add_noise(input_latent, input_lat_noise_t)\n",
        "        return latent, alphas, alphas_prev\n"
      ],
      "metadata": {
        "id": "TY9yVQKwwppc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_one_hot_predictions(mem_pred):\n",
        "    max_indices = np.argmax(mem_pred, axis=1)  # Find the indices of the maximum probabilities along axis 1\n",
        "    num_classes = mem_pred.shape[1]  # Get the number of classes\n",
        "\n",
        "    # Create an array of zeros with the same number of rows as mem_pred and num_classes columns\n",
        "    mem_true = np.zeros_like(mem_pred)\n",
        "\n",
        "    # Set the value at the corresponding max_indices positions to 1\n",
        "    mem_true[np.arange(len(max_indices)), max_indices] = 1\n",
        "\n",
        "    return mem_true"
      ],
      "metadata": {
        "id": "OvZ3J9SG1kj0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "outputs": [],
      "source": [
        "'''Generate samples and train the diffusion model at the same time'''\n",
        "\n",
        "def generate(cls=classifier, input_latent=None, train=True, coeff=1.0):\n",
        "\n",
        "    batch_size = params['batch_size'] if train else 64\n",
        "    latent, alphas, alphas_prev, timesteps = model.initialize(params, input_latent, batch_size)\n",
        "\n",
        "\n",
        "    for index, timestep in reversed(list(enumerate(timesteps))):\n",
        "        if train:\n",
        "            with tf.GradientTape() as tape:\n",
        "                e_t = model.get_model_output(\n",
        "                    latent,\n",
        "                    timestep,\n",
        "                    batch_size,\n",
        "                )\n",
        "                a_t, a_prev = alphas[index], alphas_prev[index]\n",
        "                latent = model.get_x_prev(latent, e_t,  a_t, a_prev, params[\"temperature\"])\n",
        "\n",
        "                pred = cls(latent)\n",
        "                #loss based on confidence\n",
        "                #ENT = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_pre, logits=y_pre))\n",
        "                loss = coeff*tf.keras.losses.categorical_crossentropy(pred, pred)\n",
        "            grads = tape.gradient(loss, model.trainable_variables)\n",
        "            tf.keras.optimizers.legacy.Adam(learning_rate=params[\"gen_lr\"]).apply_gradients(zip(grads, model.trainable_variables))\n",
        "        else:\n",
        "            e_t = model.get_model_output(\n",
        "                latent,\n",
        "                timestep,\n",
        "                batch_size,\n",
        "            )\n",
        "            a_t, a_prev = alphas[index], alphas_prev[index]\n",
        "            latent = model.get_x_prev(latent, e_t,  a_t, a_prev, params[\"temperature\"])\n",
        "\n",
        "    return latent"
      ],
      "metadata": {
        "id": "n0nileU3wppd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ndef run_gen_epoch():\\n\\n\\n    for i, (data, target) in tqdm(enumerate(agent.state[\"tr_loader\"])):\\n        #if agent.state[\"sample_amt\"] > agent.params[\"samples_per_task\"] > 0: break\\n        if data.shape[0] != batch_size: break\\n        agent.state[\"sample_amt\"] += data.shape[0]\\n\\n        agent.state[\"data\"] = data\\n        agent.state[\"target\"] = target\\n        agent.state[\"i_example\"] = i\\n\\n        data = agent.state[\"data\"]\\n        latent = agent.gen.encoder(data)\\n        mem_x = None\\n\\n        for it in range(agent.params[\"gen_iters\"]):\\n            generate(agent, input_latent=latent)\\n    if agent.state[\"epoch\"] % agent.params[\"print_every\"] == 0:\\n\\n        print(\"\\nEvaluate generator on Task: \", agent.state[\"task\"], \" Epoch: \", agent.state[\"epoch\"])\\n        loss = []\\n        for i, (data, target) in tqdm(enumerate(agent.state[\"ts_loader\"])):\\n\\n            mem_x = generate(agent, input_latent=agent.encoder(data), train=False)\\n            mem_pred = agent.cls(mem_x)\\n            mem_loss = tf.keras.losses.categorical_crossentropy(mem_pred, mem_pred)\\n            loss.append(np.mean(mem_loss))\\n\\n        print(\"Loss on generate: \",  np.mean(mem_loss))\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "'''\n",
        "def run_gen_epoch():\n",
        "\n",
        "\n",
        "    for i, (data, target) in tqdm(enumerate(agent.state[\"tr_loader\"])):\n",
        "        #if agent.state[\"sample_amt\"] > agent.params[\"samples_per_task\"] > 0: break\n",
        "        if data.shape[0] != batch_size: break\n",
        "        agent.state[\"sample_amt\"] += data.shape[0]\n",
        "\n",
        "        agent.state[\"data\"] = data\n",
        "        agent.state[\"target\"] = target\n",
        "        agent.state[\"i_example\"] = i\n",
        "\n",
        "        data = agent.state[\"data\"]\n",
        "        latent = agent.gen.encoder(data)\n",
        "        mem_x = None\n",
        "\n",
        "        for it in range(agent.params[\"gen_iters\"]):\n",
        "            generate(agent, input_latent=latent)\n",
        "    if agent.state[\"epoch\"] % agent.params[\"print_every\"] == 0:\n",
        "\n",
        "        print(\"\\nEvaluate generator on Task: \", agent.state[\"task\"], \" Epoch: \", agent.state[\"epoch\"])\n",
        "        loss = []\n",
        "        for i, (data, target) in tqdm(enumerate(agent.state[\"ts_loader\"])):\n",
        "\n",
        "            mem_x = generate(agent, input_latent=agent.encoder(data), train=False)\n",
        "            mem_pred = agent.cls(mem_x)\n",
        "            mem_loss = tf.keras.losses.categorical_crossentropy(mem_pred, mem_pred)\n",
        "            loss.append(np.mean(mem_loss))\n",
        "\n",
        "        print(\"Loss on generate: \",  np.mean(mem_loss))\n",
        "'''"
      ],
      "metadata": {
        "id": "1jelThWIwppd",
        "outputId": "eb4d266c-deaf-4260-8e1e-803ac04f1313",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "UNetModel init\n"
          ]
        }
      ],
      "source": [
        "model = UNetModel()"
      ],
      "metadata": {
        "id": "8IXX3Srqwppe",
        "outputId": "63f71ea3-f522-407f-ae92-9763c71c4443",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "outputs": [],
      "source": [
        "params = {\n",
        "    \"num_steps\": 2,\n",
        "    \"input_latent_strength\":0.8,\n",
        "    \"temperature\": 0.9,\n",
        "    \"batch_size\": 256,\n",
        "    \"gen_lr\": 2e-5,\n",
        "    \"n_epoch\": 3,\n",
        "}"
      ],
      "metadata": {
        "id": "xI76KdNbwppe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 13s 0us/step\n"
          ]
        }
      ],
      "source": [
        "(X_train, y_train), (X_test, y_test) = load_cifar_10()"
      ],
      "metadata": {
        "id": "hAdxt2bYwppe",
        "outputId": "0dbf7e81-6290-456b-e8ef-1a525320d10b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-279800e0dba5>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"batch_size\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mlatent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mmem_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_latent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlatent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mmem_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmem_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mmem_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategorical_crossentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmem_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmem_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-d0392c4c2fbf>\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(cls, input_latent, train, coeff)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                 e_t = model.get_model_output(\n\u001b[0m\u001b[1;32m     13\u001b[0m                     \u001b[0mlatent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mtimestep\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-f53390578d52>\u001b[0m in \u001b[0;36mget_model_output\u001b[0;34m(self, latent, timestep, batch_size)\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0mt_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimestep_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimesteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mt_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepeats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mlatent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlatent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_emb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlatent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-f53390578d52>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmiddle_block\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_blocks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-f53390578d52>\u001b[0m in \u001b[0;36mapply\u001b[0;34m(x, layer)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mResBlock\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0msaved_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/stable_diffusion/diffusion_model.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0memb_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskip_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Exception encountered when calling layer 'res_block_76' (type ResBlock).\n\n{{function_node __wrapped__AddV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} required broadcastable shapes [Op:AddV2]\n\nCall arguments received by layer 'res_block_76' (type ResBlock):\n  • inputs=['tf.Tensor(shape=(256, 1, 1, 128), dtype=float32)', 'tf.Tensor(shape=(256, 128), dtype=float32)']"
          ]
        }
      ],
      "source": [
        "for epoch in range(params[\"n_epoch\"]):\n",
        "    loss = []\n",
        "    for i in range(0, X_train.shape[0], params[\"batch_size\"]):\n",
        "        X_batch = X_train[i:i+params[\"batch_size\"]]\n",
        "        y_batch = y_train[i:i+params[\"batch_size\"]]\n",
        "        latent = encoder(X_batch)\n",
        "        mem_x = generate(input_latent=latent, train=True)\n",
        "        mem_pred = classifier(mem_x)\n",
        "        mem_loss = tf.keras.losses.categorical_crossentropy(mem_pred, mem_pred)\n",
        "        loss.append(np.mean(mem_loss))\n",
        "    print(\"Loss on generate: \",  np.mean(loss))"
      ],
      "metadata": {
        "id": "-o1U9ShTwppe",
        "outputId": "ad1aaa39-fb04-4757-e4fe-2fdb5d8391e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RXsGiESrBsK-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}