{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/lacykaltgr/continual-learning-ait/blob/experiment/classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "'''Download the files '''\n",
    "'''Only for colab'''\n",
    "\n",
    "!wget https://github.com/lacykaltgr/continual-learning-ait/archive/refs/heads/main.zip\n",
    "!unzip main.zip\n",
    "!find continual-learning-ait-main -type f ! -name \"main.ipynb\" -exec cp {} . \\;\n",
    "\n",
    "!rm -r stable_diffusion\n",
    "!mkdir stable_diffusion\n",
    "!mv diffusion_model.py stable_diffusion/\n",
    "!mv autoencoder_kl.py stable_diffusion/\n",
    "!mv layers.py stable_diffusion/\n",
    "!mv stable_diffusion.py stable_diffusion/\n",
    "!mv constants.py stable_diffusion/"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_yX0QZ7RSFWx",
    "outputId": "f9bba196-9653-4953-fcde-9ff9636605f8"
   },
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--2023-05-10 12:40:01--  https://github.com/lacykaltgr/continual-learning-ait/archive/refs/heads/main.zip\n",
      "Resolving github.com (github.com)... 140.82.114.3\n",
      "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://codeload.github.com/lacykaltgr/continual-learning-ait/zip/refs/heads/main [following]\n",
      "--2023-05-10 12:40:02--  https://codeload.github.com/lacykaltgr/continual-learning-ait/zip/refs/heads/main\n",
      "Resolving codeload.github.com (codeload.github.com)... 140.82.112.10\n",
      "Connecting to codeload.github.com (codeload.github.com)|140.82.112.10|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [application/zip]\n",
      "Saving to: ‘main.zip’\n",
      "\n",
      "main.zip                [ <=>                ] 338.93K  --.-KB/s    in 0.05s   \n",
      "\n",
      "2023-05-10 12:40:02 (6.55 MB/s) - ‘main.zip’ saved [347065]\n",
      "\n",
      "Archive:  main.zip\n",
      "4e98f3b1d72a496ef351c2ffa7a12a2d9dddf2d8\n",
      "   creating: continual-learning-ait-main/\n",
      "  inflating: continual-learning-ait-main/README.md  \n",
      "  inflating: continual-learning-ait-main/classifier.py  \n",
      "  inflating: continual-learning-ait-main/data_preparation.ipynb  \n",
      "  inflating: continual-learning-ait-main/data_preparation.py  \n",
      "  inflating: continual-learning-ait-main/img.png  \n",
      "  inflating: continual-learning-ait-main/main.ipynb  \n",
      "   creating: continual-learning-ait-main/stable_diffusion/\n",
      "  inflating: continual-learning-ait-main/stable_diffusion/autoencoder_kl.py  \n",
      "  inflating: continual-learning-ait-main/stable_diffusion/constants.py  \n",
      "  inflating: continual-learning-ait-main/stable_diffusion/diffusion_model.py  \n",
      "  inflating: continual-learning-ait-main/stable_diffusion/layers.py  \n",
      "  inflating: continual-learning-ait-main/stable_diffusion/stable_diffusion.py  \n",
      "  inflating: continual-learning-ait-main/utils.py  \n",
      "rm: cannot remove 'stable_diffusion': No such file or directory\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from stable_diffusion.layers import PaddedConv2D\n",
    "from stable_diffusion.autoencoder_kl import ResnetBlock, AttentionBlock\n",
    "from classifier import GatedDense\n",
    "from data_preparation import load_dataset, CLDataLoader\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import layers\n",
    "from keras.layers import Conv2D, MaxPool2D, Dropout, Dense, Activation, Flatten, BatchNormalization, Conv2DTranspose, UpSampling2D, ZeroPadding2D\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ],
   "metadata": {
    "id": "CsbKdzP0R02W"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def load_cifar_10():\n",
    "    (X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "    n_classes = 10\n",
    "    X_train = (X_train / 127.5) -1\n",
    "    X_test = (X_test / 127.5) -1\n",
    "    y_train = tf.keras.utils.to_categorical(y_train, n_classes)\n",
    "    y_test = tf.keras.utils.to_categorical(y_test, n_classes)\n",
    "    return (X_train, y_train), (X_test, y_test)"
   ],
   "metadata": {
    "id": "u_gDvSEFR02X"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "dpt_train, dpt_test = load_dataset('cifar-10', n_classes_first_task=4, n_classes_other_task=3)\n",
    "batch_size = 512\n",
    "train_loader = CLDataLoader(dpt_train, batch_size , train=True)\n",
    "test_loader = CLDataLoader(dpt_test, batch_size, train=False)\n",
    "INPUT_SHAPE = (32, 32, 3)\n",
    "KERNEL_SIZE = (3, 3)"
   ],
   "metadata": {
    "id": "Mcuhy4BPvEPz",
    "outputId": "54e03dba-01d6-45a8-96b9-af61fc063ca8",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170498071/170498071 [==============================] - 9s 0us/step\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#Encoder"
   ],
   "metadata": {
    "id": "fnOeY888uL1L"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "encoder = keras.Sequential()\n",
    "\n",
    "encoder.add(Conv2D(filters=32, kernel_size=KERNEL_SIZE, input_shape=INPUT_SHAPE, activation='relu', padding='same'))\n",
    "encoder.add(BatchNormalization())\n",
    "encoder.add(Conv2D(filters=32, kernel_size=KERNEL_SIZE, input_shape=INPUT_SHAPE, activation='relu', padding='same'))\n",
    "encoder.add(BatchNormalization())\n",
    "encoder.add(MaxPool2D(pool_size=(2, 2)))\n",
    "encoder.add(Dropout(0.25))\n",
    "\n",
    "encoder.add(Conv2D(filters=64, kernel_size=KERNEL_SIZE, input_shape=INPUT_SHAPE, activation='relu', padding='same'))\n",
    "encoder.add(BatchNormalization())\n",
    "encoder.add(Conv2D(filters=64, kernel_size=KERNEL_SIZE, input_shape=INPUT_SHAPE, activation='relu', padding='same'))\n",
    "encoder.add(BatchNormalization())\n",
    "encoder.add(MaxPool2D(pool_size=(2, 2)))\n",
    "encoder.add(Dropout(0.25))\n",
    "\n",
    "encoder.add(Conv2D(filters=128, kernel_size=KERNEL_SIZE, input_shape=INPUT_SHAPE, activation='relu', padding='same'))\n",
    "encoder.add(BatchNormalization())\n",
    "encoder.add(Conv2D(filters=128, kernel_size=KERNEL_SIZE, input_shape=INPUT_SHAPE, activation='relu', padding='same'))\n",
    "encoder.add(BatchNormalization())\n",
    "encoder.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "encoder.add(keras.layers.GroupNormalization(epsilon=1e-5)),\n",
    "encoder.add(keras.layers.Activation(\"swish\")),\n",
    "encoder.add(ZeroPadding2D((1, 1)))\n",
    "encoder.add(Conv2D(16, 3, strides=(1, 1)))\n",
    "encoder.add(ZeroPadding2D((1, 1)))\n",
    "encoder.add(Conv2D(8, 1, strides=(1, 1)))"
   ],
   "metadata": {
    "id": "ZoikW_9Wu_MA"
   },
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "#trainable parameters: 307640\n"
     ]
    }
   ],
   "source": [
    "print(\"#trainable parameters:\",encoder.count_params())"
   ],
   "metadata": {
    "id": "q9JxCUAkrIqd",
    "outputId": "8fadf903-3f41-4001-f927-9ae22ae3ee18",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#Classifier"
   ],
   "metadata": {
    "id": "Q9X7h2t2uNOd"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "classifier = keras.Sequential()\n",
    "\n",
    "classifier.add(Flatten())\n",
    "classifier.add(Dropout(0.2))\n",
    "classifier.add(Dense(128, activation='relu'))\n",
    "classifier.add(Dropout(0.25))\n",
    "classifier.add(Dense(10, activation='softmax'))"
   ],
   "metadata": {
    "id": "6VIQzIOYvO6q"
   },
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#Decoder"
   ],
   "metadata": {
    "id": "3FJSZP2fuPfP"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "decoder = keras.Sequential()\n",
    "\n",
    "\n",
    "decoder.add(Conv2DTranspose(filters=128, kernel_size=KERNEL_SIZE, activation='relu', padding='same'))\n",
    "decoder.add(BatchNormalization())\n",
    "decoder.add(Conv2DTranspose(filters=128, kernel_size=KERNEL_SIZE, activation='relu', padding='same'))\n",
    "decoder.add(BatchNormalization())\n",
    "decoder.add(UpSampling2D(size=(2, 2)))\n",
    "\n",
    "decoder.add(Conv2DTranspose(filters=64, kernel_size=KERNEL_SIZE, activation='relu', padding='same'))\n",
    "decoder.add(BatchNormalization())\n",
    "decoder.add(Conv2DTranspose(filters=64, kernel_size=KERNEL_SIZE, activation='relu', padding='same'))\n",
    "decoder.add(BatchNormalization())\n",
    "decoder.add(UpSampling2D(size=(2, 2)))\n",
    "\n",
    "decoder.add(Conv2DTranspose(filters=32, kernel_size=KERNEL_SIZE, activation='relu', padding='same'))\n",
    "decoder.add(BatchNormalization())\n",
    "decoder.add(Conv2DTranspose(filters=32, kernel_size=KERNEL_SIZE, activation='relu', padding='same'))\n",
    "decoder.add(BatchNormalization())\n",
    "decoder.add(UpSampling2D(size=(2, 2)))\n",
    "\n",
    "decoder.add(keras.layers.GroupNormalization(epsilon=1e-5)),\n",
    "decoder.add(keras.layers.Activation(\"swish\")),\n",
    "decoder.add(Conv2DTranspose(16, 3, padding='same' )),\n",
    "decoder.add(Conv2DTranspose(3, 1, activation='sigmoid'))"
   ],
   "metadata": {
    "id": "1DEnb9cMR02Y"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "input_image = keras.Input(shape=(32, 32, 3), name=\"image\")\n",
    "encoded = encoder(input_image)\n",
    "decoded = decoder(encoded)\n",
    "classified = classifier(encoded)\n"
   ],
   "metadata": {
    "id": "NB5a8lY6vjE2"
   },
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#encoder_decoder = keras.Model(inputs = input_image, outputs = decoded)\n",
    "#encoder_decoder.compile(\n",
    "#    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "#    loss='mse',\n",
    "#)"
   ],
   "metadata": {
    "id": "CF9Cufva5RpX"
   },
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "encoder_classifier = keras.Model(inputs = input_image, outputs = classified)\n",
    "encoder_classifier.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=5e-3),\n",
    "    loss=keras.losses.CategoricalCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")"
   ],
   "metadata": {
    "id": "WaIiWeNaxWzv"
   },
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "es1 = EarlyStopping(patience=1, monitor=\"val_loss\")\n",
    "es2 = EarlyStopping(patience=10, monitor=\"val_loss\", restore_best_weights=True)"
   ],
   "metadata": {
    "id": "M1aStwXSc6Jr"
   },
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#encoder_decoder.fit(X_train, X_train, batch_size=64, epochs=3, validation_data=(X_test, X_test), callbacks=[es1])"
   ],
   "metadata": {
    "id": "FMxMVH78x8hX"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#Training"
   ],
   "metadata": {
    "id": "QfDmTHsxuSzC"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "prev_test = None\n",
    "for (tr_loader, ts_loader) in zip(train_loader, test_loader):\n",
    "  for epoch in range(5):\n",
    "    for ((data, target) ,(testdata, testtarget)) in zip(tr_loader, ts_loader):\n",
    "      encoder_classifier.fit(data, target, epochs=1, validation_data=(testdata, testtarget), callbacks=[es2])\n",
    "  if (prev_test is not None):\n",
    "    for (testdata, testtarget) in prev_test:\n",
    "        encoder_classifier.evaluate(testdata, testtarget)\n",
    "  prev_test = ts_loader\n",
    "  print('\\n\\nNew Task')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mQBn1Kh5So48",
    "outputId": "1be78f03-b001-4189-baf4-b6aae685932e"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "16/16 [==============================] - 2s 35ms/step - loss: 1.5011 - accuracy: 0.4883 - val_loss: 1.6639 - val_accuracy: 0.4062\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.1074 - accuracy: 0.5859 - val_loss: 1.2874 - val_accuracy: 0.4844\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.0195 - accuracy: 0.5566 - val_loss: 0.9717 - val_accuracy: 0.5781\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.7122 - accuracy: 0.6699 - val_loss: 1.6245 - val_accuracy: 0.5156\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.7228 - accuracy: 0.6914 - val_loss: 2.6585 - val_accuracy: 0.3438\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.6780 - accuracy: 0.6543 - val_loss: 3.8500 - val_accuracy: 0.2969\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.6835 - accuracy: 0.6758 - val_loss: 3.0948 - val_accuracy: 0.2812\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.6991 - accuracy: 0.6914 - val_loss: 1.7921 - val_accuracy: 0.3438\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.7469 - accuracy: 0.6797 - val_loss: 2.1788 - val_accuracy: 0.3594\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.6599 - accuracy: 0.7227 - val_loss: 1.3805 - val_accuracy: 0.5625\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.6587 - accuracy: 0.7012 - val_loss: 2.0450 - val_accuracy: 0.4375\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.5792 - accuracy: 0.7520 - val_loss: 1.2312 - val_accuracy: 0.4844\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.5511 - accuracy: 0.7539 - val_loss: 1.1631 - val_accuracy: 0.5000\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.5221 - accuracy: 0.7598 - val_loss: 1.3721 - val_accuracy: 0.4844\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.5832 - accuracy: 0.7383 - val_loss: 1.9236 - val_accuracy: 0.5000\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.6024 - accuracy: 0.7246 - val_loss: 1.4060 - val_accuracy: 0.4219\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.6123 - accuracy: 0.7441 - val_loss: 1.0942 - val_accuracy: 0.5781\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.5432 - accuracy: 0.7715 - val_loss: 0.4631 - val_accuracy: 0.8125\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.5691 - accuracy: 0.7559 - val_loss: 1.1744 - val_accuracy: 0.6719\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.6317 - accuracy: 0.7109 - val_loss: 0.6392 - val_accuracy: 0.7188\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.5125 - accuracy: 0.7734 - val_loss: 0.5670 - val_accuracy: 0.7656\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.5455 - accuracy: 0.7520 - val_loss: 0.4912 - val_accuracy: 0.8125\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.5494 - accuracy: 0.7500 - val_loss: 0.9739 - val_accuracy: 0.5781\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.5505 - accuracy: 0.7578 - val_loss: 0.5025 - val_accuracy: 0.7344\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.4997 - accuracy: 0.7695 - val_loss: 0.4374 - val_accuracy: 0.8125\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.5485 - accuracy: 0.7520 - val_loss: 0.5954 - val_accuracy: 0.7188\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.4746 - accuracy: 0.8145 - val_loss: 0.6732 - val_accuracy: 0.7188\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.5292 - accuracy: 0.7832 - val_loss: 0.5758 - val_accuracy: 0.7969\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.5410 - accuracy: 0.7949 - val_loss: 0.7261 - val_accuracy: 0.6719\n",
      "5/5 [==============================] - 1s 23ms/step - loss: 0.5629 - accuracy: 0.7566 - val_loss: 0.5481 - val_accuracy: 0.7344\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.4198 - accuracy: 0.8203 - val_loss: 0.5167 - val_accuracy: 0.7656\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.5294 - accuracy: 0.7949 - val_loss: 0.7598 - val_accuracy: 0.6250\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.5292 - accuracy: 0.7461 - val_loss: 0.5027 - val_accuracy: 0.7812\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.4621 - accuracy: 0.8184 - val_loss: 0.5687 - val_accuracy: 0.7656\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.4656 - accuracy: 0.8125 - val_loss: 0.3941 - val_accuracy: 0.8438\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.4696 - accuracy: 0.7969 - val_loss: 0.5700 - val_accuracy: 0.8281\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.5843 - accuracy: 0.7559 - val_loss: 0.6456 - val_accuracy: 0.7969\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.4598 - accuracy: 0.7949 - val_loss: 0.7291 - val_accuracy: 0.7656\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.5508 - accuracy: 0.7734 - val_loss: 0.4750 - val_accuracy: 0.7500\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.4360 - accuracy: 0.8262 - val_loss: 0.4994 - val_accuracy: 0.8281\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.4096 - accuracy: 0.8301 - val_loss: 0.5928 - val_accuracy: 0.7344\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.4888 - accuracy: 0.8047 - val_loss: 0.6565 - val_accuracy: 0.6875\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.4401 - accuracy: 0.8105 - val_loss: 0.4833 - val_accuracy: 0.7812\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.4326 - accuracy: 0.8281 - val_loss: 0.6372 - val_accuracy: 0.7344\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.4397 - accuracy: 0.8145 - val_loss: 0.5081 - val_accuracy: 0.8125\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.4390 - accuracy: 0.7988 - val_loss: 0.3661 - val_accuracy: 0.8438\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.4767 - accuracy: 0.7871 - val_loss: 0.3225 - val_accuracy: 0.8750\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3738 - accuracy: 0.8281 - val_loss: 0.3376 - val_accuracy: 0.8438\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.4726 - accuracy: 0.8223 - val_loss: 0.7907 - val_accuracy: 0.7031\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.5384 - accuracy: 0.7598 - val_loss: 0.4668 - val_accuracy: 0.7969\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.4267 - accuracy: 0.8301 - val_loss: 0.5368 - val_accuracy: 0.7344\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.4651 - accuracy: 0.8145 - val_loss: 0.3527 - val_accuracy: 0.8594\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.4427 - accuracy: 0.8262 - val_loss: 0.3296 - val_accuracy: 0.8906\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.4356 - accuracy: 0.8164 - val_loss: 0.4534 - val_accuracy: 0.7812\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.4250 - accuracy: 0.8320 - val_loss: 0.2899 - val_accuracy: 0.9062\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.4576 - accuracy: 0.7891 - val_loss: 0.4543 - val_accuracy: 0.8125\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3961 - accuracy: 0.8418 - val_loss: 0.5252 - val_accuracy: 0.8125\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.4115 - accuracy: 0.8359 - val_loss: 0.4539 - val_accuracy: 0.7500\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.4577 - accuracy: 0.8008 - val_loss: 0.5188 - val_accuracy: 0.7500\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.3847 - accuracy: 0.8158 - val_loss: 0.4107 - val_accuracy: 0.8125\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3824 - accuracy: 0.8359 - val_loss: 0.4906 - val_accuracy: 0.8125\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.4253 - accuracy: 0.8301 - val_loss: 0.4389 - val_accuracy: 0.7656\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.4202 - accuracy: 0.8301 - val_loss: 0.3151 - val_accuracy: 0.8438\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.4151 - accuracy: 0.8281 - val_loss: 0.4277 - val_accuracy: 0.7812\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3991 - accuracy: 0.8398 - val_loss: 0.2624 - val_accuracy: 0.8906\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.3923 - accuracy: 0.8262 - val_loss: 0.3342 - val_accuracy: 0.8594\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.4281 - accuracy: 0.8145 - val_loss: 0.2655 - val_accuracy: 0.8906\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3777 - accuracy: 0.8535 - val_loss: 0.6830 - val_accuracy: 0.7656\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.4136 - accuracy: 0.8359 - val_loss: 0.4540 - val_accuracy: 0.8281\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3554 - accuracy: 0.8535 - val_loss: 0.2880 - val_accuracy: 0.8906\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3391 - accuracy: 0.8574 - val_loss: 0.5934 - val_accuracy: 0.7812\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.3791 - accuracy: 0.8555 - val_loss: 0.5779 - val_accuracy: 0.7344\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3385 - accuracy: 0.8594 - val_loss: 0.4876 - val_accuracy: 0.8281\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3649 - accuracy: 0.8535 - val_loss: 0.3579 - val_accuracy: 0.8750\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3973 - accuracy: 0.8555 - val_loss: 0.3849 - val_accuracy: 0.8281\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.4184 - accuracy: 0.8496 - val_loss: 0.3795 - val_accuracy: 0.8281\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.4107 - accuracy: 0.8125 - val_loss: 0.2918 - val_accuracy: 0.8906\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.3426 - accuracy: 0.8750 - val_loss: 0.3300 - val_accuracy: 0.8438\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.4084 - accuracy: 0.8398 - val_loss: 0.5427 - val_accuracy: 0.7969\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.4626 - accuracy: 0.8105 - val_loss: 0.4152 - val_accuracy: 0.8125\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3535 - accuracy: 0.8555 - val_loss: 0.4408 - val_accuracy: 0.7969\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.3707 - accuracy: 0.8379 - val_loss: 0.4179 - val_accuracy: 0.8438\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3915 - accuracy: 0.8359 - val_loss: 0.3718 - val_accuracy: 0.8906\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.3755 - accuracy: 0.8340 - val_loss: 0.4573 - val_accuracy: 0.7656\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3805 - accuracy: 0.8457 - val_loss: 0.4416 - val_accuracy: 0.7500\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3932 - accuracy: 0.8516 - val_loss: 0.4281 - val_accuracy: 0.7812\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3318 - accuracy: 0.8730 - val_loss: 0.6639 - val_accuracy: 0.7500\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.4097 - accuracy: 0.8320 - val_loss: 0.4480 - val_accuracy: 0.7812\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3771 - accuracy: 0.8438 - val_loss: 0.5188 - val_accuracy: 0.7344\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.4205 - accuracy: 0.8158 - val_loss: 0.2900 - val_accuracy: 0.8906\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3593 - accuracy: 0.8457 - val_loss: 0.3284 - val_accuracy: 0.8594\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3123 - accuracy: 0.8770 - val_loss: 0.6082 - val_accuracy: 0.7969\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3876 - accuracy: 0.8398 - val_loss: 0.3814 - val_accuracy: 0.8281\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3665 - accuracy: 0.8438 - val_loss: 0.3443 - val_accuracy: 0.8750\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3630 - accuracy: 0.8477 - val_loss: 0.3609 - val_accuracy: 0.8594\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3990 - accuracy: 0.8340 - val_loss: 0.3450 - val_accuracy: 0.8750\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.4109 - accuracy: 0.8184 - val_loss: 0.2870 - val_accuracy: 0.9062\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3676 - accuracy: 0.8418 - val_loss: 0.4352 - val_accuracy: 0.8125\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3152 - accuracy: 0.8691 - val_loss: 0.3836 - val_accuracy: 0.8594\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3676 - accuracy: 0.8574 - val_loss: 0.4186 - val_accuracy: 0.8438\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.2928 - accuracy: 0.8730 - val_loss: 0.3632 - val_accuracy: 0.8281\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3278 - accuracy: 0.8770 - val_loss: 0.5763 - val_accuracy: 0.6719\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3112 - accuracy: 0.8750 - val_loss: 0.4753 - val_accuracy: 0.7812\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3233 - accuracy: 0.8672 - val_loss: 0.3953 - val_accuracy: 0.8281\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.2963 - accuracy: 0.8828 - val_loss: 0.3688 - val_accuracy: 0.8438\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3553 - accuracy: 0.8574 - val_loss: 0.3348 - val_accuracy: 0.8594\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3853 - accuracy: 0.8418 - val_loss: 0.2572 - val_accuracy: 0.9531\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3439 - accuracy: 0.8652 - val_loss: 0.2359 - val_accuracy: 0.8906\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3640 - accuracy: 0.8438 - val_loss: 0.5316 - val_accuracy: 0.8281\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3889 - accuracy: 0.8477 - val_loss: 0.3397 - val_accuracy: 0.8594\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3397 - accuracy: 0.8809 - val_loss: 0.5469 - val_accuracy: 0.7812\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3767 - accuracy: 0.8516 - val_loss: 0.3198 - val_accuracy: 0.8750\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3761 - accuracy: 0.8633 - val_loss: 0.2625 - val_accuracy: 0.8750\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3450 - accuracy: 0.8496 - val_loss: 0.3165 - val_accuracy: 0.8906\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3276 - accuracy: 0.8613 - val_loss: 0.2795 - val_accuracy: 0.8750\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3512 - accuracy: 0.8613 - val_loss: 0.3883 - val_accuracy: 0.8125\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.3016 - accuracy: 0.8789 - val_loss: 0.5012 - val_accuracy: 0.8125\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3349 - accuracy: 0.8535 - val_loss: 0.4105 - val_accuracy: 0.7812\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3580 - accuracy: 0.8789 - val_loss: 0.4572 - val_accuracy: 0.7812\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.3524 - accuracy: 0.8553 - val_loss: 0.3247 - val_accuracy: 0.8906\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.2718 - accuracy: 0.8789 - val_loss: 0.3827 - val_accuracy: 0.8750\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.2719 - accuracy: 0.8945 - val_loss: 0.4894 - val_accuracy: 0.7812\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.3462 - accuracy: 0.8516 - val_loss: 0.3056 - val_accuracy: 0.9062\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.3329 - accuracy: 0.8828 - val_loss: 0.3617 - val_accuracy: 0.8125\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.3290 - accuracy: 0.8750 - val_loss: 0.2764 - val_accuracy: 0.8750\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3334 - accuracy: 0.8828 - val_loss: 0.3359 - val_accuracy: 0.8438\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.3705 - accuracy: 0.8555 - val_loss: 0.3608 - val_accuracy: 0.8281\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.3031 - accuracy: 0.8809 - val_loss: 0.2997 - val_accuracy: 0.8594\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3142 - accuracy: 0.8574 - val_loss: 0.2605 - val_accuracy: 0.9219\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3004 - accuracy: 0.8867 - val_loss: 0.3091 - val_accuracy: 0.8750\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.2348 - accuracy: 0.9023 - val_loss: 0.3906 - val_accuracy: 0.7656\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3302 - accuracy: 0.8711 - val_loss: 0.4041 - val_accuracy: 0.8281\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3104 - accuracy: 0.8789 - val_loss: 0.4263 - val_accuracy: 0.8125\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3080 - accuracy: 0.8750 - val_loss: 0.3655 - val_accuracy: 0.8281\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.2779 - accuracy: 0.8945 - val_loss: 0.4093 - val_accuracy: 0.8125\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.2803 - accuracy: 0.8730 - val_loss: 0.3192 - val_accuracy: 0.8438\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.2814 - accuracy: 0.8867 - val_loss: 0.3148 - val_accuracy: 0.9062\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.2738 - accuracy: 0.9043 - val_loss: 0.3564 - val_accuracy: 0.8594\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3193 - accuracy: 0.8789 - val_loss: 0.4588 - val_accuracy: 0.8906\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3784 - accuracy: 0.8496 - val_loss: 0.3705 - val_accuracy: 0.8594\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3229 - accuracy: 0.8926 - val_loss: 0.5313 - val_accuracy: 0.8438\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3780 - accuracy: 0.8633 - val_loss: 0.3345 - val_accuracy: 0.9062\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3134 - accuracy: 0.8594 - val_loss: 0.2466 - val_accuracy: 0.8906\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3351 - accuracy: 0.8535 - val_loss: 0.1871 - val_accuracy: 0.9375\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.2766 - accuracy: 0.8867 - val_loss: 0.3128 - val_accuracy: 0.8750\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3528 - accuracy: 0.8887 - val_loss: 0.2860 - val_accuracy: 0.8750\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.2591 - accuracy: 0.8848 - val_loss: 0.4927 - val_accuracy: 0.7969\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.2997 - accuracy: 0.8809 - val_loss: 0.4512 - val_accuracy: 0.7969\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3108 - accuracy: 0.8848 - val_loss: 0.3507 - val_accuracy: 0.8594\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.3012 - accuracy: 0.8816 - val_loss: 0.2849 - val_accuracy: 0.8750\n",
      "\n",
      "\n",
      "New Task\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 3.2869 - accuracy: 0.3027 - val_loss: 0.7586 - val_accuracy: 0.4375\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.7484 - accuracy: 0.5684 - val_loss: 0.5039 - val_accuracy: 0.7812\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.6164 - accuracy: 0.6914 - val_loss: 0.5326 - val_accuracy: 0.7656\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.5388 - accuracy: 0.7324 - val_loss: 0.5085 - val_accuracy: 0.7344\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.4742 - accuracy: 0.7793 - val_loss: 0.4175 - val_accuracy: 0.7969\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.4274 - accuracy: 0.8262 - val_loss: 0.3960 - val_accuracy: 0.8125\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.4014 - accuracy: 0.8223 - val_loss: 0.2974 - val_accuracy: 0.8906\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.4098 - accuracy: 0.8242 - val_loss: 0.7002 - val_accuracy: 0.7031\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.3717 - accuracy: 0.8340 - val_loss: 0.2754 - val_accuracy: 0.9219\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.4302 - accuracy: 0.8457 - val_loss: 0.2939 - val_accuracy: 0.8594\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.3342 - accuracy: 0.8438 - val_loss: 0.5244 - val_accuracy: 0.7969\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.3767 - accuracy: 0.8477 - val_loss: 0.3635 - val_accuracy: 0.8438\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.3554 - accuracy: 0.8613 - val_loss: 0.2194 - val_accuracy: 0.9062\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3485 - accuracy: 0.8613 - val_loss: 0.4629 - val_accuracy: 0.9062\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.3869 - accuracy: 0.8652 - val_loss: 0.4495 - val_accuracy: 0.8281\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.3824 - accuracy: 0.8516 - val_loss: 0.2873 - val_accuracy: 0.9062\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3111 - accuracy: 0.8848 - val_loss: 0.3189 - val_accuracy: 0.8594\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.2854 - accuracy: 0.8691 - val_loss: 0.2067 - val_accuracy: 0.8906\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3023 - accuracy: 0.8828 - val_loss: 0.1770 - val_accuracy: 0.9219\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.3240 - accuracy: 0.8713 - val_loss: 0.3498 - val_accuracy: 0.8438\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3297 - accuracy: 0.8535 - val_loss: 0.2440 - val_accuracy: 0.8906\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3141 - accuracy: 0.8867 - val_loss: 0.1191 - val_accuracy: 0.9531\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.2764 - accuracy: 0.8906 - val_loss: 0.3544 - val_accuracy: 0.7969\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.2549 - accuracy: 0.9023 - val_loss: 0.2299 - val_accuracy: 0.8750\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.2386 - accuracy: 0.9082 - val_loss: 0.3441 - val_accuracy: 0.9219\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.2275 - accuracy: 0.9062 - val_loss: 0.1123 - val_accuracy: 0.9844\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.2384 - accuracy: 0.9082 - val_loss: 0.1184 - val_accuracy: 0.9531\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.2492 - accuracy: 0.8984 - val_loss: 0.4014 - val_accuracy: 0.8125\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.2215 - accuracy: 0.8984 - val_loss: 0.1944 - val_accuracy: 0.9219\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.2134 - accuracy: 0.9180 - val_loss: 0.1443 - val_accuracy: 0.9219\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.2303 - accuracy: 0.9062 - val_loss: 0.2668 - val_accuracy: 0.9062\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.2051 - accuracy: 0.9180 - val_loss: 0.4019 - val_accuracy: 0.8750\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.2970 - accuracy: 0.8789 - val_loss: 0.2764 - val_accuracy: 0.8750\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.2390 - accuracy: 0.9121 - val_loss: 0.1837 - val_accuracy: 0.9219\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.2240 - accuracy: 0.8984 - val_loss: 0.1416 - val_accuracy: 0.9531\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.2719 - accuracy: 0.8906 - val_loss: 0.2685 - val_accuracy: 0.8906\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.2432 - accuracy: 0.9102 - val_loss: 0.1807 - val_accuracy: 0.9219\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1749 - accuracy: 0.9297 - val_loss: 0.1030 - val_accuracy: 0.9688\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.2319 - accuracy: 0.9121 - val_loss: 0.2192 - val_accuracy: 0.8750\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.2811 - accuracy: 0.9007 - val_loss: 0.2495 - val_accuracy: 0.9062\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1877 - accuracy: 0.9238 - val_loss: 0.1739 - val_accuracy: 0.9219\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.2725 - accuracy: 0.8945 - val_loss: 0.1433 - val_accuracy: 0.9375\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.2500 - accuracy: 0.9219 - val_loss: 0.3624 - val_accuracy: 0.8594\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.2650 - accuracy: 0.8965 - val_loss: 0.1670 - val_accuracy: 0.9531\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.2061 - accuracy: 0.9238 - val_loss: 0.3090 - val_accuracy: 0.8750\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.2013 - accuracy: 0.9316 - val_loss: 0.1675 - val_accuracy: 0.9062\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.2023 - accuracy: 0.9238 - val_loss: 0.2351 - val_accuracy: 0.9062\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.2360 - accuracy: 0.9121 - val_loss: 0.2645 - val_accuracy: 0.8750\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1862 - accuracy: 0.9238 - val_loss: 0.2271 - val_accuracy: 0.8906\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1451 - accuracy: 0.9414 - val_loss: 0.1751 - val_accuracy: 0.9062\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.2242 - accuracy: 0.9316 - val_loss: 0.1742 - val_accuracy: 0.9375\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1899 - accuracy: 0.9180 - val_loss: 0.2496 - val_accuracy: 0.9375\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1723 - accuracy: 0.9316 - val_loss: 0.1744 - val_accuracy: 0.9219\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.2418 - accuracy: 0.9102 - val_loss: 0.2200 - val_accuracy: 0.9219\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.2406 - accuracy: 0.9219 - val_loss: 0.1081 - val_accuracy: 0.9531\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1946 - accuracy: 0.9238 - val_loss: 0.6219 - val_accuracy: 0.8438\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1943 - accuracy: 0.9258 - val_loss: 0.1475 - val_accuracy: 0.9375\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1579 - accuracy: 0.9375 - val_loss: 0.1138 - val_accuracy: 0.9844\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1679 - accuracy: 0.9336 - val_loss: 0.2521 - val_accuracy: 0.9219\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.1854 - accuracy: 0.9154 - val_loss: 0.2662 - val_accuracy: 0.8594\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1712 - accuracy: 0.9180 - val_loss: 0.0956 - val_accuracy: 0.9844\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1990 - accuracy: 0.9219 - val_loss: 0.0681 - val_accuracy: 1.0000\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1986 - accuracy: 0.9414 - val_loss: 0.3143 - val_accuracy: 0.8594\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.2091 - accuracy: 0.9180 - val_loss: 0.1432 - val_accuracy: 0.9375\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1660 - accuracy: 0.9336 - val_loss: 0.3202 - val_accuracy: 0.8906\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1476 - accuracy: 0.9375 - val_loss: 0.2686 - val_accuracy: 0.8750\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1714 - accuracy: 0.9355 - val_loss: 0.3385 - val_accuracy: 0.8281\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.2050 - accuracy: 0.9141 - val_loss: 0.2320 - val_accuracy: 0.8594\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1714 - accuracy: 0.9355 - val_loss: 0.4158 - val_accuracy: 0.9062\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1533 - accuracy: 0.9414 - val_loss: 0.0938 - val_accuracy: 0.9531\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1676 - accuracy: 0.9434 - val_loss: 0.1811 - val_accuracy: 0.9531\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1756 - accuracy: 0.9258 - val_loss: 0.2918 - val_accuracy: 0.8906\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1292 - accuracy: 0.9590 - val_loss: 0.1522 - val_accuracy: 0.9531\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1639 - accuracy: 0.9355 - val_loss: 0.1943 - val_accuracy: 0.8750\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1861 - accuracy: 0.9395 - val_loss: 0.1092 - val_accuracy: 0.9688\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1545 - accuracy: 0.9395 - val_loss: 0.3044 - val_accuracy: 0.8906\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1539 - accuracy: 0.9434 - val_loss: 0.1025 - val_accuracy: 0.9375\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1290 - accuracy: 0.9512 - val_loss: 0.1185 - val_accuracy: 0.9688\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1394 - accuracy: 0.9531 - val_loss: 0.1170 - val_accuracy: 0.9531\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.1804 - accuracy: 0.9375 - val_loss: 0.2754 - val_accuracy: 0.8594\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1637 - accuracy: 0.9336 - val_loss: 0.1027 - val_accuracy: 0.9844\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1674 - accuracy: 0.9434 - val_loss: 0.0819 - val_accuracy: 0.9531\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1678 - accuracy: 0.9395 - val_loss: 0.2475 - val_accuracy: 0.8906\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1798 - accuracy: 0.9258 - val_loss: 0.1793 - val_accuracy: 0.9219\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1135 - accuracy: 0.9531 - val_loss: 0.4013 - val_accuracy: 0.9219\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1259 - accuracy: 0.9473 - val_loss: 0.1577 - val_accuracy: 0.9375\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1555 - accuracy: 0.9414 - val_loss: 0.1499 - val_accuracy: 0.9375\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1667 - accuracy: 0.9316 - val_loss: 0.2761 - val_accuracy: 0.8750\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1646 - accuracy: 0.9395 - val_loss: 0.1327 - val_accuracy: 0.9219\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1427 - accuracy: 0.9551 - val_loss: 0.0958 - val_accuracy: 0.9531\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1437 - accuracy: 0.9375 - val_loss: 0.2167 - val_accuracy: 0.9531\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1432 - accuracy: 0.9492 - val_loss: 0.2391 - val_accuracy: 0.9219\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1727 - accuracy: 0.9375 - val_loss: 0.0757 - val_accuracy: 0.9844\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1853 - accuracy: 0.9277 - val_loss: 0.1757 - val_accuracy: 0.9219\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1533 - accuracy: 0.9355 - val_loss: 0.2394 - val_accuracy: 0.9062\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.1441 - accuracy: 0.9414 - val_loss: 0.3699 - val_accuracy: 0.9062\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1525 - accuracy: 0.9434 - val_loss: 0.1085 - val_accuracy: 0.9688\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1222 - accuracy: 0.9512 - val_loss: 0.0512 - val_accuracy: 0.9844\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1591 - accuracy: 0.9492 - val_loss: 0.0987 - val_accuracy: 0.9688\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.1631 - accuracy: 0.9301 - val_loss: 0.2685 - val_accuracy: 0.8906\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 15.7142 - accuracy: 0.0000e+00\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 17.6175 - accuracy: 0.0000e+00\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 17.7570 - accuracy: 0.0000e+00\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 18.4337 - accuracy: 0.0000e+00\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 19.5895 - accuracy: 0.0000e+00\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 17.3657 - accuracy: 0.0000e+00\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 16.8087 - accuracy: 0.0000e+00\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 16.7630 - accuracy: 0.0000e+00\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 16.6448 - accuracy: 0.0000e+00\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 20.5611 - accuracy: 0.0000e+00\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 18.0781 - accuracy: 0.0000e+00\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 17.6971 - accuracy: 0.0000e+00\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 18.3270 - accuracy: 0.0000e+00\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 16.7025 - accuracy: 0.0000e+00\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 17.5986 - accuracy: 0.0000e+00\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 19.2256 - accuracy: 0.0000e+00\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 19.4785 - accuracy: 0.0000e+00\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 18.2457 - accuracy: 0.0000e+00\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 17.5399 - accuracy: 0.0000e+00\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 19.9736 - accuracy: 0.0000e+00\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 18.9159 - accuracy: 0.0000e+00\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 19.8339 - accuracy: 0.0000e+00\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 15.3710 - accuracy: 0.0000e+00\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 18.8861 - accuracy: 0.0000e+00\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 17.5784 - accuracy: 0.0000e+00\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 18.9439 - accuracy: 0.0000e+00\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 17.6463 - accuracy: 0.0000e+00\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 21.4874 - accuracy: 0.0000e+00\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 19.1123 - accuracy: 0.0000e+00\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 16.2822 - accuracy: 0.0000e+00\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 18.5039 - accuracy: 0.0000e+00\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 18.9114 - accuracy: 0.0000e+00\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 18.8421 - accuracy: 0.0000e+00\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 20.0305 - accuracy: 0.0000e+00\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 20.4236 - accuracy: 0.0000e+00\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 21.9390 - accuracy: 0.0000e+00\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 17.8448 - accuracy: 0.0000e+00\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 17.8193 - accuracy: 0.0000e+00\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 18.4026 - accuracy: 0.0000e+00\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 19.3580 - accuracy: 0.0000e+00\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 17.8441 - accuracy: 0.0000e+00\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 16.9305 - accuracy: 0.0000e+00\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 18.6393 - accuracy: 0.0000e+00\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 17.5181 - accuracy: 0.0000e+00\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 17.1350 - accuracy: 0.0000e+00\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 18.3277 - accuracy: 0.0000e+00\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 17.5139 - accuracy: 0.0000e+00\n",
      "\n",
      "\n",
      "New Task\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 5.0064 - accuracy: 0.0566 - val_loss: 1.0752 - val_accuracy: 0.4688\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.0218 - accuracy: 0.4473 - val_loss: 0.6278 - val_accuracy: 0.6094\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.9326 - accuracy: 0.5254 - val_loss: 0.7046 - val_accuracy: 0.5312\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.8669 - accuracy: 0.6113 - val_loss: 0.4918 - val_accuracy: 0.7812\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.9262 - accuracy: 0.6523 - val_loss: 0.6156 - val_accuracy: 0.7969\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.7628 - accuracy: 0.6484 - val_loss: 0.5371 - val_accuracy: 0.8281\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.7099 - accuracy: 0.7422 - val_loss: 0.5118 - val_accuracy: 0.8281\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.6395 - accuracy: 0.7402 - val_loss: 0.5798 - val_accuracy: 0.6094\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.6714 - accuracy: 0.7246 - val_loss: 0.5523 - val_accuracy: 0.7188\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.6567 - accuracy: 0.7246 - val_loss: 0.3424 - val_accuracy: 0.8906\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.6535 - accuracy: 0.7500 - val_loss: 0.2565 - val_accuracy: 0.8906\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.6265 - accuracy: 0.7656 - val_loss: 0.4174 - val_accuracy: 0.8281\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.6681 - accuracy: 0.7500 - val_loss: 0.3843 - val_accuracy: 0.8438\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.5771 - accuracy: 0.7715 - val_loss: 0.4805 - val_accuracy: 0.7656\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.5831 - accuracy: 0.7695 - val_loss: 0.6439 - val_accuracy: 0.7812\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.6680 - accuracy: 0.7676 - val_loss: 0.3212 - val_accuracy: 0.8438\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.5337 - accuracy: 0.7910 - val_loss: 0.6398 - val_accuracy: 0.6875\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.4921 - accuracy: 0.7910 - val_loss: 0.4995 - val_accuracy: 0.8438\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.5839 - accuracy: 0.7461 - val_loss: 0.3829 - val_accuracy: 0.8125\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.4582 - accuracy: 0.7941 - val_loss: 0.2761 - val_accuracy: 0.8906\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.4837 - accuracy: 0.7871 - val_loss: 0.3740 - val_accuracy: 0.8750\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.4907 - accuracy: 0.7734 - val_loss: 0.3197 - val_accuracy: 0.8906\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.4679 - accuracy: 0.7988 - val_loss: 0.3026 - val_accuracy: 0.9219\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.4792 - accuracy: 0.7832 - val_loss: 0.2007 - val_accuracy: 0.9375\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.5070 - accuracy: 0.7910 - val_loss: 0.3850 - val_accuracy: 0.8281\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.5757 - accuracy: 0.7383 - val_loss: 0.3938 - val_accuracy: 0.8594\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.5293 - accuracy: 0.7637 - val_loss: 0.3117 - val_accuracy: 0.8906\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.4208 - accuracy: 0.8086 - val_loss: 0.2222 - val_accuracy: 0.9219\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.4770 - accuracy: 0.7773 - val_loss: 0.3898 - val_accuracy: 0.8281\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3515 - accuracy: 0.8164 - val_loss: 0.1317 - val_accuracy: 0.9531\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.4437 - accuracy: 0.7578 - val_loss: 0.2655 - val_accuracy: 0.9219\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3139 - accuracy: 0.8203 - val_loss: 0.1728 - val_accuracy: 0.9531\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3330 - accuracy: 0.8281 - val_loss: 0.1819 - val_accuracy: 0.9688\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3791 - accuracy: 0.8320 - val_loss: 0.1185 - val_accuracy: 0.9844\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3351 - accuracy: 0.9082 - val_loss: 0.3338 - val_accuracy: 0.8750\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3975 - accuracy: 0.8984 - val_loss: 0.1575 - val_accuracy: 0.9375\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3468 - accuracy: 0.9062 - val_loss: 0.5477 - val_accuracy: 0.8281\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.2906 - accuracy: 0.9375 - val_loss: 0.2035 - val_accuracy: 0.9375\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3170 - accuracy: 0.9121 - val_loss: 0.1949 - val_accuracy: 0.8906\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.2566 - accuracy: 0.9338 - val_loss: 0.3533 - val_accuracy: 0.9375\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.2455 - accuracy: 0.9375 - val_loss: 0.1658 - val_accuracy: 0.9062\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.2508 - accuracy: 0.9297 - val_loss: 3.1685 - val_accuracy: 0.7656\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.5810 - accuracy: 0.8262 - val_loss: 0.3384 - val_accuracy: 0.8750\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3556 - accuracy: 0.8711 - val_loss: 0.1004 - val_accuracy: 0.9688\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3321 - accuracy: 0.8926 - val_loss: 0.2216 - val_accuracy: 0.9062\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.4083 - accuracy: 0.8516 - val_loss: 0.2357 - val_accuracy: 0.8906\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3429 - accuracy: 0.8945 - val_loss: 0.2260 - val_accuracy: 0.8906\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.3100 - accuracy: 0.8945 - val_loss: 0.2695 - val_accuracy: 0.8906\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3544 - accuracy: 0.8574 - val_loss: 0.5393 - val_accuracy: 0.8438\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.2382 - accuracy: 0.9238 - val_loss: 0.1365 - val_accuracy: 0.9688\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.2751 - accuracy: 0.9043 - val_loss: 0.1498 - val_accuracy: 0.9062\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3132 - accuracy: 0.8809 - val_loss: 0.1872 - val_accuracy: 0.9219\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3070 - accuracy: 0.8652 - val_loss: 0.1043 - val_accuracy: 0.9375\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.2642 - accuracy: 0.8984 - val_loss: 0.1245 - val_accuracy: 0.9375\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.2589 - accuracy: 0.9102 - val_loss: 0.3473 - val_accuracy: 0.8750\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.2263 - accuracy: 0.9199 - val_loss: 0.1073 - val_accuracy: 0.9688\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.2281 - accuracy: 0.9375 - val_loss: 0.1576 - val_accuracy: 0.9688\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1575 - accuracy: 0.9512 - val_loss: 0.3623 - val_accuracy: 0.8750\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.2116 - accuracy: 0.9258 - val_loss: 0.1599 - val_accuracy: 0.9062\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.2651 - accuracy: 0.9118 - val_loss: 0.2514 - val_accuracy: 0.9375\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.2499 - accuracy: 0.9316 - val_loss: 0.2181 - val_accuracy: 0.8750\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1933 - accuracy: 0.9414 - val_loss: 0.3599 - val_accuracy: 0.9062\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.2498 - accuracy: 0.9062 - val_loss: 0.1959 - val_accuracy: 0.9062\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.2659 - accuracy: 0.9141 - val_loss: 0.0636 - val_accuracy: 0.9844\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.2056 - accuracy: 0.9297 - val_loss: 0.4354 - val_accuracy: 0.9062\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.2455 - accuracy: 0.9082 - val_loss: 0.2131 - val_accuracy: 0.9062\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3022 - accuracy: 0.8711 - val_loss: 0.3454 - val_accuracy: 0.8906\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.2464 - accuracy: 0.9238 - val_loss: 0.2612 - val_accuracy: 0.9062\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.2567 - accuracy: 0.8945 - val_loss: 0.4179 - val_accuracy: 0.8906\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1889 - accuracy: 0.9355 - val_loss: 0.0481 - val_accuracy: 0.9688\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1757 - accuracy: 0.9453 - val_loss: 0.1335 - val_accuracy: 0.9688\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.2043 - accuracy: 0.9180 - val_loss: 0.1380 - val_accuracy: 0.9062\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.2097 - accuracy: 0.9316 - val_loss: 0.1939 - val_accuracy: 0.9688\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1483 - accuracy: 0.9375 - val_loss: 0.2314 - val_accuracy: 0.9688\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1814 - accuracy: 0.9492 - val_loss: 0.2676 - val_accuracy: 0.8906\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.2892 - accuracy: 0.8945 - val_loss: 0.1222 - val_accuracy: 0.9531\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1771 - accuracy: 0.9512 - val_loss: 0.0633 - val_accuracy: 0.9844\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1216 - accuracy: 0.9648 - val_loss: 0.5325 - val_accuracy: 0.8750\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1911 - accuracy: 0.9453 - val_loss: 0.3050 - val_accuracy: 0.8906\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.1345 - accuracy: 0.9449 - val_loss: 0.1482 - val_accuracy: 0.9219\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1411 - accuracy: 0.9414 - val_loss: 0.1181 - val_accuracy: 0.9844\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1500 - accuracy: 0.9434 - val_loss: 0.2908 - val_accuracy: 0.9219\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.2168 - accuracy: 0.9219 - val_loss: 0.2286 - val_accuracy: 0.9375\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1956 - accuracy: 0.9297 - val_loss: 0.0891 - val_accuracy: 0.9531\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1509 - accuracy: 0.9355 - val_loss: 0.4366 - val_accuracy: 0.9219\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.2658 - accuracy: 0.9219 - val_loss: 0.2384 - val_accuracy: 0.9375\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.2437 - accuracy: 0.9082 - val_loss: 0.2458 - val_accuracy: 0.9219\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1631 - accuracy: 0.9453 - val_loss: 0.1416 - val_accuracy: 0.9688\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1925 - accuracy: 0.9238 - val_loss: 0.2649 - val_accuracy: 0.9375\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1024 - accuracy: 0.9570 - val_loss: 0.1343 - val_accuracy: 0.9531\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1615 - accuracy: 0.9473 - val_loss: 0.1062 - val_accuracy: 0.9375\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1566 - accuracy: 0.9473 - val_loss: 0.1009 - val_accuracy: 0.9688\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1685 - accuracy: 0.9258 - val_loss: 0.0456 - val_accuracy: 0.9844\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1498 - accuracy: 0.9570 - val_loss: 0.1390 - val_accuracy: 0.9375\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.2296 - accuracy: 0.9102 - val_loss: 0.2053 - val_accuracy: 0.9062\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1918 - accuracy: 0.9297 - val_loss: 0.1116 - val_accuracy: 0.9375\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1309 - accuracy: 0.9570 - val_loss: 0.1433 - val_accuracy: 0.9219\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1314 - accuracy: 0.9590 - val_loss: 0.3466 - val_accuracy: 0.8906\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1561 - accuracy: 0.9336 - val_loss: 0.2700 - val_accuracy: 0.8906\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0758 - accuracy: 0.9743 - val_loss: 0.1961 - val_accuracy: 0.9219\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 23.9219 - accuracy: 0.0000e+00\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 27.4071 - accuracy: 0.0000e+00\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 22.8841 - accuracy: 0.0000e+00\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 29.1998 - accuracy: 0.0000e+00\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 28.9259 - accuracy: 0.0000e+00\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 26.0329 - accuracy: 0.0000e+00\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 27.8583 - accuracy: 0.0000e+00\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 26.0213 - accuracy: 0.0000e+00\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 25.3440 - accuracy: 0.0000e+00\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 28.3204 - accuracy: 0.0000e+00\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 31.5548 - accuracy: 0.0000e+00\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 30.7892 - accuracy: 0.0000e+00\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 25.8717 - accuracy: 0.0000e+00\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 26.3889 - accuracy: 0.0000e+00\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 25.9784 - accuracy: 0.0000e+00\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 26.7401 - accuracy: 0.0000e+00\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 24.7036 - accuracy: 0.0000e+00\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 22.9987 - accuracy: 0.0000e+00\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 29.5947 - accuracy: 0.0000e+00\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 23.9622 - accuracy: 0.0000e+00\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 30.3493 - accuracy: 0.0000e+00\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 28.9453 - accuracy: 0.0000e+00\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 24.8570 - accuracy: 0.0000e+00\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 29.5382 - accuracy: 0.0000e+00\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 25.5032 - accuracy: 0.0000e+00\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 24.9455 - accuracy: 0.0000e+00\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 26.8824 - accuracy: 0.0000e+00\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 25.9577 - accuracy: 0.0000e+00\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 26.4318 - accuracy: 0.0000e+00\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 28.3037 - accuracy: 0.0000e+00\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 31.5850 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 28.2109 - accuracy: 0.0000e+00\n",
      "\n",
      "\n",
      "New Task\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#Export the model"
   ],
   "metadata": {
    "id": "W4zJdLeitCyT"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "(X_train, y_train), (X_test, y_test) = load_cifar_10()\n",
    "encoder_classifier.fit(X_train, y_train, epochs=100, validation_data=(X_test, y_test), callbacks=[es2])"
   ],
   "metadata": {
    "id": "LcN99bBy1wRa",
    "outputId": "0b66ed11-8a0f-4e0c-deb9-fd7aac13c5e6",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "execution_count": 21,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/100\n",
      "1563/1563 [==============================] - 25s 10ms/step - loss: 1.5032 - accuracy: 0.4556 - val_loss: 1.1502 - val_accuracy: 0.6000\n",
      "Epoch 2/100\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.0521 - accuracy: 0.6321 - val_loss: 0.9515 - val_accuracy: 0.6714\n",
      "Epoch 3/100\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.9039 - accuracy: 0.6931 - val_loss: 0.8167 - val_accuracy: 0.7318\n",
      "Epoch 4/100\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.8048 - accuracy: 0.7266 - val_loss: 0.7245 - val_accuracy: 0.7551\n",
      "Epoch 5/100\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.7406 - accuracy: 0.7502 - val_loss: 0.6519 - val_accuracy: 0.7798\n",
      "Epoch 6/100\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.6974 - accuracy: 0.7652 - val_loss: 0.6192 - val_accuracy: 0.7918\n",
      "Epoch 7/100\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.6485 - accuracy: 0.7827 - val_loss: 0.6282 - val_accuracy: 0.7849\n",
      "Epoch 8/100\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.6207 - accuracy: 0.7911 - val_loss: 0.6243 - val_accuracy: 0.7942\n",
      "Epoch 9/100\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.5845 - accuracy: 0.8045 - val_loss: 0.6311 - val_accuracy: 0.8015\n",
      "Epoch 10/100\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.5627 - accuracy: 0.8119 - val_loss: 0.5683 - val_accuracy: 0.8137\n",
      "Epoch 11/100\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.5442 - accuracy: 0.8193 - val_loss: 0.6164 - val_accuracy: 0.8059\n",
      "Epoch 12/100\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.5236 - accuracy: 0.8249 - val_loss: 0.5651 - val_accuracy: 0.8165\n",
      "Epoch 13/100\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.5082 - accuracy: 0.8306 - val_loss: 0.6106 - val_accuracy: 0.8105\n",
      "Epoch 14/100\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.4924 - accuracy: 0.8353 - val_loss: 0.5825 - val_accuracy: 0.8203\n",
      "Epoch 15/100\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.4768 - accuracy: 0.8411 - val_loss: 0.6339 - val_accuracy: 0.8060\n",
      "Epoch 16/100\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.4641 - accuracy: 0.8450 - val_loss: 0.5753 - val_accuracy: 0.8182\n",
      "Epoch 17/100\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.4494 - accuracy: 0.8491 - val_loss: 0.5577 - val_accuracy: 0.8230\n",
      "Epoch 18/100\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.4385 - accuracy: 0.8555 - val_loss: 0.5799 - val_accuracy: 0.8336\n",
      "Epoch 19/100\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.4300 - accuracy: 0.8560 - val_loss: 0.6086 - val_accuracy: 0.8189\n",
      "Epoch 20/100\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.4163 - accuracy: 0.8606 - val_loss: 0.5625 - val_accuracy: 0.8291\n",
      "Epoch 21/100\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.4069 - accuracy: 0.8640 - val_loss: 0.5754 - val_accuracy: 0.8317\n",
      "Epoch 22/100\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.4035 - accuracy: 0.8664 - val_loss: 0.5813 - val_accuracy: 0.8320\n",
      "Epoch 23/100\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.3946 - accuracy: 0.8690 - val_loss: 0.6623 - val_accuracy: 0.8306\n",
      "Epoch 24/100\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.3883 - accuracy: 0.8720 - val_loss: 0.5755 - val_accuracy: 0.8308\n",
      "Epoch 25/100\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.3857 - accuracy: 0.8727 - val_loss: 0.5899 - val_accuracy: 0.8333\n",
      "Epoch 26/100\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.3725 - accuracy: 0.8777 - val_loss: 0.5825 - val_accuracy: 0.8329\n",
      "Epoch 27/100\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.3633 - accuracy: 0.8804 - val_loss: 0.7227 - val_accuracy: 0.8188\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe79308d180>"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "encoder.save(\"encoder.h5\")\n",
    "classifier.save(\"classifier.h5\")"
   ],
   "metadata": {
    "id": "xQCXTvWKFsfC",
    "outputId": "7dce7be1-2e7e-485b-86cd-535aa005f0fd",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "execution_count": 22,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "l5NTBFQYHybC"
   },
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": [],
   "machine_shape": "hm",
   "gpuType": "T4",
   "include_colab_link": true
  },
  "accelerator": "GPU",
  "gpuClass": "standard"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
