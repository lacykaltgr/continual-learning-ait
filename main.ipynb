{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/lacykaltgr/continual-learning-ait/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pveLpmUzEF5A",
    "outputId": "64c6b82c-aaf7-47d8-a488-a7fd18cc748a"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--2023-05-16 12:06:40--  https://github.com/lacykaltgr/continual-learning-ait/archive/refs/heads/main.zip\n",
      "Resolving github.com (github.com)... 20.205.243.166\n",
      "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://codeload.github.com/lacykaltgr/continual-learning-ait/zip/refs/heads/main [following]\n",
      "--2023-05-16 12:06:40--  https://codeload.github.com/lacykaltgr/continual-learning-ait/zip/refs/heads/main\n",
      "Resolving codeload.github.com (codeload.github.com)... 20.205.243.165\n",
      "Connecting to codeload.github.com (codeload.github.com)|20.205.243.165|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [application/zip]\n",
      "Saving to: ‘main.zip’\n",
      "\n",
      "main.zip                [ <=>                ]   1.72M  --.-KB/s    in 0.1s    \n",
      "\n",
      "2023-05-16 12:06:40 (15.2 MB/s) - ‘main.zip’ saved [1804472]\n",
      "\n",
      "Archive:  main.zip\n",
      "78073f2b860fbe1e8c269de51b1bcaf4804042ed\n",
      "   creating: continual-learning-ait-main/\n",
      "  inflating: continual-learning-ait-main/.gitattributes  \n",
      "  inflating: continual-learning-ait-main/README.md  \n",
      "  inflating: continual-learning-ait-main/classifier.py  \n",
      "  inflating: continual-learning-ait-main/data_preparation.py  \n",
      "   creating: continual-learning-ait-main/dnnlib/\n",
      "  inflating: continual-learning-ait-main/dnnlib/__init__.py  \n",
      "  inflating: continual-learning-ait-main/dnnlib/util.py  \n",
      "  inflating: continual-learning-ait-main/generator.py  \n",
      "   creating: continual-learning-ait-main/guided_diffusion/\n",
      "  inflating: continual-learning-ait-main/guided_diffusion/__init__.py  \n",
      "  inflating: continual-learning-ait-main/guided_diffusion/dist_util.py  \n",
      "  inflating: continual-learning-ait-main/guided_diffusion/fp16_util.py  \n",
      "  inflating: continual-learning-ait-main/guided_diffusion/gaussian_diffusion.py  \n",
      "  inflating: continual-learning-ait-main/guided_diffusion/logger.py  \n",
      "  inflating: continual-learning-ait-main/guided_diffusion/losses.py  \n",
      "  inflating: continual-learning-ait-main/guided_diffusion/nn.py  \n",
      "  inflating: continual-learning-ait-main/guided_diffusion/resample.py  \n",
      "  inflating: continual-learning-ait-main/guided_diffusion/respace.py  \n",
      "  inflating: continual-learning-ait-main/guided_diffusion/script_util.py  \n",
      "  inflating: continual-learning-ait-main/guided_diffusion/train_util.py  \n",
      "  inflating: continual-learning-ait-main/guided_diffusion/unet.py  \n",
      "  inflating: continual-learning-ait-main/img.png  \n",
      "  inflating: continual-learning-ait-main/main.ipynb  \n",
      "   creating: continual-learning-ait-main/models/\n",
      "  inflating: continual-learning-ait-main/models/classifier.h5  \n",
      "  inflating: continual-learning-ait-main/models/encoder.h5  \n",
      "   creating: continual-learning-ait-main/notebooks/\n",
      "  inflating: continual-learning-ait-main/notebooks/classifier.ipynb  \n",
      "  inflating: continual-learning-ait-main/notebooks/data_preparation.ipynb  \n",
      "  inflating: continual-learning-ait-main/notebooks/generator.ipynb  \n",
      "   creating: continual-learning-ait-main/torch_utils/\n",
      "  inflating: continual-learning-ait-main/torch_utils/__init__.py  \n",
      "  inflating: continual-learning-ait-main/torch_utils/distributed.py  \n",
      "  inflating: continual-learning-ait-main/torch_utils/misc.py  \n",
      "  inflating: continual-learning-ait-main/torch_utils/persistence.py  \n",
      "  inflating: continual-learning-ait-main/torch_utils/training_stats.py  \n",
      "  inflating: continual-learning-ait-main/utils.py  \n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "'''Download the files '''\n",
    "'''Only for colab'''\n",
    "useColab = True\n",
    "useDrive = True\n",
    "\n",
    "if useColab:\n",
    "    !wget https://github.com/lacykaltgr/continual-learning-ait/archive/refs/heads/main.zip\n",
    "    !unzip main.zip\n",
    "    #!find continual-learning-ait-experiment -type f ! -name \"main.ipynb\" -exec cp {} . \\;\n",
    "    !cd continual-learning-ait-main\n",
    "\n",
    "    import sys\n",
    "    sys.path.append('/content/continual-learning-ait-main')\n",
    "\n",
    "    if useDrive:\n",
    "        from google.colab import drive\n",
    "        drive.mount('/content/drive')\n",
    "        encoder_f = '/drive/MyDrive/continual-learning-ait/checkpoints/32x32_classifier.pt'\n",
    "        scorenet_f = 'drive/MyDrive/continual-learning-ait/checkpoints/edm-cifar10-32x32-cond-vp.pkl'\n",
    "    #else:\n",
    "        #!wget https://nvlabs-fi-cdn.nvidia.com/edm/pretrained/edm-cifar10-32x32-cond-vp.pkl\n",
    "\n",
    "       #!wget https://nvlabs-fi-cdn.nvidia.com/edm/pretrained/32x32_classifier.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "vjfVuEmXECoL"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "#from sklearn.metrics import classification_report\n",
    "#from keras.metrics import Accuracy\n",
    "\n",
    "from generator import Generator\n",
    "from classifier import Classifier\n",
    "import utils\n",
    "from data_preparation import load_dataset, ClassifierDataLoader, RealFakeConditionalDataLoader\n",
    "\n",
    "import gc\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load the dataset"
   ],
   "metadata": {
    "collapsed": false,
    "id": "zzYWiWfZ8kVi"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "TaH3bi-5crqD",
    "outputId": "863e0b23-cef2-4ab4-bdf0-f82b8531d26b",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170498071/170498071 [==============================] - 13s 0us/step\n"
     ]
    }
   ],
   "source": [
    "dpt_train, dpt_test = load_dataset('cifar-10', n_classes_first_task=4, n_classes_other_task=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Define parameters and agent"
   ],
   "metadata": {
    "collapsed": false,
    "id": "3Jl-cBYs8kVj"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "GY9MAk581iYQ"
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    #general\n",
    "    \"n_runs\": 1,\n",
    "    \"n_tasks\": 3,\n",
    "    \"n_classes\": 10,\n",
    "    \"input_shape\": (32, 32, 3),\n",
    "    \"batch_size\": 128,\n",
    "    \"print_every\": 1,\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \"img_resolution\": 32,\n",
    "    \"classes_learned\": [4, 3, 3],\n",
    "\n",
    "    #classifier\n",
    "    \"cls_iters\": 1,\n",
    "    \"cls_lr\": 1e-2,\n",
    "    \"cls_epochs\": 5,\n",
    "\n",
    "    #generator\n",
    "    \"gen_epochs\": 2,\n",
    "    \"gen_lr\": 3e-4,\n",
    "    \"gen_scaler\": lambda x: 2. * x - 1.,\n",
    "\n",
    "    #mir\n",
    "    \"n_mem\": 1,\n",
    "    \"mir_iters\": 2,\n",
    "    \"reuse_samples\": False,\n",
    "    \"mem_coeff\": 0.12,\n",
    "\n",
    "    \"z_size\": 10,\n",
    "    \"xent_coeff\": 0.1,\n",
    "    \"ent_coeff\": 0.1,\n",
    "    \"div_coeff\": 0.1,\n",
    "    \"shell_coeff\": 0.1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "OmitFSMM2WJn"
   },
   "outputs": [],
   "source": [
    "'''Agent to handle models, parameters and states'''\n",
    "\n",
    "class Agent:\n",
    "  def __init__(self, hparams):\n",
    "    self.params = hparams\n",
    "    self.state = dict()\n",
    "    self.eval = dict()\n",
    "    self.score = accuracy_score\n",
    "\n",
    "    self.state[\"tasks_learned\"] = 0\n",
    "    self.eval[\"cls_loss\"] = []\n",
    "    self.eval[\"cls_acc\"] = []\n",
    "    self.eval[\"discriminator_loss\"] = []\n",
    "    self.eval[\"correction_rate\"] = []\n",
    "\n",
    "    self.classifier = None\n",
    "    self.generator = None\n",
    "    self.optimizer = None\n",
    "    self.optimizer_gen = None\n",
    "    self.loss = None\n",
    "    self.loss_gen = None\n",
    "\n",
    "\n",
    "\n",
    "  def set_models(\n",
    "          self,\n",
    "          _generator=None,\n",
    "          _classifier=None,\n",
    "    ):\n",
    "    cls = _classifier #classifier\n",
    "    gen = _generator  #generator\n",
    "\n",
    "    # losses\n",
    "    self.loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "    self.loss_gen = torch.nn.BCELoss()\n",
    "\n",
    "    # optimizers\n",
    "    self.optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=params[\"cls_lr\"])\n",
    "    self.optimizer_gen = torch.optim.Adam(gen.discriminator.parameters(), lr=agent.params[\"gen_lr\"], weight_decay=1e-7)\n",
    "\n",
    "    # classifier pipeline\n",
    "    data_input = keras.Input(shape=self.params[\"input_shape\"], name=\"image\")\n",
    "    cls_output = cls(data_input)\n",
    "    self.classifier = keras.Model(inputs=data_input, outputs=cls_output)\n",
    "    self.classifier.compile(optimizer=self.optimizer, loss=self.loss, metrics=[\"accuracy\"])\n",
    "\n",
    "    # generator pipeline\n",
    "    self.generator = gen"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Functions for training"
   ],
   "metadata": {
    "collapsed": false,
    "id": "OPqiS9VV8kVk"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "'''Generate samples and train the diffusion model at the same time'''\n",
    "\n",
    "def generate(\n",
    "        agent,\n",
    "        num_samples,\n",
    "        dg_weight_1st_order=1,\n",
    "        dg_weight_2nd_order=0,\n",
    "        boosting = 1,\n",
    "        time_min= 0.01, time_max= 1,\n",
    "        class_idx=None,\n",
    "):\n",
    "    latents = torch.randn([num_samples, agent.generator.net.img_channels, agent.params[\"img_resolution\"], agent.params[\"img_resolution\"]], device=agent.params['device'])\n",
    "\n",
    "    class_labels = torch.eye(agent.params['n_classes'], device=agent.params['device'])[torch.randint(agent.params['classes_learned'][agent.state[\"tasks_learned\"]]-1, size=[num_samples], device=agent.params['device'])]\n",
    "    if class_idx is not None:\n",
    "        class_labels[:, :] = 0\n",
    "        class_labels[:, class_idx] = 1\n",
    "\n",
    "\n",
    "    images = agent.generator.sample(boosting, time_min, time_max, dg_weight_1st_order, dg_weight_2nd_order, latents, class_labels)\n",
    "\n",
    "    # turn (3 32 32) into (32 32 3)\n",
    "    images = torch.transpose(images, 1, 3)\n",
    "    images = torch.transpose(images, 1, 2)\n",
    "\n",
    "    images, class_labels = \\\n",
    "        tf.convert_to_tensor(images.cpu().numpy()), \\\n",
    "            tf.convert_to_tensor(class_labels.cpu().numpy())\n",
    "    return images, class_labels\n"
   ],
   "metadata": {
    "id": "2BgWNzhg8kVk"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "'''Retrive maximally interferred latent vector for classifier'''\n",
    "\n",
    "def retrieve_mir(agent):\n",
    "\n",
    "    virtual_cls = Classifier()\n",
    "    virtual_cls = utils.get_next_step_cls(\n",
    "        agent.classifier,\n",
    "        virtual_cls,\n",
    "        agent.state[\"task_train_samples\"],\n",
    "        agent.state[\"task_train_targets\"]\n",
    "    )\n",
    "\n",
    "    final_generated = None\n",
    "    final_labels = None\n",
    "    for i in range(agent.params[\"n_mem\"]):\n",
    "\n",
    "        generated, labels = generate(agent, agent.params[\"batch_size\"])\n",
    "\n",
    "        for j in range(params[\"mir_iters\"]):\n",
    "            with tf.GradientTape(persistent=True) as tape:\n",
    "\n",
    "                tape.watch(generated)\n",
    "\n",
    "                y_pre = agent.classifier(generated)\n",
    "                y_virtual = virtual_cls(generated)\n",
    "\n",
    "                # maximise the interference:\n",
    "                XENT = tf.constant(0.)\n",
    "                if params[\"xent_coeff\"] > 0.:\n",
    "                    XENT = tf.keras.losses.categorical_crossentropy(y_virtual, y_pre)\n",
    "\n",
    "                # the predictions from the two models should be confident\n",
    "                ENT = tf.constant(0.)\n",
    "                if params[\"ent_coeff\"] > 0.:\n",
    "                    ENT = tf.keras.losses.categorical_crossentropy(y_pre, y_pre)\n",
    "\n",
    "                # the new-found samples should be different from each others\n",
    "                DIV = tf.constant(0.)\n",
    "                if params[\"div_coeff\"] > 0.:\n",
    "                    for found_generated in range(i):\n",
    "                        DIV += tf.cast(tf.keras.losses.MSE(\n",
    "                            generated,\n",
    "                            final_generated[found_generated * generated.shape[0]:found_generated * generated.shape[0] + generated.shape[0]]\n",
    "                        ) / i, tf.float32)\n",
    "\n",
    "                # (NEW) stay on gaussian shell loss:\n",
    "                SHELL = tf.constant(0.)\n",
    "                if params[\"shell_coeff\"] > 0.:\n",
    "                    SHELL = tf.keras.losses.MSE(\n",
    "                        tf.norm(generated, axis=1),\n",
    "                        tf.ones_like(tf.norm(generated, axis=1))*np.sqrt(params[\"z_size\"])\n",
    "                    )\n",
    "\n",
    "                XENT, ENT, DIV, SHELL = \\\n",
    "                    tf.cast(tf.reduce_mean(XENT), dtype=tf.float64), \\\n",
    "                    tf.cast(tf.reduce_mean(ENT), dtype=tf.float64), \\\n",
    "                    tf.cast(tf.reduce_mean(DIV), dtype=tf.float64), \\\n",
    "                    tf.cast(tf.reduce_mean(SHELL), dtype=tf.float64)\n",
    "\n",
    "                gain = params[\"xent_coeff\"] * XENT + \\\n",
    "                       -params[\"ent_coeff\"] * ENT + \\\n",
    "                       params[\"div_coeff\"] * DIV + \\\n",
    "                       -params[\"shell_coeff\"] * SHELL\n",
    "\n",
    "            gen_grad = tape.gradient(gain, generated)\n",
    "            if gen_grad is not None:\n",
    "                generated = (generated + 1 * gen_grad)\n",
    "\n",
    "        if final_generated is None:\n",
    "            final_generated = generated.numpy().copy()\n",
    "            final_labels = labels.numpy().copy()\n",
    "        else:\n",
    "            final_generated = np.concatenate([final_generated, generated.numpy().copy()])\n",
    "            final_labels = np.concatenate([final_labels, labels.numpy().copy()])\n",
    "\n",
    "    tf.stop_gradient(final_generated)\n",
    "\n",
    "    return final_generated, final_labels"
   ],
   "metadata": {
    "id": "OlENSPig8kVl"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "'''Run an epoch'''\n",
    "\n",
    "def train_classifier(agent):\n",
    "\n",
    "\n",
    "    mem_x, mem_y = retrieve_mir(agent)\n",
    "    train_data = np.concatenate((agent.state[\"task_train_samples\"], mem_x))\n",
    "    train_target = np.concatenate((agent.state[\"task_train_targets\"], mem_y))\n",
    "\n",
    "    classifier_loader = ClassifierDataLoader(train_data, train_target)\n",
    "\n",
    "    history = agent.classifier.fit(classifier_loader, batch_size=agent.params[\"batch_size\"], epochs=agent.params[\"cls_epochs\"], verbose=1)\n",
    "\n",
    "    agent.eval[\"cls_loss\"].append(history.history[\"loss\"])\n",
    "    agent.eval[\"cls_acc\"].append(history.history[\"accuracy\"])\n",
    "\n",
    "    '''Evaluate the models in epoch'''\n",
    "    if agent.state[\"epoch\"] % agent.params[\"print_every\"] == 0:\n",
    "        print(f\"    Classifier loss: {np.mean(agent.eval['cls_loss'][-1])}\"\n",
    "              f\"    Classifier accuracy: {np.mean(agent.eval['cls_acc'][-1])}\")"
   ],
   "metadata": {
    "id": "xmJWM9GCzym_"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "'''Train the discriminator unit'''\n",
    "\n",
    "def train_generator(agent):\n",
    "\n",
    "\n",
    "    real_samples, real_labels = agent.state[\"task_train_samples\"], agent.state[\"task_train_targets\"]\n",
    "    fake_samples, fake_labels = generate(\n",
    "        agent, len(real_samples) , dg_weight_1st_order=0, dg_weight_2nd_order=0, boosting=0)\n",
    "\n",
    "    train_data = np.concatenate((real_samples, fake_samples))\n",
    "    train_label = torch.zeros(train_data.shape[0])\n",
    "    train_label[:real_samples.shape[0]] = 1.\n",
    "    condition_label = np.concatenate((real_labels, fake_labels))\n",
    "\n",
    "    real_fake_loader = RealFakeConditionalDataLoader(train_data, train_label, condition_label)\n",
    "    for epoch in range(agent.params[\"gen_epochs\"]):\n",
    "        outs = []\n",
    "        cors = []\n",
    "        for data in real_fake_loader:\n",
    "            agent.optimizer_gen.zero_grad()\n",
    "\n",
    "            inputs, labels, cond = data\n",
    "            cond = cond.to(agent.params[\"device\"])\n",
    "            inputs = inputs.to(agent.params[\"device\"])\n",
    "            labels = labels.to(agent.params[\"device\"])\n",
    "            inputs = agent.params[\"gen_scaler\"](inputs)\n",
    "\n",
    "            # Data perturbation\n",
    "            t, _ = agent.generator.vpsde.get_diffusion_time(inputs.shape[0], inputs.device)\n",
    "            mean, std = agent.generator.vpsde.marginal_prob(t)\n",
    "            z = torch.randn_like(inputs)\n",
    "            perturbed_inputs = mean[:, None, None, None] * inputs + std[:, None, None, None] * z\n",
    "\n",
    "            # Forward\n",
    "            with torch.no_grad():\n",
    "                pretrained_feature = agent.generator.encoder(perturbed_inputs, timesteps=t, feature=True).type(torch.cuda.FloatTensor)\n",
    "            label_prediction = agent.generator.discriminator(pretrained_feature, t, sigmoid=True, condition=cond).view(-1)\n",
    "\n",
    "            # Backward\n",
    "            out = agent.loss_gen(label_prediction, labels)\n",
    "            out.backward()\n",
    "            agent.optimizer_gen.step()\n",
    "\n",
    "            # Report\n",
    "            cor = ((label_prediction > 0.5).float() == labels).float().mean()\n",
    "            outs.append(out.item())\n",
    "            cors.append(cor.item())\n",
    "        agent.eval[\"correction_rate\"][-1].append(np.mean(cors))\n",
    "        agent.eval[\"discriminator_loss\"][-1].append(np.mean(outs))\n",
    "\n",
    "    '''Evaluate the models in epoch'''\n",
    "    if agent.state[\"epoch\"] % agent.params[\"print_every\"] == 0:\n",
    "        print(f\"    Discriminator loss: {np.mean(agent.eval['discriminator_loss'][-1])}\"\n",
    "              f\"    Correction rate: {np.mean(agent.eval['correction_rate'][-1])}\")"
   ],
   "metadata": {
    "id": "K48EQq7VGuI-"
   },
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "0SyPNSep_K0t"
   },
   "outputs": [],
   "source": [
    "'''Run a task'''\n",
    "\n",
    "def run_task(agent):\n",
    "\n",
    "    print(f\"\\n#############\\n\"\n",
    "          f\"  TASK {agent.state['task']}\\n\"\n",
    "          f\"#############\\n\")\n",
    "\n",
    "    agent.eval[\"discriminator_loss\"].append([])\n",
    "    agent.eval[\"correction_rate\"].append([])\n",
    "  \n",
    "    train_classifier(agent)\n",
    "\n",
    "    agent.state[\"tasks_learned\"] += 1\n",
    "    print(\"\\n\")\n",
    "\n",
    "    train_generator(agent)\n",
    "\n",
    "    '''Evaluate forgetting'''\n",
    "    print(\"\\nEvaluate Task: \", agent.state[\"task\"])\n",
    "    for i in range(agent.state[\"task\"]+1):\n",
    "        data, target = dpt_test[i]\n",
    "        logits = agent.classifier.predict(data, batch_size=256)\n",
    "        #loss\n",
    "        loss = agent.loss(logits, target)\n",
    "        #accuracy\n",
    "        pred = np.argmax(logits, axis=1)\n",
    "        y = np.argmax(target, axis=1)\n",
    "        accuracy = agent.score(y, pred)\n",
    "        print(f\"    Task {agent.state['task']} forgetting on task {i} : \"\n",
    "              f\"        Loss: {np.mean(loss)}\"\n",
    "              f\"        ACC: {np.mean(accuracy)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "VhbA5MCFCi4r"
   },
   "outputs": [],
   "source": [
    "'''Run the experiment'''\n",
    "\n",
    "def run(agent):\n",
    "    for r in range(agent.params[\"n_runs\"]):\n",
    "        agent.state[\"run\"] = r\n",
    "        for task, (tr_loader, ts_loader) in enumerate(zip(dpt_train, dpt_test)):\n",
    "            agent.state[\"task\"] = task\n",
    "            agent.state[\"task_train_samples\"], agent.state[\"task_train_targets\"]  = tr_loader\n",
    "            agent.state[\"task_test_samples\"], agent.state[\"task_test_targets\"] = ts_loader\n",
    "            run_task(agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training"
   ],
   "metadata": {
    "collapsed": false,
    "id": "AoBLwork8kVn"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "BlPHqKTaC41u"
   },
   "outputs": [],
   "source": [
    "agent = Agent(params)\n",
    "agent.set_models(\n",
    "    _classifier=Classifier(),\n",
    "    _generator=Generator(encoder_path=encoder_f, scorenet_path=scorenet_f),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "run(agent)"
   ],
   "metadata": {
    "id": "jL7eBmbM33Nw",
    "outputId": "b392d847-1570-498b-e1e0-13087b6a359a",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    }
   },
   "execution_count": 43,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "#############\n",
      "  TASK 0\n",
      "#############\n",
      "\n",
      "Epoch: 0 on Classifier\n",
      "    Classifier loss: 0.38944953699020823    Classifier accuracy: 0.8586285828025477\n",
      "Epoch: 1 on Classifier\n",
      "    Classifier loss: 0.2807658105898815    Classifier accuracy: 0.8975417993630573\n",
      "Epoch: 2 on Classifier\n",
      "    Classifier loss: 0.24176669329594655    Classifier accuracy: 0.9132663216560509\n",
      "Epoch: 3 on Classifier\n",
      "    Classifier loss: 0.23046819424363457    Classifier accuracy: 0.9189390923566879\n",
      "Epoch: 4 on Classifier\n",
      "    Classifier loss: 0.20969912039626176    Classifier accuracy: 0.9230692675159236\n",
      "\n",
      "\n",
      "Epoch: 0 on Generator\n",
      "    Discriminator loss: 0.9922369458252871    Correction rate: 0.04416427313338352\n",
      "Epoch: 1 on Generator\n",
      "    Discriminator loss: 0.9922369458252871    Correction rate: 0.04286144774324626\n",
      "\n",
      "Evaluate Task:  0\n",
      "    Task 0 forgetting on task 0 :         Loss: 2.091749429702759        ACC: 0.8933531746031746\n",
      "\n",
      "#############\n",
      "  TASK 1\n",
      "#############\n",
      "\n",
      "Epoch: 0 on Classifier\n",
      "2/2 [==============================] - 1s 22ms/step - loss: 0.8845 - accuracy: 0.6875\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.1396 - accuracy: 0.1914\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:tensorflow:5 out of the last 842 calls to <function Model.make_train_function.<locals>.train_function at 0x7fe2d64a25f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2/2 [==============================] - 0s 22ms/step - loss: 0.9189 - accuracy: 0.7422\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.8759 - accuracy: 0.8320\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.8171 - accuracy: 0.8438\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.5460 - accuracy: 0.8828\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.4755 - accuracy: 0.9297\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4959 - accuracy: 0.8867\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.4465 - accuracy: 0.9023\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.3781 - accuracy: 0.9102\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.4683 - accuracy: 0.8867\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.5526 - accuracy: 0.8828\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.3583 - accuracy: 0.9258\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.3763 - accuracy: 0.8906\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-43-74a7f609a4a4>\u001B[0m in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mrun\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0magent\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m<ipython-input-23-41136fada665>\u001B[0m in \u001B[0;36mrun\u001B[0;34m(agent)\u001B[0m\n\u001B[1;32m     17\u001B[0m             \u001B[0magent\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstate\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"ts_loader\"\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mts_loader\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     18\u001B[0m             \u001B[0magent\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstate\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"tasks_learned\"\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 19\u001B[0;31m             \u001B[0mrun_task\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0magent\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m<ipython-input-42-63859c8f0eb8>\u001B[0m in \u001B[0;36mrun_task\u001B[0;34m(agent)\u001B[0m\n\u001B[1;32m      9\u001B[0m     \u001B[0;32mfor\u001B[0m \u001B[0mepoch\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0magent\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mparams\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"cls_epochs\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     10\u001B[0m         \u001B[0magent\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstate\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"epoch\"\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mepoch\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 11\u001B[0;31m         \u001B[0mrun_cls_epoch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0magent\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     12\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     13\u001B[0m     \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"\\n\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-20-12dd2963a9fb>\u001B[0m in \u001B[0;36mrun_cls_epoch\u001B[0;34m(agent)\u001B[0m\n\u001B[1;32m     13\u001B[0m         \u001B[0magent\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstate\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"data\"\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     14\u001B[0m         \u001B[0magent\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstate\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"target\"\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtarget\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 15\u001B[0;31m         \u001B[0mtrain_classifier\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0magent\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     16\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     17\u001B[0m     \u001B[0;34m'''Evaluate the models in epoch'''\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-11-6abf4b313f84>\u001B[0m in \u001B[0;36mtrain_classifier\u001B[0;34m(agent)\u001B[0m\n\u001B[1;32m     10\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0magent\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstate\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"task\"\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     11\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mit\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m0\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0magent\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mparams\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"reuse_samples\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 12\u001B[0;31m                 \u001B[0mmem_x\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmem_y\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mretrieve_mir\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0magent\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0magent\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstate\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"data\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0magent\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstate\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"target\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     13\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     14\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mmem_x\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-27-15bfa21f0adb>\u001B[0m in \u001B[0;36mretrieve_mir\u001B[0;34m(agent, samples, target)\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m     \u001B[0mvirtual_cls\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mClassifier\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 7\u001B[0;31m     virtual_cls = utils.get_next_step_cls(\n\u001B[0m\u001B[1;32m      8\u001B[0m         \u001B[0magent\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclassifier\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      9\u001B[0m         \u001B[0mvirtual_cls\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/content/continual-learning-ait-main/utils.py\u001B[0m in \u001B[0;36mget_next_step_cls\u001B[0;34m(current_classifier, virtual_classifier, sample, target)\u001B[0m\n\u001B[1;32m     78\u001B[0m     \u001B[0mvirtual_classifier\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbuild\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput_shape\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0msample\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     79\u001B[0m     \u001B[0mvirtual_classifier\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcompile\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0moptimizer\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"adam\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mloss\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"categorical_crossentropy\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmetrics\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"accuracy\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 80\u001B[0;31m     \u001B[0mvirtual_classifier\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msample\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtarget\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msample\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mepochs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mverbose\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     81\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mvirtual_classifier\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     82\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     63\u001B[0m         \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     64\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 65\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     66\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     67\u001B[0m             \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1683\u001B[0m                         ):\n\u001B[1;32m   1684\u001B[0m                             \u001B[0mcallbacks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mon_train_batch_begin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1685\u001B[0;31m                             \u001B[0mtmp_logs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1686\u001B[0m                             \u001B[0;32mif\u001B[0m \u001B[0mdata_handler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshould_sync\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1687\u001B[0m                                 \u001B[0mcontext\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0masync_wait\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m     \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    149\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 150\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    151\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    152\u001B[0m       \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    892\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    893\u001B[0m       \u001B[0;32mwith\u001B[0m \u001B[0mOptionalXlaContext\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_jit_compile\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 894\u001B[0;31m         \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    895\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    896\u001B[0m       \u001B[0mnew_tracing_count\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexperimental_get_tracing_count\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001B[0m in \u001B[0;36m_call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    957\u001B[0m         \u001B[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    958\u001B[0m         \u001B[0;31m# no_variable_creation function.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 959\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_no_variable_creation_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    960\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    961\u001B[0m       _, _, filtered_flat_args = (\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    141\u001B[0m       (concrete_function,\n\u001B[1;32m    142\u001B[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001B[0;32m--> 143\u001B[0;31m     return concrete_function._call_flat(\n\u001B[0m\u001B[1;32m    144\u001B[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001B[1;32m    145\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001B[0m in \u001B[0;36m_call_flat\u001B[0;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[1;32m   1755\u001B[0m         and executing_eagerly):\n\u001B[1;32m   1756\u001B[0m       \u001B[0;31m# No tape is watching; skip to running the function.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1757\u001B[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001B[0m\u001B[1;32m   1758\u001B[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001B[1;32m   1759\u001B[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001B[0m in \u001B[0;36mcall\u001B[0;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[1;32m    379\u001B[0m       \u001B[0;32mwith\u001B[0m \u001B[0m_InterpolateFunctionError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    380\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mcancellation_manager\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 381\u001B[0;31m           outputs = execute.execute(\n\u001B[0m\u001B[1;32m    382\u001B[0m               \u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msignature\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    383\u001B[0m               \u001B[0mnum_outputs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_num_outputs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001B[0m in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     50\u001B[0m   \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     51\u001B[0m     \u001B[0mctx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mensure_initialized\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 52\u001B[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001B[0m\u001B[1;32m     53\u001B[0m                                         inputs, attrs, num_outputs)\n\u001B[1;32m     54\u001B[0m   \u001B[0;32mexcept\u001B[0m \u001B[0mcore\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Image generation"
   ],
   "metadata": {
    "collapsed": false,
    "id": "1TZSRE2moKuY"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "images = generate(agent, 1, 0.01, 1, 1, 0, 10, 4)"
   ],
   "metadata": {
    "id": "aT_2YcuyLYWN"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def disp(image):\n",
    "    image = (image + 1)* 127.5\n",
    "\n",
    "    plt.imshow(image.astype(np.uint8))\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ],
   "metadata": {
    "id": "M2GlqzEzMEod"
   },
   "execution_count": 34,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "disp(images[0][1])"
   ],
   "metadata": {
    "id": "yNc1tDejMGoB",
    "outputId": "87c56ccf-d5eb-4b5e-a9c2-645da285e5e0",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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\n"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluation, testing"
   ],
   "metadata": {
    "collapsed": false,
    "id": "UiiKIl618kVn"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "def evaluate(loader, first_n_tasks=None):\n",
    "    for task, tr_loader in enumerate(loader):\n",
    "        print(\"Task: \", task)\n",
    "        data, target = tr_loader.batch(124)\n",
    "        logits = agent.classifier_model(data)\n",
    "        pred = np.argmax(logits, axis=1)\n",
    "        report = agent.score(np.argmax(target, axis=1), pred)\n",
    "        loss = tf.keras.losses.categorical_crossentropy(target, logits)\n",
    "        print(report)\n",
    "        print(\"Mean loss: \", np.mean(loss))\n",
    "\n",
    "print(\"Evaluation on training set:\")\n",
    "evaluate(train_loader)\n",
    "print(\"Evaluation on test set:\")\n",
    "evaluate(test_loader)\n",
    "'''"
   ],
   "metadata": {
    "id": "r_K9lbNh8kVn"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Utils for development"
   ],
   "metadata": {
    "collapsed": false,
    "id": "vOxdRLeJ8kVn"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "59341"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "# Garbage collection\n",
    "gc.collect()"
   ],
   "metadata": {
    "id": "NCdIwGMq8kVn",
    "outputId": "cffd2280-970f-4435-da6b-cb20a1e40a34",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   }
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "machine_shape": "hm",
   "gpuType": "T4",
   "include_colab_link": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "accelerator": "GPU",
  "gpuClass": "standard"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
