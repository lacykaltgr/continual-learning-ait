{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lacykaltgr/continual-learning-ait/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pveLpmUzEF5A",
        "outputId": "64c6b82c-aaf7-47d8-a488-a7fd18cc748a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-05-16 12:06:40--  https://github.com/lacykaltgr/continual-learning-ait/archive/refs/heads/main.zip\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://codeload.github.com/lacykaltgr/continual-learning-ait/zip/refs/heads/main [following]\n",
            "--2023-05-16 12:06:40--  https://codeload.github.com/lacykaltgr/continual-learning-ait/zip/refs/heads/main\n",
            "Resolving codeload.github.com (codeload.github.com)... 20.205.243.165\n",
            "Connecting to codeload.github.com (codeload.github.com)|20.205.243.165|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘main.zip’\n",
            "\n",
            "main.zip                [ <=>                ]   1.72M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2023-05-16 12:06:40 (15.2 MB/s) - ‘main.zip’ saved [1804472]\n",
            "\n",
            "Archive:  main.zip\n",
            "78073f2b860fbe1e8c269de51b1bcaf4804042ed\n",
            "   creating: continual-learning-ait-main/\n",
            "  inflating: continual-learning-ait-main/.gitattributes  \n",
            "  inflating: continual-learning-ait-main/README.md  \n",
            "  inflating: continual-learning-ait-main/classifier.py  \n",
            "  inflating: continual-learning-ait-main/data_preparation.py  \n",
            "   creating: continual-learning-ait-main/dnnlib/\n",
            "  inflating: continual-learning-ait-main/dnnlib/__init__.py  \n",
            "  inflating: continual-learning-ait-main/dnnlib/util.py  \n",
            "  inflating: continual-learning-ait-main/generator.py  \n",
            "   creating: continual-learning-ait-main/guided_diffusion/\n",
            "  inflating: continual-learning-ait-main/guided_diffusion/__init__.py  \n",
            "  inflating: continual-learning-ait-main/guided_diffusion/dist_util.py  \n",
            "  inflating: continual-learning-ait-main/guided_diffusion/fp16_util.py  \n",
            "  inflating: continual-learning-ait-main/guided_diffusion/gaussian_diffusion.py  \n",
            "  inflating: continual-learning-ait-main/guided_diffusion/logger.py  \n",
            "  inflating: continual-learning-ait-main/guided_diffusion/losses.py  \n",
            "  inflating: continual-learning-ait-main/guided_diffusion/nn.py  \n",
            "  inflating: continual-learning-ait-main/guided_diffusion/resample.py  \n",
            "  inflating: continual-learning-ait-main/guided_diffusion/respace.py  \n",
            "  inflating: continual-learning-ait-main/guided_diffusion/script_util.py  \n",
            "  inflating: continual-learning-ait-main/guided_diffusion/train_util.py  \n",
            "  inflating: continual-learning-ait-main/guided_diffusion/unet.py  \n",
            "  inflating: continual-learning-ait-main/img.png  \n",
            "  inflating: continual-learning-ait-main/main.ipynb  \n",
            "   creating: continual-learning-ait-main/models/\n",
            "  inflating: continual-learning-ait-main/models/classifier.h5  \n",
            "  inflating: continual-learning-ait-main/models/encoder.h5  \n",
            "   creating: continual-learning-ait-main/notebooks/\n",
            "  inflating: continual-learning-ait-main/notebooks/classifier.ipynb  \n",
            "  inflating: continual-learning-ait-main/notebooks/data_preparation.ipynb  \n",
            "  inflating: continual-learning-ait-main/notebooks/generator.ipynb  \n",
            "   creating: continual-learning-ait-main/torch_utils/\n",
            "  inflating: continual-learning-ait-main/torch_utils/__init__.py  \n",
            "  inflating: continual-learning-ait-main/torch_utils/distributed.py  \n",
            "  inflating: continual-learning-ait-main/torch_utils/misc.py  \n",
            "  inflating: continual-learning-ait-main/torch_utils/persistence.py  \n",
            "  inflating: continual-learning-ait-main/torch_utils/training_stats.py  \n",
            "  inflating: continual-learning-ait-main/utils.py  \n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "'''Download the files '''\n",
        "'''Only for colab'''\n",
        "useColab = True\n",
        "useDrive = True\n",
        "\n",
        "if useColab:\n",
        "    !wget https://github.com/lacykaltgr/continual-learning-ait/archive/refs/heads/main.zip\n",
        "    !unzip main.zip\n",
        "    #!find continual-learning-ait-experiment -type f ! -name \"main.ipynb\" -exec cp {} . \\;\n",
        "    !cd continual-learning-ait-main\n",
        "\n",
        "    import sys\n",
        "    sys.path.append('/content/continual-learning-ait-main')\n",
        "\n",
        "    if useDrive:\n",
        "        from google.colab import drive\n",
        "        drive.mount('/content/drive')\n",
        "        encoder_f = '/drive/MyDrive/continual-learning-ait/checkpoints/32x32_classifier.pt'\n",
        "        scorenet_f = 'drive/MyDrive/continual-learning-ait/checkpoints/edm-cifar10-32x32-cond-vp.pkl'\n",
        "    #else:\n",
        "        #!wget https://nvlabs-fi-cdn.nvidia.com/edm/pretrained/edm-cifar10-32x32-cond-vp.pkl\n",
        "\n",
        "       #!wget https://nvlabs-fi-cdn.nvidia.com/edm/pretrained/32x32_classifier.pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vjfVuEmXECoL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "#from sklearn.metrics import classification_report\n",
        "#from keras.metrics import Accuracy\n",
        "\n",
        "from generator import Generator\n",
        "from classifier import Classifier\n",
        "import utils\n",
        "from data_preparation import load_dataset, CLDataLoader, RealFakeConditionalDataset\n",
        "\n",
        "import gc\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "\n",
        "import importlib"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the dataset"
      ],
      "metadata": {
        "collapsed": false,
        "id": "zzYWiWfZ8kVi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "TaH3bi-5crqD",
        "outputId": "863e0b23-cef2-4ab4-bdf0-f82b8531d26b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 13s 0us/step\n"
          ]
        }
      ],
      "source": [
        "dpt_train, dpt_test = load_dataset('cifar-10', n_classes_first_task=4, n_classes_other_task=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "yIESUurDeOCR"
      },
      "outputs": [],
      "source": [
        "batch_size = 128\n",
        "train_loader = CLDataLoader(dpt_train, batch_size , train=True)\n",
        "test_loader = CLDataLoader(dpt_test, batch_size, train=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define parameters and agent"
      ],
      "metadata": {
        "collapsed": false,
        "id": "3Jl-cBYs8kVj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "GY9MAk581iYQ"
      },
      "outputs": [],
      "source": [
        "params = {\n",
        "    #general\n",
        "    \"n_runs\": 1,\n",
        "    \"n_tasks\": 3,\n",
        "    \"n_classes\": 10,\n",
        "    \"input_shape\": (32, 32, 3),\n",
        "    \"batch_size\": batch_size,\n",
        "    \"print_every\": 1,\n",
        "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
        "    \"img_resolution\": 32,\n",
        "    \"classes_learned\": [4, 3, 3],\n",
        "\n",
        "    #classifier\n",
        "    \"cls_iters\": 1,\n",
        "    \"cls_lr\": 1e-2,\n",
        "    \"cls_epochs\": 5,\n",
        "\n",
        "    #generator\n",
        "    \"gen_epochs\": 2,\n",
        "    \"gen_lr\": 3e-4,\n",
        "\n",
        "    #mir\n",
        "    \"n_mem\": 1,\n",
        "    \"mir_iters\": 2,\n",
        "    \"reuse_samples\": False,\n",
        "    \"mem_coeff\": 0.12,\n",
        "\n",
        "    \"z_size\": 10,\n",
        "    \"xent_coeff\": 0.1,\n",
        "    \"ent_coeff\": 0.1,\n",
        "    \"div_coeff\": 0.1,\n",
        "    \"shell_coeff\": 0.1,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "OmitFSMM2WJn"
      },
      "outputs": [],
      "source": [
        "'''Agent to handle models, parameters and states'''\n",
        "\n",
        "class Agent:\n",
        "  def __init__(self, hparams):\n",
        "    self.params = hparams\n",
        "    self.state = dict()\n",
        "\n",
        "    self.classifier = None\n",
        "    self.generator = None\n",
        "\n",
        "    self.optimizer = None\n",
        "    self.optimizer_gen = None\n",
        "\n",
        "    self.loss = None\n",
        "    self.loss_gen = None\n",
        "\n",
        "    self.eval = accuracy_score\n",
        "\n",
        "\n",
        "  def set_models(\n",
        "          self,\n",
        "          _generator=None,\n",
        "          _classifier=None,\n",
        "    ):\n",
        "    cls = _classifier #classifier\n",
        "    gen = _generator  #generator\n",
        "\n",
        "    # losses\n",
        "    self.loss = tf.keras.losses.CategoricalCrossentropy()\n",
        "    self.loss_gen = torch.nn.BCELoss()\n",
        "\n",
        "    # optimizers\n",
        "    self.optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=params[\"cls_lr\"])\n",
        "    self.optimizer_gen = torch.optim.Adam(gen.discriminator.parameters(), lr=agent.params[\"gen_lr\"], weight_decay=1e-7)\n",
        "\n",
        "    # classifier pipeline\n",
        "    data_input = keras.Input(shape=self.params[\"input_shape\"], name=\"image\")\n",
        "    cls_output = cls(data_input)\n",
        "    self.classifier = keras.Model(inputs=data_input, outputs=cls_output)\n",
        "    self.classifier.compile(optimizer=self.optimizer, loss=self.loss, metrics=[\"accuracy\"])\n",
        "\n",
        "    # generator pipeline\n",
        "    self.generator = gen"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions for training"
      ],
      "metadata": {
        "collapsed": false,
        "id": "OPqiS9VV8kVk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "outputs": [],
      "source": [
        "'''Generate samples and train the diffusion model at the same time'''\n",
        "\n",
        "def generate(\n",
        "        agent,\n",
        "        num_samples,\n",
        "        dg_weight_1st_order=1,\n",
        "        dg_weight_2nd_order=0,\n",
        "        boosting = 1,\n",
        "        time_min= 0.01, time_max= 1,\n",
        "        class_idx=None,\n",
        "):\n",
        "    latents = torch.randn([num_samples, agent.generator.net.img_channels, agent.params[\"img_resolution\"], agent.params[\"img_resolution\"]], device=agent.params['device'])\n",
        "\n",
        "    class_labels = torch.eye(agent.params['n_classes'], device=agent.params['device'])[torch.randint(agent.params['classes_learned'][agent.state[\"tasks_learned\"]]-1, size=[num_samples], device=agent.params['device'])]\n",
        "    if class_idx is not None:\n",
        "        class_labels[:, :] = 0\n",
        "        class_labels[:, class_idx] = 1\n",
        "\n",
        "\n",
        "    images = agent.generator.sample(boosting, time_min, time_max, dg_weight_1st_order, dg_weight_2nd_order, latents, class_labels)\n",
        "    images = torch.transpose(images, 1, 3)\n",
        "    images = torch.transpose(images, 1, 2)\n",
        "    images, class_labels = images.cpu(), class_labels.cpu()\n",
        "    images, class_labels = images.numpy(), class_labels.numpy()\n",
        "    images, class_labels = tf.convert_to_tensor(images), tf.convert_to_tensor(class_labels)\n",
        "    return images, class_labels\n"
      ],
      "metadata": {
        "id": "2BgWNzhg8kVk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "outputs": [],
      "source": [
        "'''Retrive maximally interferred latent vector for classifier'''\n",
        "\n",
        "def retrieve_mir(agent):\n",
        "\n",
        "    virtual_cls = Classifier()\n",
        "    virtual_cls = utils.get_next_step_cls(\n",
        "        agent.classifier,\n",
        "        virtual_cls,\n",
        "        agent.state[\"task_train_samples\"],\n",
        "        agent.state[\"task_train_targets\"]\n",
        "    )\n",
        "\n",
        "    final_generated = None\n",
        "    final_labels = None\n",
        "    for i in range(agent.params[\"n_mem\"]):\n",
        "\n",
        "        generated, labels = generate(agent, agent.params[\"batch_size\"])\n",
        "\n",
        "        for j in range(params[\"mir_iters\"]):\n",
        "            with tf.GradientTape(persistent=True) as tape:\n",
        "\n",
        "                tape.watch(generated)\n",
        "\n",
        "                y_pre = agent.classifier(generated)\n",
        "                y_virtual = virtual_cls(generated)\n",
        "\n",
        "                # maximise the interference:\n",
        "                XENT = tf.constant(0.)\n",
        "                if params[\"xent_coeff\"] > 0.:\n",
        "                    XENT = tf.keras.losses.categorical_crossentropy(y_virtual, y_pre)\n",
        "\n",
        "                # the predictions from the two models should be confident\n",
        "                ENT = tf.constant(0.)\n",
        "                if params[\"ent_coeff\"] > 0.:\n",
        "                    ENT = tf.keras.losses.categorical_crossentropy(y_pre, y_pre)\n",
        "\n",
        "                # the new-found samples should be different from each others\n",
        "                DIV = tf.constant(0.)\n",
        "                if params[\"div_coeff\"] > 0.:\n",
        "                    for found_generated in range(i):\n",
        "                        DIV += tf.cast(tf.keras.losses.MSE(\n",
        "                            generated,\n",
        "                            final_generated[found_generated * generated.shape[0]:found_generated * generated.shape[0] + generated.shape[0]]\n",
        "                        ) / i, tf.float32)\n",
        "\n",
        "                # (NEW) stay on gaussian shell loss:\n",
        "                SHELL = tf.constant(0.)\n",
        "                if params[\"shell_coeff\"] > 0.:\n",
        "                    SHELL = tf.keras.losses.MSE(\n",
        "                        tf.norm(generated, axis=1),\n",
        "                        tf.ones_like(tf.norm(generated, axis=1))*np.sqrt(params[\"z_size\"])\n",
        "                    )\n",
        "\n",
        "                XENT, ENT, DIV, SHELL = \\\n",
        "                    tf.cast(tf.reduce_mean(XENT), dtype=tf.float64), \\\n",
        "                    tf.cast(tf.reduce_mean(ENT), dtype=tf.float64), \\\n",
        "                    tf.cast(tf.reduce_mean(DIV), dtype=tf.float64), \\\n",
        "                    tf.cast(tf.reduce_mean(SHELL), dtype=tf.float64)\n",
        "\n",
        "                gain = params[\"xent_coeff\"] * XENT + \\\n",
        "                       -params[\"ent_coeff\"] * ENT + \\\n",
        "                       params[\"div_coeff\"] * DIV + \\\n",
        "                       -params[\"shell_coeff\"] * SHELL\n",
        "\n",
        "            gen_grad = tape.gradient(gain, generated)\n",
        "            if gen_grad is not None:\n",
        "                generated = (generated + 1 * gen_grad)\n",
        "\n",
        "        if final_generated is None:\n",
        "            final_generated = generated.numpy().copy()\n",
        "            final_labels = labels.numpy().copy()\n",
        "        else:\n",
        "            final_generated = np.concatenate([final_generated, generated.numpy().copy()])\n",
        "            final_labels = np.concatenate([final_labels, labels.numpy().copy()])\n",
        "\n",
        "    tf.stop_gradient(final_generated)\n",
        "\n",
        "    return final_generated, final_labels"
      ],
      "metadata": {
        "id": "OlENSPig8kVl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "lM8aEv6833SS"
      },
      "outputs": [],
      "source": [
        "'''Train the generator unit'''\n",
        "\n",
        "def train_generator(agent, real_fake_loader):\n",
        "    scaler = lambda x: 2. * x - 1.\n",
        "\n",
        "    # Training\n",
        "    outs = []\n",
        "    cors = []\n",
        "    for data in real_fake_loader:\n",
        "        agent.optimizer_gen.zero_grad()\n",
        "\n",
        "        inputs, labels, cond = data\n",
        "        cond = cond.to(agent.params[\"device\"])\n",
        "        inputs = inputs.to(agent.params[\"device\"])\n",
        "        labels = labels.to(agent.params[\"device\"])\n",
        "        inputs = scaler(inputs)\n",
        "\n",
        "        # Data perturbation\n",
        "        t, _ = agent.generator.vpsde.get_diffusion_time(inputs.shape[0], inputs.device)\n",
        "        mean, std = agent.generator.vpsde.marginal_prob(t)\n",
        "        z = torch.randn_like(inputs)\n",
        "        perturbed_inputs = mean[:, None, None, None] * inputs + std[:, None, None, None] * z\n",
        "\n",
        "        # Forward\n",
        "        with torch.no_grad():\n",
        "            pretrained_feature = agent.generator.encoder(perturbed_inputs, timesteps=t, feature=True).type(torch.cuda.FloatTensor)\n",
        "        label_prediction = agent.generator.discriminator(pretrained_feature, t, sigmoid=True, condition=cond).view(-1)\n",
        "\n",
        "        # Backward\n",
        "        out = agent.loss_gen(label_prediction, labels)\n",
        "        out.backward()\n",
        "        agent.optimizer_gen.step()\n",
        "\n",
        "        # Report\n",
        "        cor = ((label_prediction > 0.5).float() == labels).float().mean()\n",
        "        agent.state[\"eval\"][\"correction_rate\"][-1].append(out.item())\n",
        "        agent.state[\"eval\"][\"discriminator_loss\"][-1].append(cor.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AXTbt9sT8gHE"
      },
      "outputs": [],
      "source": [
        "'''Train the encoder and the classifier unit'''\n",
        "\n",
        "def train_classifier(agent):\n",
        "\n",
        "    mem_x, mem_y = None, None\n",
        "\n",
        "    for it in range(agent.params[\"cls_iters\"]):\n",
        "        history = agent.classifier.fit(agent.state[\"data\"], agent.state[\"target\"], batch_size=agent.params[\"batch_size\"], epochs=1, verbose=0)\n",
        "        if agent.state[\"task\"] > 0:\n",
        "            if it == 0 or not agent.params[\"reuse_samples\"]:\n",
        "                mem_x, mem_y = retrieve_mir(agent, agent.state[\"data\"], agent.state[\"target\"])\n",
        "\n",
        "            if mem_x is not None:\n",
        "                mem_history = agent.classifier.fit(mem_x, mem_y, batch_size=agent.params[\"batch_size\"], epochs=1, verbose=0)\n",
        "\n",
        "                agent.state[\"eval\"][\"retr_cls_loss\"][-1].append(mem_history.history[\"loss\"][0])\n",
        "                agent.state[\"eval\"][\"retr_cls_accuracy\"][-1].append(mem_history.history[\"accuracy\"][0])\n",
        "        agent.state[\"eval\"][\"cls_loss\"][-1].append(history.history[\"loss\"][0])\n",
        "        agent.state[\"eval\"][\"cls_acc\"][-1].append(history.history[\"accuracy\"][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "outputs": [],
      "source": [
        "'''Run an epoch'''\n",
        "\n",
        "def run_cls_epoch(agent):\n",
        "\n",
        "    print(f\"Epoch: {agent.state['epoch']} on Classifier\")\n",
        "\n",
        "    agent.state[\"eval\"][\"cls_loss\"].append([])\n",
        "    agent.state[\"eval\"][\"cls_acc\"].append([])\n",
        "    agent.state[\"eval\"][\"retr_cls_loss\"].append([])\n",
        "    agent.state[\"eval\"][\"retr_cls_accuracy\"].append([])\n",
        "\n",
        "    mem_x, mem_y = retrieve_mir(agent)\n",
        "    train_data = np.concatenate((agent.state[\"task_train_samples\"], mem_x))\n",
        "    train_target = np.concatenate((agent.state[\"task_train_targets\"], mem_y))\n",
        "\n",
        "    classifier_loader = ClassifierDataset(train_data, train_target)\n",
        " \n",
        "    for i, (data, target) in enumerate(agent.state[\"tr_loader\"]):\n",
        "        agent.state[\"data\"] = data\n",
        "        agent.state[\"target\"] = target\n",
        "        train_classifier(agent)\n",
        "\n",
        "    '''Evaluate the models in epoch'''\n",
        "    if agent.state[\"epoch\"] % agent.params[\"print_every\"] == 0:\n",
        "        print(f\"    Classifier loss: {np.mean(agent.state['eval']['cls_loss'][-1])}\"\n",
        "              f\"    Classifier accuracy: {np.mean(agent.state['eval']['cls_acc'][-1])}\" +\n",
        "              (f\"    Retrieval loss: {np.mean(agent.state['eval']['retr_cls_loss'][-1])}\" if agent.state[\"task\"] > 0 else \"\") +\n",
        "              (f\"    Retrieval accuracy: {np.mean(agent.state['eval']['retr_cls_accuracy'][-1])}\" if agent.state[\"task\"] > 0 else \"\"))"
      ],
      "metadata": {
        "id": "xmJWM9GCzym_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Run an epoch'''\n",
        "\n",
        "def run_gen_epoch(agent):\n",
        "  \n",
        "    print(f\"Epoch: {agent.state['epoch']} on Generator\")\n",
        "    \n",
        "    agent.state[\"eval\"][\"discriminator_loss\"].append([])\n",
        "    agent.state[\"eval\"][\"correction_rate\"].append([])\n",
        "\n",
        "    real_samples, real_labels = agent.state[\"task_train_samples\"], agent.state[\"task_train_targets\"]\n",
        "    fake_samples, fake_labels = generate(\n",
        "        agent, len(real_samples) , dg_weight_1st_order=0, dg_weight_2nd_order=0, boosting=0)\n",
        "\n",
        "    train_data = np.concatenate((real_samples, fake_samples))\n",
        "    train_label = torch.zeros(train_data.shape[0])\n",
        "    train_label[:real_samples.shape[0]] = 1.\n",
        "    transform = transforms.Compose([transforms.ToTensor()])\n",
        "    condition_label = np.concatenate((real_labels, fake_labels))\n",
        "    train_dataset = RealFakeConditionalDataset(train_data, train_label, condition_label, transform)\n",
        "\n",
        "    real_fake_loader  = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=agent.params[\"batch_size\"], shuffle=True)\n",
        "    train_generator(agent, real_fake_loader)\n",
        "    \n",
        "\n",
        "    '''Evaluate the models in epoch'''\n",
        "    if agent.state[\"epoch\"] % agent.params[\"print_every\"] == 0:\n",
        "        print(f\"    Discriminator loss: {np.mean(agent.state['eval']['discriminator_loss'][-1])}\"\n",
        "              f\"    Correction rate: {np.mean(agent.state['eval']['correction_rate'][-1])}\")"
      ],
      "metadata": {
        "id": "K48EQq7VGuI-"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "0SyPNSep_K0t"
      },
      "outputs": [],
      "source": [
        "'''Run a task'''\n",
        "\n",
        "def run_task(agent):\n",
        "\n",
        "    print(f\"\\n#############\\n\"\n",
        "          f\"  TASK {agent.state['task']}\\n\"\n",
        "          f\"#############\\n\")\n",
        "  \n",
        "    for epoch in range(agent.params[\"cls_epochs\"]):\n",
        "        agent.state[\"epoch\"] = epoch\n",
        "        run_cls_epoch(agent)\n",
        "    agent.state[\"tasks_learned\"] += 1\n",
        "\n",
        "    print(\"\\n\")\n",
        "\n",
        "    for epoch in range(agent.params[\"gen_epochs\"]):\n",
        "        agent.state[\"epoch\"] = epoch\n",
        "        run_gen_epoch(agent)\n",
        "\n",
        "\n",
        "    '''Evaluate forgetting'''\n",
        "    print(\"\\nEvaluate Task: \", agent.state[\"task\"])\n",
        "    for i in range(agent.state[\"task\"]+1):\n",
        "        data, target = dpt_test[i]\n",
        "        logits = agent.classifier.predict(data, batch_size=256)\n",
        "        #loss\n",
        "        loss = agent.loss(logits, target)\n",
        "        #accuracy\n",
        "        pred = np.argmax(logits, axis=1)\n",
        "        y = np.argmax(target, axis=1)\n",
        "        accuracy = agent.eval(y, pred)\n",
        "    print(f\"    Task {agent.state['task']} forgetting on task {i} : \"\n",
        "          f\"        Loss: {np.mean(loss)}\"\n",
        "          f\"        ACC: {np.mean(accuracy)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "VhbA5MCFCi4r"
      },
      "outputs": [],
      "source": [
        "'''Run the experiment'''\n",
        "\n",
        "def run(agent):\n",
        "    agent.state[\"eval\"] = dict()\n",
        "    agent.state[\"tasks_learned\"] = 0\n",
        "    agent.state[\"eval\"][\"cls_loss\"] = []\n",
        "    agent.state[\"eval\"][\"cls_acc\"] = []\n",
        "    agent.state[\"eval\"][\"retr_cls_loss\"] = []\n",
        "    agent.state[\"eval\"][\"retr_cls_accuracy\"] = []\n",
        "    agent.state[\"eval\"][\"discriminator_loss\"] = []\n",
        "    agent.state[\"eval\"][\"correction_rate\"] = []\n",
        "    for r in range(agent.params[\"n_runs\"]):\n",
        "        agent.state[\"run\"] = r\n",
        "        for task, (tr_loader, ts_loader) in enumerate(zip(dpt_train, dpt_test)):\n",
        "            agent.state[\"task\"] = task\n",
        "            agent.state[\"task_train_samples\"], agent.state[\"task_train_targets\"]  = tr_loader\n",
        "            agent.state[\"task_test_samples\"], agent.state[\"task_test_targets\"] = ts_loader\n",
        "            run_task(agent)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "collapsed": false,
        "id": "AoBLwork8kVn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "BlPHqKTaC41u"
      },
      "outputs": [],
      "source": [
        "agent = Agent(params)\n",
        "agent.set_models(\n",
        "    _classifier=Classifier(),\n",
        "    _generator=Generator(encoder_path=encoder_f, scorenet_path=scorenet_f),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run(agent)"
      ],
      "metadata": {
        "id": "jL7eBmbM33Nw",
        "outputId": "b392d847-1570-498b-e1e0-13087b6a359a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "#############\n",
            "  TASK 0\n",
            "#############\n",
            "\n",
            "Epoch: 0 on Classifier\n",
            "    Classifier loss: 0.38944953699020823    Classifier accuracy: 0.8586285828025477\n",
            "Epoch: 1 on Classifier\n",
            "    Classifier loss: 0.2807658105898815    Classifier accuracy: 0.8975417993630573\n",
            "Epoch: 2 on Classifier\n",
            "    Classifier loss: 0.24176669329594655    Classifier accuracy: 0.9132663216560509\n",
            "Epoch: 3 on Classifier\n",
            "    Classifier loss: 0.23046819424363457    Classifier accuracy: 0.9189390923566879\n",
            "Epoch: 4 on Classifier\n",
            "    Classifier loss: 0.20969912039626176    Classifier accuracy: 0.9230692675159236\n",
            "\n",
            "\n",
            "Epoch: 0 on Generator\n",
            "    Discriminator loss: 0.9922369458252871    Correction rate: 0.04416427313338352\n",
            "Epoch: 1 on Generator\n",
            "    Discriminator loss: 0.9922369458252871    Correction rate: 0.04286144774324626\n",
            "\n",
            "Evaluate Task:  0\n",
            "    Task 0 forgetting on task 0 :         Loss: 2.091749429702759        ACC: 0.8933531746031746\n",
            "\n",
            "#############\n",
            "  TASK 1\n",
            "#############\n",
            "\n",
            "Epoch: 0 on Classifier\n",
            "2/2 [==============================] - 1s 22ms/step - loss: 0.8845 - accuracy: 0.6875\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 2.1396 - accuracy: 0.1914\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 842 calls to <function Model.make_train_function.<locals>.train_function at 0x7fe2d64a25f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 22ms/step - loss: 0.9189 - accuracy: 0.7422\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.8759 - accuracy: 0.8320\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.8171 - accuracy: 0.8438\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.5460 - accuracy: 0.8828\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.4755 - accuracy: 0.9297\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.4959 - accuracy: 0.8867\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.4465 - accuracy: 0.9023\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.3781 - accuracy: 0.9102\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.4683 - accuracy: 0.8867\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.5526 - accuracy: 0.8828\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.3583 - accuracy: 0.9258\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.3763 - accuracy: 0.8906\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-74a7f609a4a4>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-23-41136fada665>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(agent)\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ts_loader\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mts_loader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tasks_learned\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mrun_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-42-63859c8f0eb8>\u001b[0m in \u001b[0;36mrun_task\u001b[0;34m(agent)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"cls_epochs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"epoch\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mrun_cls_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-12dd2963a9fb>\u001b[0m in \u001b[0;36mrun_cls_epoch\u001b[0;34m(agent)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"target\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mtrain_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;34m'''Evaluate the models in epoch'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-6abf4b313f84>\u001b[0m in \u001b[0;36mtrain_classifier\u001b[0;34m(agent)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"task\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mit\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"reuse_samples\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                 \u001b[0mmem_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmem_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretrieve_mir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"target\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmem_x\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-15bfa21f0adb>\u001b[0m in \u001b[0;36mretrieve_mir\u001b[0;34m(agent, samples, target)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mvirtual_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     virtual_cls = utils.get_next_step_cls(\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mvirtual_cls\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/continual-learning-ait-main/utils.py\u001b[0m in \u001b[0;36mget_next_step_cls\u001b[0;34m(current_classifier, virtual_classifier, sample, target)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0mvirtual_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0mvirtual_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"adam\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"categorical_crossentropy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0mvirtual_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvirtual_classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1683\u001b[0m                         ):\n\u001b[1;32m   1684\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1685\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1686\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    957\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0;31m# no_variable_creation function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 959\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    960\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m       _, _, filtered_flat_args = (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m       (concrete_function,\n\u001b[1;32m    142\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    144\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1755\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1756\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1757\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1758\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1759\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    382\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image generation"
      ],
      "metadata": {
        "collapsed": false,
        "id": "1TZSRE2moKuY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "images = generate(agent, 1, 0.01, 1, 1, 0, 10, 4)"
      ],
      "metadata": {
        "id": "aT_2YcuyLYWN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def disp(image):\n",
        "    image = (image + 1)* 127.5\n",
        "\n",
        "    plt.imshow(image.astype(np.uint8))\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "M2GlqzEzMEod"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "disp(samples.numpy()[5])"
      ],
      "metadata": {
        "id": "BcdjXCeTlHb7",
        "outputId": "8ac077bf-a9ae-456e-eb08-1671dd5f0d8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "disp(mem_x[0])"
      ],
      "metadata": {
        "id": "9gFH49EUlBgM",
        "outputId": "65b2c627-1fc9-4641-c207-8ed75c9509a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAY+ElEQVR4nO3cy28dh3XH8TP3/SQvKVLUg6TeVuxUVh5I4zhIWgQF3GaT/hXZNF0U+ROy7D6LLls0aHZB0zYbww4UJIgVO35IsVzZEi1ZlCiSurwk73vuzO3Cwdnm/AAHbYrvZ31wOJw7c393FvNL5vP53AAAMLPC//YBAAD+7yAUAACOUAAAOEIBAOAIBQCAIxQAAI5QAAA4QgEA4ErRwR/9879Ii2+/91Z4dnWlI+2eJXl49lm/J+1WXuXL8/hxmJmVy5Xw7GJnUdo9GE+k+YVOJzz75q9/I+3+2U/+MzybTWfS7o2VU+HZl7/6NWn3tW9+XZo/9cJz4dnFBe3zXG4thGcbzbq0OxOu2+3tbWn39qP4/Ph4IO3O00yav3f/o/Dsg60taXdnaSk8u765Ke024TsonaXS6n/8wQ/+4AxPCgAARygAAByhAABwhAIAwBEKAABHKAAAHKEAAHCEAgDAEQoAAEcoAAAcoQAAcOHuo/fvvC8tfrrzNDxbKSXS7lkS70AZTMfSbrP4sVRK8S4jMzMrhU+3dfd60upJqnUfWRYvWMlnWj/R6TPxfqLFelPavVyI9/wUZ1pXzvUvXJfmly5shGfzqXYs4+N+eHb72b60e393Lzy7JXYCjUfx++1gXzvuWr0hzReS+G9epfPMzCzP4v1RlVJZ2l2r1cKz44n6/faH8aQAAHCEAgDAEQoAAEcoAAAcoQAAcIQCAMARCgAARygAAByhAABwhAIAwIV7F27/7nfS4lH/KDz74ON70u55IV4ZkAmzZmaVavwV80ISr60wM5vn8QqNJP4WvZmZlSrasRTL8VfvR4OhtLvTasWPQzgnZmY2ScOjzVJVWr23uyvN74ziVRTZcCrtHvWPw7Pjkfb5dPe74dl5rl2IFaFaYmVpWdpda8QrTszMjoSqkEQ4bjOzXOrF0Do0FjuL4dnmTKuJieBJAQDgCAUAgCMUAACOUAAAOEIBAOAIBQCAIxQAAI5QAAA4QgEA4AgFAIAjFAAALlyYk+Vah1CxFO/iSZKKtLtaFrpEcq0XplorhmcTi8+amWVpvEemWdV6XrKi2MNk8c6hheUlaXerFu8cysczaXe6H++zORrEZ83M7t/fkuat3QiPzgZjaXVL6Pk56vWk3b+68YvwbO9A2z2baZ+nIilqv2GvXb8eni2XxftH+Aq6ceOGtHs4HIRnK1Wt3+vvv/vdPzjDkwIAwBEKAABHKAAAHKEAAHCEAgDAEQoAAEcoAAAcoQAAcIQCAMARCgAAF363++6Hd6XFi+1meHbYP5Z2N4UqioJNpN3tdhqerVa0V8znabwqpJLHKzHMzIpiLUZBqMUoFbTfDiWhA2Ai1iIMZ/HPc1zUzuH9rfvS/E7vIDzbPziUdp86tRaeHffjtQhmZr1uNzx71NOOOxeu20kav9fMzKwYr2YxM0vT+LVVKGg1F5bEj6Ug3j+tVuuPtju08zPfCAD4k0UoAAAcoQAAcIQCAMARCgAARygAAByhAABwhAIAwBEKAABHKAAAHKEAAHDhwo/uQU9a3KjVwrO7e/vS7kIx3n00EfpPzMwuX2iHZ1uZtrts8e4jS7Tennkm9sgI/URzi8+amSXCeUnE3Vk53jlTXIj3b5mZFctlab5ZjV/j9TWtJ6vVFq5D4V4zM+vu74VnyyWtE0hpJ0rF3qu5+BO2Vouf8+P+UNo9ncXvtxdeeF7afenSpfCseg4jeFIAADhCAQDgCAUAgCMUAACOUAAAOEIBAOAIBQCAIxQAAI5QAAA4QgEA4MLvsKfpVFpcLMdfj280tTqCw+NBeHacxSsxzMxanbXwbHk+kXZn48PwbLXe0HZnWi1GuRKvdCgVtfqH7sFBeHYy0V7TH07j12GlWZd2f+1rX5XmjwfxaoTjQfyaNTMbj8fxYbHq4J133gnPDo+Ppd25UP9wdKTtbizEqz/MzJJEKN0Qfx6XhO+3al27DsfCNa7UikTxpAAAcIQCAMARCgAARygAAByhAABwhAIAwBEKAABHKAAAHKEAAHCEAgDAEQoAABcu8FA7NtI03oFSrlSl3bM03iFULmndR41GLTy7uhTvSTIzS2bxPpuTK8vS7rUzp6T5s+vr4Vm1o+bnr/88PFtN59Luge2FZ6XuGzOr1CrSfFP5SVXQ/s8sj98/Y6FvyMxsNIl3dhXK2v3TFvqm9nbjn6WZWamqfT5zi/eBFcX/s1qLf2clBe23d0n4zkqSz/53PU8KAABHKAAAHKEAAHCEAgDAEQoAAEcoAAAcoQAAcIQCAMARCgAARygAAFy45mKei6/pZ/FXzHNxdz7PwrMXz12Udq+txasrut0DaXf/KD7/uBuv8jAz+8rSqjR/7cz58GxloS/tfv7Lo/DsQntR2r314GF4dnFZqwpJc60Wo1SOV6IkFj8nZmZCQ4Pt7DyVVvcO49dWvVKWdneazfBsUtDOt1rpUCqFv96sJtRWmJnV6vH5SkWr5ygUhMoNtX8o8vc/+5UAgD9VhAIAwBEKAABHKAAAHKEAAHCEAgDAEQoAAEcoAAAcoQAAcIQCAMARCgAAFy4HGY8n0uKjo+PwbJqm0u6l5ZXw7Mvf+Etp99vvvBeefbqrdc7k83ihTZbF+53MzNbOXZbmd7rxPqPus2fS7pOnz4dnN8+dk3af2rwUnm20W9LuVO3gms3Cs9Wy1q2TTuO7H28/0XYL99tsPJZ2Hx10w7PT6VTaXUnFeaG36dyJDWn3VPjsO52OtDvLhXt/rl2zETwpAAAcoQAAcIQCAMARCgAARygAAByhAABwhAIAwBEKAABHKAAAHKEAAHCEAgDAhbuP/uqvX5EWdzpL8dnFRWn3orC7P9Q6m7afxPuMmu22tHsm9BmVxEqT1dV1ab5QqIVnB0Otm+rhJzvh2c3z8S4jM7NKpR6e/e+796TdQ7Hn5+qV+LEfPDuQdifxW9POn78g7X7/9u3w7Lgf78j6lPA7M9E250onkJkVC/FjWVk9Ie3udg/jw2I/UalUlOY/azwpAAAcoQAAcIQCAMARCgAARygAAByhAABwhAIAwBEKAABHKAAAHKEAAHDhd+n/7nvfkxb3evHXwOv1eHWB6oc//Cdpvt1qhWebTa3mYpxO47vrTWn3mdNnpPn9vWfh2ac7u9LuI+Gz395+LO2uVavh2f7xsbR7kmp1Hnkery9YWTkp7d76eCs8+/k/uybtzmbx//Nn//FTafd4EN9dqlSk3aVSvPrDzGxvN37dHol1Hqtrp8Kz02n8vv9UOTyZJJ/973qeFAAAjlAAADhCAQDgCAUAgCMUAACOUAAAOEIBAOAIBQCAIxQAAI5QAAA4QgEA4MJlIh/dj3exmJl1Fjvh2YbQN2RmNuwP4rMDrf+mXov3jmSzibZb6HrpLGq9SivLHWn+7t274dleN96TZGbWbsc/z73dHWn3c1efC89ePL8p7d7e0Y7l3kcfhmeXF5ak3fM8Cc/2hfvBzOzatevh2eNeT9p94/XXwrNHRyNpd1HsPprP8/istNksFXqy1N2lktJ9JC4P4EkBAOAIBQCAIxQAAI5QAAA4QgEA4AgFAIAjFAAAjlAAADhCAQDgCAUAgAu/Nz4aaa+kX758OTx7+vRpafd0HK+X+P73/0Ha/XT3qTC7J+3e7x6EZ7PpTNq90KpJ8816/FX6z78Qr5YwM1tfXw/PDkZaRUNReK2/WNA6AMolbb5erodnG434rJlZU6h+2XnyWNo9nU7Ds6+88oq0e7Edr2d5/fVXpd1Zpt0Tyjm8dv2L0u7xJP4dtHxiRdrdEo67WCxKuyN4UgAAOEIBAOAIBQCAIxQAAI5QAAA4QgEA4AgFAIAjFAAAjlAAADhCAQDgCAUAgAt3H53b3JQWN+vxrpdU6GIxM6vWKuHZjY2z0u6LF8+HZztLHWl3YvGekl6vJ+1OU+0cLi8vhGeLBe23w9HRUXi2UtF2Ly/Fu3X6xz1p94X1DWl+/Wz82qrXG9LuLMvCs1cvn5d2F4ROqEpJ69Z57kq88+zlr78k7d7e3pbmZ9k8PJvP4ufbzKxWqYZnC4nWqZUJx5JnubQ7gicFAIAjFAAAjlAAADhCAQDgCAUAgCMUAACOUAAAOEIBAOAIBQCAIxQAAC5cczEZDbXFRSFv8pm0O5nHX73Pc+018GIhvruYaJlaLpfDs7u7O9LuWjX+2r2Z2fOfuxqeVc/haDgKzw7H2nW1vLQUnr10/ry0u1bTqijm8/h5GY3G0u5ZmoZn07r22SufZ5Zp92al0wnPfuXPtZqLzx0fS/P9/iA8OxrFr1kzs5JwL/eF+8HMbG9vLz6sNWiE8KQAAHCEAgDAEQoAAEcoAAAcoQAAcIQCAMARCgAARygAAByhAABwhAIAwBEKAAAX7j568uSxtPjs2TPh2WwW73kx0zqHWs2WtLtcDp8SS2daL0yxGO9VOrm6Ku0uFLR8T5J4aYq6u9NZDM+287a0W+phms+l3Zn4eSq9M/V6TVo9r8Xn8zyTdis9P5OJtNoS4VpRr6vFhfh1ZWbWWexI8wrl/xyOtZM4HMY7m9749RvS7gieFAAAjlAAADhCAQDgCAUAgCMUAACOUAAAOEIBAOAIBQCAIxQAAI5QAAA4QgEA4MJFP8NBvI/DzGz70aPw7C9u/ELa/dWXXgrPfvFLX5R2Hx/He5haLa1XSenWWVlZkXYLVUZmZjYVSm20BiGzmfB/FotqZ1N8Phe7j2yudQhJx5JrvUpKL1ClUpV2l0rxfq9ypSLtVvqm1O4j9fOcC/OT8VjaPcvi18pCW+v3unThYnj2/r370u4InhQAAI5QAAA4QgEA4AgFAIAjFAAAjlAAADhCAQDgCAUAgCMUAACOUAAAuPD77rdv35IWv/mbm+HZV199Tdr98YMH4dmLl+KvjJuZpdNpePbo+EjaXSnHKwPa4qvx9XpdOxahvqBYLEq7lc6NJN4q8vtjif+OUWoozMwS8TdSqRw/L9VqTdqdCTUKE6GyxMwsn+fh2XpNO26lWmIgVudMptr/mVj8Otzd25V2d7u98Owsi59vM7Nbt+LftU+2H0u7I3hSAAA4QgEA4AgFAIAjFAAAjlAAADhCAQDgCAUAgCMUAACOUAAAOEIBAOAIBQCAC3cfPXywJS1+9PBRePbKlSvS7n6/H5596623pN3XX3wxPDsejaXdaRov+hlPtN0lsZ+oXC6HZyuVqrS7Xo/35ZSK4UvQzMxG41F4ttFoSrtrNa0/anIU777a29W6dZTuq9Nnz0i7i4X4taJcs2ZmmdDzo3aHPXu2L833j+PdSu+//760+8mTnfDsrdu/k3YfCddVp9ORdkfwpAAAcIQCAMARCgAARygAAByhAABwhAIAwBEKAABHKAAAHKEAAHCEAgDAhTsGNte1V+nT8SQ8+9LLL0u7j4Sai1vv3ZJ2f+7q1fBslmXS7vl8Hp7NhboAM7OsMNPm8/j+6XQq7R4LVRSFgva7RDkv6jmcTLT/88f/9uPw7I0bN6Tdm5ub4dlv/MU3pd3f/vbfhGdbrZa0e29nLzw7GMZrKMzM8jyR5jvLJ8Kzb771trQ7KcSP5d79e9LuhYX4OZ9M4pUyUTwpAAAcoQAAcIQCAMARCgAARygAAByhAABwhAIAwBEKAABHKAAAHKEAAHCEAgDAhbuPrl69LC1uNuL9HYuLi9LuSZqGZ+/evSvt/uTRo/DsUqcj7a5Wq+HZYlHLa7GGyXKh+6hYCl8mvz+W+MEkidZno3QlFcRzePu21pP1rz/6UXi2++yZtHtr6+Pw7DvvvivtHo/H4dm//c53pN27u0/Ds7n4m7Te1HqYpkL3VaFckXYPhd6mtbVVaffCQjs8K9SphfGkAABwhAIAwBEKAABHKAAAHKEAAHCEAgDAEQoAAEcoAAAcoQAAcIQCAMCF+wu6B3vS4jSPV1FUajVp96A/DM/e/UCrufjZT/8rPLu+sS7tXl5eDs+eOnNK2r2ysiLN1+r18Gyeq+/Sx+fVOg+l5mIyidc5mJm98cavpfneQby64vKVS9Luy5fitTJ37tyRdv/7T34Snr363HPS7oZwXX1490NpdxpvrTAzs+3H2+HZVrMp7T579nR4djaJV2KYmV24cCE8+5ubN6XdETwpAAAcoQAAcIQCAMARCgAARygAAByhAABwhAIAwBEKAABHKAAAHKEAAHCEAgDAhbuPer0DafHBQbyfaK+zK+0+POzFZ8Xjfu21V8OzjUa858XMrNVaCM+ub2xKu9dOrUnzZ9fjvU1rayel3cvLi+HZhYX4rJlZrVYNz2ZZJu2+99FH0ny1WgnPXr9+Tdr95S99OTybCF1TZmY3b74Znt26f1/a/a1vfSs8++ab8eMwM3vw8JE0r/QwJUJXm5nZ4bP98GwhCX/NmplZNp2FZ1u1srQ7gicFAIAjFAAAjlAAADhCAQDgCAUAgCMUAACOUAAAOEIBAOAIBQCAIxQAAC78/nWlUpMW1xvx2d/+Vnvd/ZHwuntBjb0kD48OBn1pda93GJ795BPtlf5SWXuVvt1uh2eXljrS7rVTp8Kzm5tancfGxkZ49uRJrZ7j8ePH0rxSc7J+Nl4rYmbWbDbDs6fPnJF2D4aD8OzNmzel3V+4fj08WyoWpd3HQr2Nmdl0PArPvvveu9LuRiP+BTccjqXdbeG6OrepXVcRPCkAAByhAABwhAIAwBEKAABHKAAAHKEAAHCEAgDAEQoAAEcoAAAcoQAAcIQCAMCFC3MuX3leWtw7jPf8lCsVaXe5FM+yCxfjXTlmZq1mKzybplNp99Od3fBs91n8/JmZHfe1HqbDg65wLPvS7q37H4dn337rHWl3R+hhOn063sFkZrbz9Kk0v3JiOTxbF7pyzMx6Qs9PsxHvSTIzy7MsPPv6a69Ju7e2tsKzszSVdh8K3ylm2ndQpVSWdqez+LEPhkNp98b6Wnj2xJLW7xXBkwIAwBEKAABHKAAAHKEAAHCEAgDAEQoAAEcoAAAcoQAAcIQCAMARCgAARygAAFy4+6ghdAKZmSWFeN40m1ovzJXLF8Oz8zyXdmdCL4zSf2JmdtQ7Cs/2uj1pd+8wvtvM7LB3EJ7tHqjHMgjPDgYjaff29qPw7NMnj6XdxYrWf7PQbodnc/E6tLkwm2irlWv84CB+nZiZ7Qs9WfNc+SfNkkT7R1OpW0k7lrkwXhS62szM3n77t+HZ6QtXpd0RPCkAAByhAABwhAIAwBEKAABHKAAAHKEAAHCEAgDAEQoAAEcoAAAcoQAAcOGaC5XyRnq5rB1GqRjPMrXmQqkjKEy11+4XF+NVIZ0Frfojz09J82k6Dc8eHw+l3YfH8eqK7sGhtLvb7YZnB/2+tPuZeCz7wrE8efJE2v3itRfDsx988Ctp92w2C89Op/HrxEwsi5iL1R8ipYpCrQqpN2rh2cXOgrR7+cRSeHZ1dVXaHcGTAgDAEQoAAEcoAAAcoQAAcIQCAMARCgAARygAAByhAABwhAIAwBEKAABHKAAAXLh0qNWM9/aYmZXLxfDsXOxAydJ4d4vS8fPpscQLU4ql+P9oZlatCOckj/+PZmZZps2bVcOTjWZd2nxiJf5bY2NdO+7JdBKeHY3H0u7d/QNp/qN7H4dnf/lLrZ/o4cNH4dlb770n7U6F7iOpP8jEzrNK/Bo0M6tUtY60Rj3eH7a4uCjt3ji3GZ49uRrvMlKPpV6LdzBF8aQAAHCEAgDAEQoAAEcoAAAcoQAAcIQCAMARCgAARygAAByhAABwhAIAwIXfG681tKqDklJzYVrNxWQcrzqoixUNWZaFZ2dC3canu+PzuVpzIVQXmJnNhGMpif9nPot3I6Ti7mYrXl1QLGo1JGfPnJXm18+cDs/eufOBtHvrozvx4blW5bJyYiE8Wypp1RLLJ5bDsyfXTmq7l7W6iIWFeF1Eu92Wdjca8euwUBC6P8ysoHSF/BHwpAAAcIQCAMARCgAARygAAByhAABwhAIAwBEKAABHKAAAHKEAAHCEAgDAEQoAABcuNpnP4302ZlqHUKVakXZbLX4sRbG7ZZam4dl8PpJ2F4QunvlcOydJTe1LEfqJplq3znwW/+xHI+0cjsdj4UC0a7Yi9HWZma2fWQvPnl5bkXYrXVbjSbwLzMxsLnz25bJ2Hdab8U6gcqUs7S4UtXu5WIz/5i0k2u9j5dLKMq3bLc/j89WK+N0ZwJMCAMARCgAARygAAByhAABwhAIAwBEKAABHKAAAHKEAAHCEAgDAEQoAABd+bzwxtUYhPp+Iq0ul+OvxhYKWe4nwJn1e/eO9vl4UX7vPsngtgpnZRKiuKBa0+odSTfl8tN31ej08K7ZcmJn2eSr1Bcpnb2ZWKMRvirZQW2FmZsK1VRFrFJQKDfXjUe57M+3ez+fi55PEr9s01e7NqXBvlsQanwieFAAAjlAAADhCAQDgCAUAgCMUAACOUAAAOEIBAOAIBQCAIxQAAI5QAAA4QgEA4JL5XG+IAQD8/8STAgDAEQoAAEcoAAAcoQAAcIQCAMARCgAARygAAByhAABwhAIAwP0PbaTaaFB0b6MAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "disp(images[0][1])"
      ],
      "metadata": {
        "id": "yNc1tDejMGoB",
        "outputId": "87c56ccf-d5eb-4b5e-a9c2-645da285e5e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation, testing"
      ],
      "metadata": {
        "collapsed": false,
        "id": "UiiKIl618kVn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "def evaluate(loader, first_n_tasks=None):\n",
        "    for task, tr_loader in enumerate(loader):\n",
        "        print(\"Task: \", task)\n",
        "        data, target = tr_loader.batch(124)\n",
        "        logits = agent.classifier_model(data)\n",
        "        pred = np.argmax(logits, axis=1)\n",
        "        report = agent.eval(np.argmax(target, axis=1), pred)\n",
        "        loss = tf.keras.losses.categorical_crossentropy(target, logits)\n",
        "        print(report)\n",
        "        print(\"Mean loss: \", np.mean(loss))"
      ],
      "metadata": {
        "id": "r_K9lbNh8kVn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4I2ZLTm-JnX8"
      },
      "outputs": [],
      "source": [
        "print(\"Evaluation on training set:\")\n",
        "evaluate(train_loader)\n",
        "print(\"Evaluation on test set:\")\n",
        "evaluate(test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utils for development"
      ],
      "metadata": {
        "collapsed": false,
        "id": "vOxdRLeJ8kVn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "59341"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "# Garbage collection\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "NCdIwGMq8kVn",
        "outputId": "cffd2280-970f-4435-da6b-cb20a1e40a34",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}