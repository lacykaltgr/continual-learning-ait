{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/lacykaltgr/continual-learning-ait/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pveLpmUzEF5A",
    "outputId": "8522ff4a-f1e2-4c03-c20e-70125eca9913"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-05-14 16:36:52--  https://github.com/lacykaltgr/continual-learning-ait/archive/refs/heads/main.zip\r\n",
      "Resolving github.com (github.com)... 140.82.121.4\r\n",
      "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 302 Found\r\n",
      "Location: https://codeload.github.com/lacykaltgr/continual-learning-ait/zip/refs/heads/main [following]\r\n",
      "--2023-05-14 16:36:53--  https://codeload.github.com/lacykaltgr/continual-learning-ait/zip/refs/heads/main\r\n",
      "Resolving codeload.github.com (codeload.github.com)... 140.82.121.10\r\n",
      "Connecting to codeload.github.com (codeload.github.com)|140.82.121.10|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: unspecified [application/zip]\r\n",
      "Saving to: ‘main.zip’\r\n",
      "\r\n",
      "main.zip                [  <=>               ]   1.67M  4.95MB/s    in 0.3s    \r\n",
      "\r\n",
      "2023-05-14 16:36:53 (4.95 MB/s) - ‘main.zip’ saved [1751742]\r\n",
      "\r\n",
      "Archive:  main.zip\r\n",
      "7628fe5a1ea465ed4b25e68ee85736ac92ef6d09\r\n",
      "   creating: continual-learning-ait-main/\r\n",
      "  inflating: continual-learning-ait-main/README.md  \r\n",
      "  inflating: continual-learning-ait-main/classifier.py  \r\n",
      "  inflating: continual-learning-ait-main/constants.py  \r\n",
      "  inflating: continual-learning-ait-main/data_preparation.py  \r\n",
      "  inflating: continual-learning-ait-main/generator.py  \r\n",
      "  inflating: continual-learning-ait-main/img.png  \r\n",
      "  inflating: continual-learning-ait-main/main.ipynb  \r\n",
      "   creating: continual-learning-ait-main/models/\r\n",
      "  inflating: continual-learning-ait-main/models/classifier.h5  \r\n",
      "  inflating: continual-learning-ait-main/models/encoder.h5  \r\n",
      "   creating: continual-learning-ait-main/notebooks/\r\n",
      "  inflating: continual-learning-ait-main/notebooks/classifier.ipynb  \r\n",
      "  inflating: continual-learning-ait-main/notebooks/data_preparation.ipynb  \r\n",
      "  inflating: continual-learning-ait-main/notebooks/generator.ipynb  \r\n",
      "  inflating: continual-learning-ait-main/utils.py  \r\n"
     ]
    }
   ],
   "source": [
    "'''Download the files '''\n",
    "'''Only for colab'''\n",
    "\n",
    "!wget https://github.com/lacykaltgr/continual-learning-ait/archive/refs/heads/main.zip\n",
    "!unzip main.zip\n",
    "!find continual-learning-ait-main -type f ! -name \"main.ipynb\" -exec cp {} . \\;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "vjfVuEmXECoL"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "#from keras.metrics import Accuracy\n",
    "\n",
    "#import classifier\n",
    "#from generator import Generator\n",
    "#from classifier import Encoder, Classifier\n",
    "import utils\n",
    "from data_preparation import load_dataset, CLDataLoader\n",
    "\n",
    "import gc\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load the dataset"
   ],
   "metadata": {
    "collapsed": false,
    "id": "zzYWiWfZ8kVi"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "TaH3bi-5crqD",
    "outputId": "98e6db14-746a-4303-a183-f910a8402347",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [],
   "source": [
    "dpt_train, dpt_test = load_dataset('cifar-10', n_classes_first_task=4, n_classes_other_task=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "yIESUurDeOCR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M2\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "train_loader = CLDataLoader(dpt_train, batch_size , train=True)\n",
    "test_loader = CLDataLoader(dpt_train, batch_size, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Define parameters and agent"
   ],
   "metadata": {
    "collapsed": false,
    "id": "3Jl-cBYs8kVj"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "GY9MAk581iYQ"
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    #general\n",
    "    \"n_runs\": 1,\n",
    "    \"n_tasks\": 3,\n",
    "    \"n_classes\": 10,\n",
    "    \"input_shape\": (32, 32, 3),\n",
    "    \"embedding_shape\": (6, 6, 8),\n",
    "    \"samples_per_task\": 10000,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"eval_batch_size\": 1,\n",
    "    \"print_every\": 1,\n",
    "\n",
    "    #classifier\n",
    "    \"cls_iters\": 1,\n",
    "    \"cls_lr\": 1e-2,\n",
    "    \"cls_epochs\": 5,\n",
    "\n",
    "    #generator\n",
    "    \"gen_epochs\": 1,\n",
    "    \"num_steps\": 3,\n",
    "    \"gen_lr\": 2e-4,\n",
    "    \"gen_iters\": 1,\n",
    "    \"input_latent_strength\": 0.9,\n",
    "    \"temperature\": 0.9,\n",
    "\n",
    "    #mir\n",
    "    \"n_mem\": 2,\n",
    "    \"mir_iters\": 3,\n",
    "    \"reuse_samples\": True,\n",
    "    \"mem_coeff\": 0.12,\n",
    "    \"z_size\": 10,\n",
    "    \n",
    "    \"gen_ent_coeff\": 0.5,\n",
    "    \"gen_div_coeff\": 0.5,\n",
    "    \"gen_shell_coeff\": 0.5,\n",
    "    \"cls_xent_coeff\": 0.5,\n",
    "    \"cls_ent_coeff\": 0.5,\n",
    "    \"cls_div_coeff\": 0.5,\n",
    "    \"cls_shell_coeff\": 0.5,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "OmitFSMM2WJn"
   },
   "outputs": [],
   "source": [
    "'''Agent to handle models, parameters and states'''\n",
    "\n",
    "class Agent:\n",
    "  def __init__(self, hparams):\n",
    "    self.params = hparams\n",
    "    self.state = dict()\n",
    "\n",
    "    self.classifier = None\n",
    "    self.generator = None\n",
    "    self.encoder = None\n",
    "    self.encoder_classifier = None\n",
    "\n",
    "    self.eval = accuracy_score\n",
    "\n",
    "\n",
    "  def set_models(\n",
    "          self,\n",
    "          _generator=None,\n",
    "          _classifier=None,\n",
    "          _encoder  = None,\n",
    "    ):\n",
    "    cls = _classifier #classifier\n",
    "    gen = _generator  #generator\n",
    "    enc = _encoder #encoder\n",
    "\n",
    "    self.optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=params[\"cls_lr\"])\n",
    "    self.optimizer_gen = tf.keras.optimizers.legacy.Adam(learning_rate=params[\"gen_lr\"])\n",
    "\n",
    "    #encoder pipeline\n",
    "    data_input = keras.Input(shape=self.params[\"input_shape\"], name=\"image\")\n",
    "    enc_output = enc(data_input)\n",
    "    self.encoder = keras.Model(inputs=data_input, outputs=enc_output)\n",
    "\n",
    "    # classifier pipeline\n",
    "    latent_input = keras.Input(shape=self.params[\"embedding_shape\"], name=\"latent\")\n",
    "    cls_output = cls(latent_input)\n",
    "    self.classifier = keras.Model(inputs=latent_input, outputs=cls_output)\n",
    "    self.classifier.compile(optimizer=self.optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    # encoder - classifier pipeline\n",
    "    data_input = keras.Input(shape=self.params[\"input_shape\"], name=\"image\")\n",
    "    enc_output = enc(data_input)\n",
    "    enc_cls_output = cls(enc_output)\n",
    "    self.encoder_classifier = keras.Model(inputs= data_input, outputs = enc_cls_output)\n",
    "    self.encoder_classifier.compile(optimizer=self.optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    \n",
    "    # generator pipeline\n",
    "    self.generator = gen\n",
    "    #latent_input = keras.Input(shape=self.params[\"embedding_shape\"], name=\"latent\")\n",
    "    #gen_output = gen(latent_input)\n",
    "    #self.generator = keras.Model(inputs = latent_input, outputs = gen_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Functions for training"
   ],
   "metadata": {
    "collapsed": false,
    "id": "OPqiS9VV8kVk"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "'''Generate samples and train the diffusion model at the same time'''\n",
    "\n",
    "#plusz lehetne itt még kritérium hogy ne menjen olyan messze az alaptól --- similarity loss\n",
    "#plusz még lehetne talán egy discriminator is, hogy valós reprezentációkat tanuljon meg\n",
    "\n",
    "\n",
    "def generate(agent, cls=None, input_latent=None, train=True, coeff=1.0):\n",
    "\n",
    "    if cls is None:\n",
    "      cls = agent.classifier\n",
    "\n",
    "    batch_size = input_latent.shape[0]\n",
    "    latent, alphas, alphas_prev, timesteps = agent.generator.initialize(params, input_latent, batch_size)\n",
    "\n",
    "\n",
    "    for index, timestep in reversed(list(enumerate(timesteps))):\n",
    "        if train:\n",
    "            with tf.GradientTape() as tape:\n",
    "                e_t = agent.generator.get_model_output(\n",
    "                    latent,\n",
    "                    timestep,\n",
    "                    batch_size,\n",
    "                )\n",
    "                a_t, a_prev = alphas[index], alphas_prev[index]\n",
    "                latent = agent.generator.get_x_prev(latent, e_t,  a_t, a_prev, params[\"temperature\"])\n",
    "\n",
    "                pred = cls(latent)\n",
    "                pred_true = utils.get_one_hot_predictions(pred) #ezt nem fixen kell mecsinálni\n",
    "                confidence_loss = coeff*tf.reduce_mean(tf.keras.losses.categorical_crossentropy(pred_true, pred))\n",
    "                #print(confidence_loss)\n",
    "                similarity_loss = 0.1 * tf.reduce_mean(tf.square(latent - e_t))\n",
    "                #print(similarity_loss)\n",
    "                loss = confidence_loss + similarity_loss\n",
    "                agent.state[\"epoch_eval\"][\"gen_loss\"].append(loss)\n",
    "            grads = tape.gradient(loss, agent.generator.trainable_variables)\n",
    "            agent.optimizer_gen.apply_gradients(zip(grads, agent.generator.trainable_variables))\n",
    "        else:\n",
    "            e_t = agent.generator.get_model_output(\n",
    "                latent,\n",
    "                timestep,\n",
    "                batch_size,\n",
    "            )\n",
    "            a_t, a_prev = alphas[index], alphas_prev[index]\n",
    "            latent = agent.generator.get_x_prev(latent, e_t,  a_t, a_prev, params[\"temperature\"])\n",
    "\n",
    "    return latent\n"
   ],
   "metadata": {
    "id": "2BgWNzhg8kVk"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "'''Retrive maximally interferred latent vector for classifier'''\n",
    "\n",
    "def retrieve_gen_for_cls(agent):\n",
    "\n",
    "    print(\"Retrieving latent vector for classifier...\")\n",
    "\n",
    "    latent = agent.encoder(agent.state[\"data\"])\n",
    "    virtual_cls = Classifier()\n",
    "    virtual_cls = utils.get_next_step_cls(\n",
    "        agent.cls,\n",
    "        virtual_cls,\n",
    "        latent,\n",
    "        agent.state[\"target\"]\n",
    "    )\n",
    "\n",
    "    #mean_latent = tf.cast(tf.reduce_mean(latent, axis=0), tf.float64)\n",
    "    final_latent = None\n",
    "\n",
    "    for i in range(agent.params[\"n_mem\"]):\n",
    "\n",
    "        generated = generate(agent, input_latent=latent, train=False)\n",
    "\n",
    "        for j in range(params[\"mir_iters\"]):\n",
    "            with tf.GradientTape(persistent=True) as tape:\n",
    "\n",
    "                tape.watch(generated)\n",
    "\n",
    "                y_pre = agent.classifier(generated)\n",
    "                y_virtual = virtual_cls(generated)\n",
    "\n",
    "                # maximise the interference:\n",
    "                XENT = tf.constant(0.)\n",
    "                if params[\"cls_xent_coeff\"] > 0.:\n",
    "                    XENT = tf.keras.losses.categorical_crossentropy(y_virtual, y_pre)\n",
    "\n",
    "                # the predictions from the two models should be confident\n",
    "                ENT = tf.constant(0.)\n",
    "                if params[\"cls_ent_coeff\"] > 0.:\n",
    "                    ENT = tf.keras.losses.categorical_crossentropy(y_pre, y_pre)\n",
    "\n",
    "                # the new-found samples should be different from each others\n",
    "                DIV = tf.constant(0.)\n",
    "                if params[\"cls_div_coeff\"] > 0.:\n",
    "                    for found_generated in range(i):\n",
    "                        DIV += tf.keras.losses.MSE(\n",
    "                            generated,\n",
    "                            final_latent[found_generated * generated.shape[0]:found_generated * generated.shape[0] + generated.shape[0]]\n",
    "                        ) / i\n",
    "\n",
    "                # (NEW) stay on gaussian shell loss:\n",
    "                SHELL = tf.constant(0.)\n",
    "                if params[\"cls_shell_coeff\"] > 0.:\n",
    "                    SHELL = tf.keras.losses.MSE(\n",
    "                        tf.norm(generated, axis=1),\n",
    "                        tf.ones_like(tf.norm(generated, axis=1))*np.sqrt(params[\"z_size\"])\n",
    "                    )\n",
    "\n",
    "                XENT, ENT, DIV, SHELL = \\\n",
    "                    tf.reduce_mean(XENT), \\\n",
    "                        tf.reduce_mean(ENT), \\\n",
    "                        tf.reduce_mean(DIV), \\\n",
    "                        tf.reduce_mean(SHELL)\n",
    "\n",
    "                gain = params[\"cls_xent_coeff\"] * XENT + \\\n",
    "                       -params[\"cls_ent_coeff\"] * ENT + \\\n",
    "                       params[\"cls_div_coeff\"] * DIV + \\\n",
    "                       -params[\"cls_shell_coeff\"] * SHELL\n",
    "\n",
    "            gen_grad = tape.gradient(gain, generated)\n",
    "            if gen_grad is not None:\n",
    "                generated = (generated + 1 * gen_grad)\n",
    "\n",
    "        if final_latent is None:\n",
    "            final_latent = generated.numpy().copy()\n",
    "        else:\n",
    "            final_latent = np.concatenate([final_latent, generated.numpy().copy()])\n",
    "\n",
    "    tf.stop_gradient(final_latent)\n",
    "\n",
    "    mir_worked = not np.isnan(final_latent).any()\n",
    "    mem_x = final_latent if mir_worked else generate(agent, train=False)\n",
    "    mem_y = agent.classifier(mem_x).numpy()\n",
    "\n",
    "    return mem_x, mem_y, mir_worked"
   ],
   "metadata": {
    "id": "OlENSPig8kVl"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "'''Retrive maximally interferred latent vector for generator'''\n",
    "\n",
    "\n",
    "def retrieve_gen_for_gen(agent):\n",
    "\n",
    "    print(\"Retrieving latent vector for generator...\")\n",
    "\n",
    "    latent = agent.encoder(agent.state[\"data\"])\n",
    "    #mean_latent = tf.cast(tf.reduce_mean(latent, axis=0), tf.float64)\n",
    "    final_latent = None\n",
    "\n",
    "    for i in range(params[\"n_mem\"]):\n",
    "\n",
    "        generated = generate(agent, input_latent=latent, train=False)\n",
    "\n",
    "        for j in range(params[\"mir_iters\"]):\n",
    "\n",
    "            with tf.GradientTape(persistent=True) as tape:\n",
    "                tape.watch(generated)\n",
    "\n",
    "                # the predictions from the two models should be confident\n",
    "                ENT = tf.constant(0.)\n",
    "                if params[\"gen_ent_coeff\"]>0.:\n",
    "                    y_pre = agent.classifier(generated)\n",
    "                    y_pre_true = utils.get_one_hot_predictions(y_pre)\n",
    "                    ENT = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y_pre_true, y_pre))\n",
    "\n",
    "                # the new-found samples should be different from each others\n",
    "                DIV = tf.constant(0.)\n",
    "                if params[\"gen_div_coeff\"]>0.:\n",
    "                    for found_generated in range(i):\n",
    "                        DIV += tf.reduce_mean(tf.math.squared_difference(\n",
    "                            generated,\n",
    "                            final_latent[found_generated * generated.shape[0]:found_generated * generated.shape[0] + generated.shape[0]])\n",
    "                        ) / i\n",
    "\n",
    "                # (NEW) stay on gaussian shell loss:\n",
    "                SHELL = tf.constant(0.)\n",
    "                if params[\"gen_shell_coeff\"]>0.:\n",
    "                    SHELL = tf.reduce_mean(tf.math.squared_difference(\n",
    "                        tf.norm(generated, ord=2, axis=1),\n",
    "                        tf.ones_like(tf.norm(generated, ord=2, axis=1))*np.sqrt(params[\"z_size\"])))\n",
    "\n",
    "\n",
    "                gain =params[\"gen_div_coeff\"] * DIV + \\\n",
    "                      -params[\"gen_ent_coeff\"] * ENT + \\\n",
    "                       -params[\"gen_shell_coeff\"] * SHELL\n",
    "\n",
    "            grad = tape.gradient(gain, generated)\n",
    "            generated = (generated + grad)\n",
    "\n",
    "        if final_latent is None:\n",
    "            final_latent = tf.identity(generated)\n",
    "        else:\n",
    "            final_latent = tf.concat([final_latent, generated], axis=0)\n",
    "\n",
    "\n",
    "    tf.stop_gradient(final_latent)\n",
    "\n",
    "    mir_worked = not np.isnan(final_latent).any()\n",
    "    mem_x = final_latent if mir_worked else generate(agent, train=False)\n",
    "\n",
    "    return mem_x, mir_worked"
   ],
   "metadata": {
    "id": "5ho68Omg8kVl"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "lM8aEv6833SS"
   },
   "outputs": [],
   "source": [
    "'''Train the generator unit'''\n",
    "\n",
    "def train_generator(agent):\n",
    "\n",
    "    data = agent.state[\"data\"]\n",
    "    latent = agent.encoder(data)\n",
    "\n",
    "    mem_x = None\n",
    "    for it in range(agent.params[\"gen_iters\"]):\n",
    "        generate(agent, input_latent=latent)\n",
    "\n",
    "        if agent.state[\"task\"] > 0:\n",
    "            if it == 0 or not agent.params[\"reuse_samples\"]:\n",
    "                mem_x, mir_worked = retrieve_gen_for_gen(agent)\n",
    "\n",
    "                agent.state[\"mir_tries\"] += 1\n",
    "                if mir_worked:\n",
    "                    agent.state[\"mir_success\"] += 1\n",
    "\n",
    "        if mem_x is not None:\n",
    "          if len(mem_x.shape) == 3:\n",
    "            mem_x = tf.expand__dims(mem_x, axis=-1)\n",
    "          generate(agent, input_latent=mem_x, coeff=agent.params[\"mem_coeff\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "AXTbt9sT8gHE"
   },
   "outputs": [],
   "source": [
    "'''Train the encoder and the classifier unit'''\n",
    "\n",
    "def train_classifier(agent):\n",
    "\n",
    "    data = agent.state[\"data\"]\n",
    "    target = agent.state[\"target\"]\n",
    "    mem_x, mem_y = None, None\n",
    "\n",
    "    for it in range(agent.params[\"cls_iters\"]):\n",
    "        history = agent.encoder_classifier.fit(data, target, batch_size=agent.params[\"batch_size\"], epochs=1, verbose=0)\n",
    "        if agent.state[\"task\"] > 0:\n",
    "            if it == 0 or not agent.params[\"reuse_samples\"]:\n",
    "                mem_x, mem_y, mir_worked = retrieve_gen_for_cls(agent)\n",
    "                agent.state[\"mir_tries\"] += 1\n",
    "                if mir_worked:\n",
    "                    agent.state[\"mir_success\"] += 1\n",
    "\n",
    "            if mem_x is not None:\n",
    "                mem_history = agent.classifier.fit(mem_x, utils.get_one_hot_predictions(mem_y), batch_size=agent.params[\"batch_size\"], epochs=1, verbose=1)\n",
    "\n",
    "                agent.state[\"epoch_eval\"][\"retr_cls_loss\"].append(mem_history.history[\"loss\"][0])\n",
    "                agent.state[\"epoch_eval\"][\"retr_cls_accuracy\"].append(mem_history.history[\"accuracy\"][0])\n",
    "        agent.state[\"epoch_eval\"][\"cls_loss\"].append(history.history[\"loss\"][0])\n",
    "        agent.state[\"epoch_eval\"][\"cls_acc\"].append(history.history[\"accuracy\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "0A88lN-h9hdV"
   },
   "outputs": [],
   "source": [
    "'''Train model'''\n",
    "\n",
    "def train_model(train_function, agent):\n",
    "    agent.state[\"sample_amt\"] = 0\n",
    "    loader = agent.state[\"tr_loader\"]\n",
    "    for i, (data, target) in enumerate(loader):\n",
    "        #if agent.state[\"sample_amt\"] > agent.params[\"samples_per_task\"] > 0: break\n",
    "        agent.state[\"sample_amt\"] += data.shape[0]\n",
    "        agent.state[\"data\"] = data\n",
    "        agent.state[\"target\"] = target\n",
    "        agent.state[\"i_example\"] = i\n",
    "        train_function(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "'''Run an epoch'''\n",
    "\n",
    "def run_cls_epoch(agent):\n",
    "\n",
    "    print(f\"Running Task {agent.state['task']}, Epoch: {agent.state['epoch']} on Classifier\")\n",
    "\n",
    "    agent.state[\"epoch_eval\"][\"cls_loss\"] = []\n",
    "    agent.state[\"epoch_eval\"][\"cls_acc\"] = []\n",
    "    agent.state[\"epoch_eval\"][\"retr_cls_loss\"] = []\n",
    "    agent.state[\"epoch_eval\"][\"retr_cls_accuracy\"] = []\n",
    "\n",
    "    train_model(train_classifier, agent)\n",
    "\n",
    "    '''Evaluate the models in epoch'''\n",
    "    if agent.state[\"epoch\"] % agent.params[\"print_every\"] == 0:\n",
    "        print(f\"    Classifier loss: {np.mean(agent.state['epoch_eval']['cls_loss'])}\"\n",
    "              f\"    Classifier accuracy: {np.mean(agent.state['epoch_eval']['cls_acc'])}\")"
   ],
   "metadata": {
    "id": "xmJWM9GCzym_"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "'''Run an epoch'''\n",
    "\n",
    "def run_gen_epoch(agent):\n",
    "  \n",
    "    print(f\"Running Task {agent.state['task']}, Epoch: {agent.state['epoch']} on Generator\")\n",
    "    \n",
    "    agent.state[\"epoch_eval\"][\"gen_loss\"] = []\n",
    "    agent.state[\"epoch_eval\"][\"retr_gen_loss\"] = []\n",
    "    agent.state[\"epoch_eval\"][\"retr_gen_accuracy\"] = []\n",
    "\n",
    "    train_model(train_generator, agent)\n",
    "\n",
    "    '''Evaluate the models in epoch'''\n",
    "    if agent.state[\"epoch\"] % agent.params[\"print_every\"] == 0:\n",
    "        print(f\"    Generator loss: {np.mean(agent.state['epoch_eval']['gen_loss'])}\")\n",
    "              #f\"    Loss on gen retrieve for cls: {np.mean(agent.state['epoch_eval']['retr_cls_loss'])}\"\n",
    "              #f\"    Loss on gen retrieve for gen: {np.mean(agent.state['epoch_eval']['retr_gen_loss'])}\")"
   ],
   "metadata": {
    "id": "K48EQq7VGuI-"
   },
   "execution_count": 54,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "0SyPNSep_K0t"
   },
   "outputs": [],
   "source": [
    "'''Run a task'''\n",
    "\n",
    "def run_task(agent):\n",
    "\n",
    "    agent.state[\"mir_tries\"], agent.state[\"mir_success\"] = 0, 0\n",
    "    agent.state[\"epoch_eval\"] = dict()\n",
    "\n",
    "    for epoch in range(agent.params[\"cls_epochs\"]):\n",
    "        agent.state[\"epoch\"] = epoch\n",
    "        run_cls_epoch(agent)\n",
    "\n",
    "    for epoch in range(agent.params[\"gen_epochs\"]):\n",
    "        agent.state[\"epoch\"] = epoch\n",
    "        run_gen_epoch(agent)\n",
    "\n",
    "    '''Evaluate forgetting'''\n",
    "    if (agent.state['task']) > 0:\n",
    "      print(\"Evaluate Task: \", agent.state[\"task\"])\n",
    "    for i in range(agent.state[\"task\"]):\n",
    "        task_loss = []\n",
    "        task_eval = []\n",
    "        for data, target in test_loader[i]:\n",
    "            logits = agent.encoder_classifier(data)\n",
    "            pred = np.argmax(logits, axis=1)\n",
    "            y = np.argmax(target, axis=1)\n",
    "            eval = agent.eval(y, pred)\n",
    "            task_eval.append(eval)\n",
    "            loss = tf.keras.losses.categorical_crossentropy(target, logits)\n",
    "            task_loss.append(np.mean(loss))\n",
    "        print(f\"    Task {agent.state['task']} forgetting on task {i} : \"\n",
    "              f\"        Loss: {np.mean(task_loss)}\"\n",
    "              f\"        ACC: {np.mean(task_eval)}\")\n",
    "\n",
    "    #print(\"MIR success rate: \", agent.state[\"mir_success\"] / agent.state[\"mir_tries\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "VhbA5MCFCi4r"
   },
   "outputs": [],
   "source": [
    "'''Run the experiment'''\n",
    "\n",
    "def run(agent):\n",
    "\n",
    "  agent.set_models(\n",
    "      _classifier=Classifier(),\n",
    "      _generator=Generator(img_height=32, img_width=32),\n",
    "      _encoder=Encoder(),\n",
    "  )\n",
    "\n",
    "  for task, (tr_loader, ts_loader) in enumerate(zip(train_loader, test_loader)):\n",
    "    agent.state[\"task\"] = task\n",
    "    agent.state[\"tr_loader\"] = tr_loader\n",
    "    agent.state[\"ts_loader\"] = ts_loader\n",
    "    run_task(agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training"
   ],
   "metadata": {
    "collapsed": false,
    "id": "AoBLwork8kVn"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BlPHqKTaC41u",
    "outputId": "f8aad095-4b7b-4b89-b453-f155803bb049",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Generator init\n",
      "Running Task 0, Epoch: 0 on Classifier\n",
      "    Classifier loss: 1.1025629296141155    Classifier accuracy: 0.6429527209976972\n",
      "Running Task 0, Epoch: 1 on Classifier\n",
      "    Classifier loss: 0.529264626361556    Classifier accuracy: 0.7715767167382321\n",
      "Running Task 0, Epoch: 2 on Classifier\n",
      "    Classifier loss: 0.46851174811185414    Classifier accuracy: 0.7981712757530859\n",
      "Running Task 0, Epoch: 3 on Classifier\n",
      "    Classifier loss: 0.42587326492293404    Classifier accuracy: 0.8232395739878638\n",
      "Running Task 0, Epoch: 4 on Classifier\n",
      "    Classifier loss: 0.3907396576162112    Classifier accuracy: 0.8342335244356576\n",
      "Running Task 0, Epoch: 0 on Generator\n"
     ]
    }
   ],
   "source": [
    "agent = Agent(params)\n",
    "for r in range(agent.params[\"n_runs\"]):\n",
    "  agent.state[\"run\"] = r\n",
    "  run(agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Eval"
   ],
   "metadata": {
    "collapsed": false,
    "id": "Qqe-XGuwzynA"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "''' Evaluation'''\n",
    "for task, loader in enumerate(test_loader):\n",
    "    print(\"Task: \", task)\n",
    "    LOSS = []\n",
    "    ACC = []\n",
    "    for data, target in loader:\n",
    "      logits = agent.classifier_model(data)\n",
    "      pred = np.argmax(logits, axis=1)\n",
    "      report = agent.eval(np.argmax(target, axis=1), pred)\n",
    "      loss = tf.keras.losses.categorical_crossentropy(target, logits)\n",
    "      #print(report)\n",
    "      ACC.append(report)\n",
    "      LOSS.append(loss)\n",
    "    print(\"Mean loss: \", np.mean(LOSS))\n",
    "    print(\"Mean accuracy: \", np.mean(ACC))\n",
    "    print(\"\\n\")"
   ],
   "metadata": {
    "id": "-BguEZvfzynA"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluation, testing"
   ],
   "metadata": {
    "collapsed": false,
    "id": "UiiKIl618kVn"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def evaluate(loader, first_n_tasks=None):\n",
    "    for task, tr_loader in enumerate(loader):\n",
    "        print(\"Task: \", task)\n",
    "        data, target = tr_loader.batch(124)\n",
    "        logits = agent.classifier_model(data)\n",
    "        pred = np.argmax(logits, axis=1)\n",
    "        report = agent.eval(np.argmax(target, axis=1), pred)\n",
    "        loss = tf.keras.losses.categorical_crossentropy(target, logits)\n",
    "        print(report)\n",
    "        print(\"Mean loss: \", np.mean(loss))"
   ],
   "metadata": {
    "id": "r_K9lbNh8kVn"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4I2ZLTm-JnX8"
   },
   "outputs": [],
   "source": [
    "print(\"Evaluation on training set:\")\n",
    "evaluate(train_loader)\n",
    "print(\"Evaluation on test set:\")\n",
    "evaluate(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Utils for development"
   ],
   "metadata": {
    "collapsed": false,
    "id": "vOxdRLeJ8kVn"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "data": {
      "text/plain": "<module 'stable_diffusion.stable_diffusion' from '/Users/laszlofreund/PycharmProjects/continual-learning-ait/stable_diffusion/stable_diffusion.py'>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reload modules\n",
    "importlib.reload()"
   ],
   "metadata": {
    "id": "LNWS0pbd8kVn",
    "outputId": "b2184f26-86ef-40da-d970-7bd8b2d283ff"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "data": {
      "text/plain": "21547"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Garbage collection\n",
    "gc.collect()"
   ],
   "metadata": {
    "id": "NCdIwGMq8kVn",
    "outputId": "2495022b-fa19-489f-ae37-79b95d3ae24a"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Generator"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'ndarray'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[20], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorchvision\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda/lib/python3.10/site-packages/torchvision/__init__.py:6\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmodulefinder\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Module\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[0;32m----> 6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorchvision\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m datasets, io, models, ops, transforms, utils\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mextension\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _HAS_OPS\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[0;32m~/miniconda/lib/python3.10/site-packages/torchvision/datasets/__init__.py:1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_optical_flow\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m FlyingChairs, FlyingThings3D, HD1K, KittiFlow, Sintel\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_stereo_matching\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m      3\u001B[0m     CarlaStereo,\n\u001B[1;32m      4\u001B[0m     CREStereo,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     12\u001B[0m     SintelStereo,\n\u001B[1;32m     13\u001B[0m )\n\u001B[1;32m     14\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcaltech\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Caltech101, Caltech256\n",
      "File \u001B[0;32m~/miniconda/lib/python3.10/site-packages/torchvision/datasets/_optical_flow.py:13\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mPIL\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Image\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mio\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mimage\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _read_png_16\n\u001B[0;32m---> 13\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _read_pfm, verify_str_arg\n\u001B[1;32m     14\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mvision\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m VisionDataset\n\u001B[1;32m     17\u001B[0m T1 \u001B[38;5;241m=\u001B[39m Tuple[Image\u001B[38;5;241m.\u001B[39mImage, Image\u001B[38;5;241m.\u001B[39mImage, Optional[np\u001B[38;5;241m.\u001B[39mndarray], Optional[np\u001B[38;5;241m.\u001B[39mndarray]]\n",
      "File \u001B[0;32m~/miniconda/lib/python3.10/site-packages/torchvision/datasets/utils.py:476\u001B[0m\n\u001B[1;32m    471\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(msg)\n\u001B[1;32m    473\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m value\n\u001B[0;32m--> 476\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_read_pfm\u001B[39m(file_name: \u001B[38;5;28mstr\u001B[39m, slice_channels: \u001B[38;5;28mint\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m2\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mndarray\u001B[49m:\n\u001B[1;32m    477\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Read file in .pfm format. Might contain either 1 or 3 channels of data.\u001B[39;00m\n\u001B[1;32m    478\u001B[0m \n\u001B[1;32m    479\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    482\u001B[0m \u001B[38;5;124;03m            Useful for reading different data formats stored in .pfm files: Optical Flows, Stereo Disparity Maps, etc.\u001B[39;00m\n\u001B[1;32m    483\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m    485\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(file_name, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrb\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m f:\n",
      "\u001B[0;31mAttributeError\u001B[0m: module 'numpy' has no attribute 'ndarray'"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torchvision' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[21], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m trainset \u001B[38;5;241m=\u001B[39m \u001B[43mtorchvision\u001B[49m\u001B[38;5;241m.\u001B[39mdatasets\u001B[38;5;241m.\u001B[39mCIFAR10(root\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m./data\u001B[39m\u001B[38;5;124m'\u001B[39m, train\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, download\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m      2\u001B[0m trainloader \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mDataLoader(trainset, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m32\u001B[39m, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'torchvision' is not defined"
     ]
    }
   ],
   "source": [
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m (X_train, y_train), (X_test, y_test) \u001B[38;5;241m=\u001B[39m \u001B[43mload_cifar_10\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[5], line 2\u001B[0m, in \u001B[0;36mload_cifar_10\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mload_cifar_10\u001B[39m():\n\u001B[0;32m----> 2\u001B[0m     (X_train, y_train), (X_test, y_test) \u001B[38;5;241m=\u001B[39m \u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkeras\u001B[49m\u001B[38;5;241m.\u001B[39mdatasets\u001B[38;5;241m.\u001B[39mcifar10\u001B[38;5;241m.\u001B[39mload_data()\n\u001B[1;32m      3\u001B[0m     n_classes \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m10\u001B[39m\n\u001B[1;32m      4\u001B[0m     X_train \u001B[38;5;241m=\u001B[39m (X_train \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m127.5\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m\n",
      "\u001B[0;31mAttributeError\u001B[0m: module 'tensorflow' has no attribute 'keras'"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = load_cifar_10()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!wget -U https://nvlabs-fi-cdn.nvidia.com/edm/pretrained/edm-cifar10-32x32-cond-vp.pkl -P /Users/laszlofreund/PycharmProjects/continual-learning-ait/checkpoints/\n",
    "!wget -U"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import classifier_lib\n",
    "import pickle\n",
    "from train import train_generator"
   ],
   "metadata": {
    "id": "YvU86CThdnOY"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "encoder =       classifier_lib.load_encoder('/checkpoints/32x32_classifier.pt', 32, \"cpu\", eval=False)\n",
    "discriminator = classifier_lib.load_discriminator(None, \"cpu\", eval=False)\n",
    "\n",
    "# Load pretrained score network.\n",
    "#with open('/Users/laszlofreund/PycharmProjects/continual-learning-ait#/checkpoints/edm-cifar10-32x32-cond-vp.pkl', 'rb') as f:\n",
    "  #  scorenet = pickle.load(f)['ema'].to(\"cpu\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "zero-dimensional arrays cannot be concatenated",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mtrain_generator\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/continual-learning-ait/train.py:32\u001B[0m, in \u001B[0;36mtrain_generator\u001B[0;34m(X_real, y_real, X_gen, y_gen, encoder, discriminator, epochs, batch_size, learning_rate, device)\u001B[0m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtrain_generator\u001B[39m(\n\u001B[1;32m     24\u001B[0m         X_real, y_real,\n\u001B[1;32m     25\u001B[0m         X_gen, y_gen,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     30\u001B[0m ):\n\u001B[1;32m     31\u001B[0m     \u001B[38;5;66;03m# Combine the fake / real\u001B[39;00m\n\u001B[0;32m---> 32\u001B[0m     train_data \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconcatenate\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_real\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_gen\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     33\u001B[0m     train_label \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mzeros(train_data\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m])\n\u001B[1;32m     34\u001B[0m     train_label[:X_real\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]] \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1.\u001B[39m\n",
      "File \u001B[0;32m<__array_function__ internals>:5\u001B[0m, in \u001B[0;36mconcatenate\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: zero-dimensional arrays cannot be concatenated"
     ]
    }
   ],
   "source": [
    "train_generator(None, None, None, None, None, None)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "include_colab_link": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "accelerator": "GPU",
  "gpuClass": "standard"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
