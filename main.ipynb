{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/lacykaltgr/continual-learning-ait/blob/experiment/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pveLpmUzEF5A",
    "outputId": "74fb5a9f-bd1e-4778-92c3-1ebb03693fb2"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--2023-05-15 15:46:05--  https://github.com/lacykaltgr/continual-learning-ait/archive/refs/heads/experiment.zip\n",
      "Resolving github.com (github.com)... 192.30.255.113\n",
      "Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://codeload.github.com/lacykaltgr/continual-learning-ait/zip/refs/heads/experiment [following]\n",
      "--2023-05-15 15:46:05--  https://codeload.github.com/lacykaltgr/continual-learning-ait/zip/refs/heads/experiment\n",
      "Resolving codeload.github.com (codeload.github.com)... 192.30.255.120\n",
      "Connecting to codeload.github.com (codeload.github.com)|192.30.255.120|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [application/zip]\n",
      "Saving to: ‘experiment.zip’\n",
      "\n",
      "experiment.zip          [ <=>                ]   1.62M  --.-KB/s    in 0.1s    \n",
      "\n",
      "2023-05-15 15:46:05 (16.7 MB/s) - ‘experiment.zip’ saved [1703633]\n",
      "\n",
      "Archive:  experiment.zip\n",
      "33be9feb84db205993049252d9cce46db0ed1dbd\n",
      "   creating: continual-learning-ait-experiment/\n",
      "  inflating: continual-learning-ait-experiment/README.md  \n",
      "  inflating: continual-learning-ait-experiment/classifier.py  \n",
      "  inflating: continual-learning-ait-experiment/data_preparation.py  \n",
      "   creating: continual-learning-ait-experiment/dnnlib/\n",
      "  inflating: continual-learning-ait-experiment/dnnlib/__init__.py  \n",
      "  inflating: continual-learning-ait-experiment/dnnlib/util.py  \n",
      "  inflating: continual-learning-ait-experiment/generator.py  \n",
      "   creating: continual-learning-ait-experiment/guided_diffusion/\n",
      "  inflating: continual-learning-ait-experiment/guided_diffusion/__init__.py  \n",
      "  inflating: continual-learning-ait-experiment/guided_diffusion/dist_util.py  \n",
      "  inflating: continual-learning-ait-experiment/guided_diffusion/fp16_util.py  \n",
      "  inflating: continual-learning-ait-experiment/guided_diffusion/gaussian_diffusion.py  \n",
      "  inflating: continual-learning-ait-experiment/guided_diffusion/logger.py  \n",
      "  inflating: continual-learning-ait-experiment/guided_diffusion/losses.py  \n",
      "  inflating: continual-learning-ait-experiment/guided_diffusion/nn.py  \n",
      "  inflating: continual-learning-ait-experiment/guided_diffusion/resample.py  \n",
      "  inflating: continual-learning-ait-experiment/guided_diffusion/respace.py  \n",
      "  inflating: continual-learning-ait-experiment/guided_diffusion/script_util.py  \n",
      "  inflating: continual-learning-ait-experiment/guided_diffusion/train_util.py  \n",
      "  inflating: continual-learning-ait-experiment/guided_diffusion/unet.py  \n",
      "  inflating: continual-learning-ait-experiment/img.png  \n",
      "  inflating: continual-learning-ait-experiment/main.ipynb  \n",
      "   creating: continual-learning-ait-experiment/models/\n",
      "  inflating: continual-learning-ait-experiment/models/classifier.h5  \n",
      "  inflating: continual-learning-ait-experiment/models/encoder.h5  \n",
      "   creating: continual-learning-ait-experiment/notebooks/\n",
      "  inflating: continual-learning-ait-experiment/notebooks/classifier.ipynb  \n",
      "  inflating: continual-learning-ait-experiment/notebooks/data_preparation.ipynb  \n",
      "  inflating: continual-learning-ait-experiment/notebooks/generator.ipynb  \n",
      "   creating: continual-learning-ait-experiment/torch_utils/\n",
      "  inflating: continual-learning-ait-experiment/torch_utils/__init__.py  \n",
      "  inflating: continual-learning-ait-experiment/torch_utils/distributed.py  \n",
      "  inflating: continual-learning-ait-experiment/torch_utils/misc.py  \n",
      "  inflating: continual-learning-ait-experiment/torch_utils/persistence.py  \n",
      "  inflating: continual-learning-ait-experiment/torch_utils/training_stats.py  \n",
      "  inflating: continual-learning-ait-experiment/utils.py  \n"
     ]
    }
   ],
   "source": [
    "'''Download the files '''\n",
    "'''Only for colab'''\n",
    "useColab = True\n",
    "useDrive = True\n",
    "\n",
    "if useColab:\n",
    "    !wget https://github.com/lacykaltgr/continual-learning-ait/archive/refs/heads/experiment.zip\n",
    "    !unzip experiment.zip\n",
    "    #!find continual-learning-ait-experiment -type f ! -name \"main.ipynb\" -exec cp {} . \\;\n",
    "    !cd continual-learning-ait-experiment\n",
    "\n",
    "    import sys\n",
    "    sys.path.append('/content/continual-learning-ait-experiment')\n",
    "\n",
    "    if useDrive:\n",
    "        from google.colab import drive\n",
    "        drive.mount('/content/drive')\n",
    "        encoder_f = '/drive/MyDrive/continual-learning-ait/checkpoints/32x32_classifier.pt'\n",
    "        scorenet_f = 'drive/MyDrive/continual-learning-ait/checkpoints/edm-cifar10-32x32-cond-vp.pkl'\n",
    "    else:\n",
    "        !wget https://nvlabs-fi-cdn.nvidia.com/edm/pretrained/edm-cifar10-32x32-cond-vp.pkl\n",
    "\n",
    "       !wget https://nvlabs-fi-cdn.nvidia.com/edm/pretrained/32x32_classifier.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "vjfVuEmXECoL"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "#from keras.metrics import Accuracy\n",
    "\n",
    "#import classifier\n",
    "import generator\n",
    "from classifier import Classifier\n",
    "import utils\n",
    "from data_preparation import load_dataset, CLDataLoader, RealFakeConditionalDataset\n",
    "\n",
    "import gc\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load the dataset"
   ],
   "metadata": {
    "collapsed": false,
    "id": "zzYWiWfZ8kVi"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "TaH3bi-5crqD",
    "outputId": "ed4c5b73-afe7-42e7-ba0b-d1b34d0ffd16",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170498071/170498071 [==============================] - 4s 0us/step\n"
     ]
    }
   ],
   "source": [
    "dpt_train, dpt_test = load_dataset('cifar-10', n_classes_first_task=4, n_classes_other_task=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "yIESUurDeOCR"
   },
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train_loader = CLDataLoader(dpt_train, batch_size , train=True)\n",
    "test_loader = CLDataLoader(dpt_test, batch_size, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Define parameters and agent"
   ],
   "metadata": {
    "collapsed": false,
    "id": "3Jl-cBYs8kVj"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "GY9MAk581iYQ"
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    #general\n",
    "    \"n_runs\": 1,\n",
    "    \"n_tasks\": 3,\n",
    "    \"n_classes\": 10,\n",
    "    \"input_shape\": (32, 32, 3),\n",
    "    \"embedding_shape\": (6, 6, 8),\n",
    "    \"samples_per_task\": 10000,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"eval_batch_size\": 1,\n",
    "    \"print_every\": 1,\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \"img_resolution\": 32,\n",
    "\n",
    "    #classifier\n",
    "    \"cls_iters\": 1,\n",
    "    \"cls_lr\": 1e-2,\n",
    "    \"cls_epochs\": 5,\n",
    "\n",
    "    #generator\n",
    "    \"gen_epochs\": 2,\n",
    "    \"gen_lr\": 3e-4,\n",
    "\n",
    "    #mir\n",
    "    \"n_mem\": 2,\n",
    "    \"mir_iters\": 3,\n",
    "    \"reuse_samples\": True,\n",
    "    \"mem_coeff\": 0.12,\n",
    "    \"z_size\": 10,\n",
    "    \n",
    "    \"gen_ent_coeff\": 0.5,\n",
    "    \"gen_div_coeff\": 0.5,\n",
    "    \"gen_shell_coeff\": 0.5,\n",
    "    \"cls_xent_coeff\": 0.5,\n",
    "    \"cls_ent_coeff\": 0.5,\n",
    "    \"cls_div_coeff\": 0.5,\n",
    "    \"cls_shell_coeff\": 0.5,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "OmitFSMM2WJn"
   },
   "outputs": [],
   "source": [
    "'''Agent to handle models, parameters and states'''\n",
    "\n",
    "class Agent:\n",
    "  def __init__(self, hparams):\n",
    "    self.params = hparams\n",
    "    self.state = dict()\n",
    "\n",
    "    self.classifier = None\n",
    "    self.generator = None\n",
    "\n",
    "    self.optimizer = None\n",
    "    self.optimizer_gen = None\n",
    "\n",
    "    self.loss = None\n",
    "    self.loss_gen = None\n",
    "\n",
    "    self.eval = accuracy_score\n",
    "\n",
    "\n",
    "  def set_models(\n",
    "          self,\n",
    "          _generator=None,\n",
    "          _classifier=None,\n",
    "    ):\n",
    "    cls = _classifier #classifier\n",
    "    gen = _generator  #generator\n",
    "\n",
    "    # optimizers\n",
    "    self.optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=params[\"cls_lr\"])\n",
    "    self.optimizer_gen = torch.optim.Adam(agent.generator.discriminator.parameters(), lr=agent.params[\"gen_lr\"], weight_decay=1e-7)\n",
    "\n",
    "    # losses\n",
    "    self.loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "    self.loss_gen = torch.nn.BCELoss()\n",
    "\n",
    "    # classifier pipeline\n",
    "    data_input = keras.Input(shape=self.params[\"input_shape\"], name=\"image\")\n",
    "    cls_output = cls(data_input)\n",
    "    self.classifier = keras.Model(inputs=data_input, outputs=cls_output)\n",
    "    self.classifier.compile(optimizer=self.optimizer, loss=self.loss, metrics=[\"accuracy\"])\n",
    "\n",
    "    # generator pipeline\n",
    "    self.generator = gen"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Functions for training"
   ],
   "metadata": {
    "collapsed": false,
    "id": "OPqiS9VV8kVk"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "'''Generate samples and train the diffusion model at the same time'''\n",
    "\n",
    "def generate(\n",
    "        agent,\n",
    "        num_samples,\n",
    "        dg_weight_1st_order=1,\n",
    "        dg_weight_2nd_order=0,\n",
    "        boosting = 1,\n",
    "        time_min= 0.01, time_max= 1,\n",
    "        class_idx=None,\n",
    "):\n",
    "    # Pick latents and labels.\n",
    "    latents = torch.randn([num_samples, agent.generator.net.img_channels, agent.params[\"img_resolution\"], agent.params[\"img_resolution\"]], device=agent.params['device'])\n",
    "\n",
    "    class_labels = torch.eye(agent.params['n_classes'], device=agent.params['device'])[torch.randint(len(agent.state['classes_learned'])+1, size=[num_samples], device=agent.params['device'])]\n",
    "    if class_idx is not None:\n",
    "        class_labels[:, :] = 0\n",
    "        class_labels[:, class_idx] = 1\n",
    "\n",
    "    # Generate images.\n",
    "    images = agent.generator.sample(boosting, time_min, time_max, dg_weight_1st_order, dg_weight_2nd_order, latents, class_labels)\n",
    "    images = torch.transpose(images, 1, 3)\n",
    "    images = torch.transpose(images, 1, 2)\n",
    "    images, class_labels = images.cpu(), class_labels.cpu()\n",
    "    images, class_labels = images.numpy(), class_labels.numpy()\n",
    "    return images, class_labels\n"
   ],
   "metadata": {
    "id": "2BgWNzhg8kVk"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "'''Retrive maximally interferred latent vector for classifier'''\n",
    "\n",
    "def retrieve_mir(agent, samples, target):\n",
    "\n",
    "\n",
    "    virtual_cls = Classifier()\n",
    "    virtual_cls = utils.get_next_step_cls(\n",
    "        agent.cls,\n",
    "        virtual_cls,\n",
    "        samples,\n",
    "        target\n",
    "    )\n",
    "\n",
    "    final_generated = None\n",
    "    final_labels = None\n",
    "    for i in range(agent.params[\"n_mem\"]):\n",
    "\n",
    "        generated, labels = generate(agent, agent.params[\"batch_size\"])\n",
    "\n",
    "        for j in range(params[\"mir_iters\"]):\n",
    "            with tf.GradientTape(persistent=True) as tape:\n",
    "\n",
    "                tape.watch(generated)\n",
    "\n",
    "                y_pre = agent.classifier(generated)\n",
    "                y_virtual = virtual_cls(generated)\n",
    "\n",
    "                # maximise the interference:\n",
    "                XENT = tf.constant(0.)\n",
    "                if params[\"cls_xent_coeff\"] > 0.:\n",
    "                    XENT = tf.keras.losses.categorical_crossentropy(y_virtual, y_pre)\n",
    "\n",
    "                # the predictions from the two models should be confident\n",
    "                ENT = tf.constant(0.)\n",
    "                if params[\"cls_ent_coeff\"] > 0.:\n",
    "                    ENT = tf.keras.losses.categorical_crossentropy(y_pre, y_pre)\n",
    "\n",
    "                # the new-found samples should be different from each others\n",
    "                DIV = tf.constant(0.)\n",
    "                if params[\"cls_div_coeff\"] > 0.:\n",
    "                    for found_generated in range(i):\n",
    "                        DIV += tf.keras.losses.MSE(\n",
    "                            generated,\n",
    "                            final_generated[found_generated * generated.shape[0]:found_generated * generated.shape[0] + generated.shape[0]]\n",
    "                        ) / i\n",
    "\n",
    "                # (NEW) stay on gaussian shell loss:\n",
    "                SHELL = tf.constant(0.)\n",
    "                if params[\"cls_shell_coeff\"] > 0.:\n",
    "                    SHELL = tf.keras.losses.MSE(\n",
    "                        tf.norm(generated, axis=1),\n",
    "                        tf.ones_like(tf.norm(generated, axis=1))*np.sqrt(params[\"z_size\"])\n",
    "                    )\n",
    "\n",
    "                XENT, ENT, DIV, SHELL = \\\n",
    "                    tf.reduce_mean(XENT), \\\n",
    "                        tf.reduce_mean(ENT), \\\n",
    "                        tf.reduce_mean(DIV), \\\n",
    "                        tf.reduce_mean(SHELL)\n",
    "\n",
    "                gain = params[\"cls_xent_coeff\"] * XENT + \\\n",
    "                       -params[\"cls_ent_coeff\"] * ENT + \\\n",
    "                       params[\"cls_div_coeff\"] * DIV + \\\n",
    "                       -params[\"cls_shell_coeff\"] * SHELL\n",
    "\n",
    "            gen_grad = tape.gradient(gain, generated)\n",
    "            if gen_grad is not None:\n",
    "                generated = (generated + 1 * gen_grad)\n",
    "\n",
    "        if final_generated is None:\n",
    "            final_generated = generated.numpy().copy()\n",
    "            final_labels = labels.numpy().copy()\n",
    "        else:\n",
    "            final_generated = np.concatenate([final_generated, generated.numpy().copy()])\n",
    "            final_labels = np.concatenate([final_labels, labels.numpy().copy()])\n",
    "\n",
    "    tf.stop_gradient(final_generated)\n",
    "\n",
    "    return final_generated, final_labels"
   ],
   "metadata": {
    "id": "OlENSPig8kVl"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "lM8aEv6833SS"
   },
   "outputs": [],
   "source": [
    "'''Train the generator unit'''\n",
    "\n",
    "def train_generator(agent, real_fake_loader):\n",
    "    scaler = lambda x: 2. * x - 1.\n",
    "\n",
    "    # Training\n",
    "    outs = []\n",
    "    cors = []\n",
    "    for data in real_fake_loader:\n",
    "        agent.optimizer_gen.zero_grad()\n",
    "\n",
    "        inputs, labels, cond = data\n",
    "        cond = cond.to(agent.params[\"device\"])\n",
    "        inputs = inputs.to(agent.params[\"device\"])\n",
    "        labels = labels.to(agent.params[\"device\"])\n",
    "        inputs = scaler(inputs)\n",
    "\n",
    "        # Data perturbation\n",
    "        t, _ = agent.generator.vpsde.get_diffusion_time(inputs.shape[0], inputs.device)\n",
    "        mean, std = agent.generator.vpsde.marginal_prob(t)\n",
    "        z = torch.randn_like(inputs)\n",
    "        perturbed_inputs = mean[:, None, None, None] * inputs + std[:, None, None, None] * z\n",
    "\n",
    "        # Forward\n",
    "        with torch.no_grad():\n",
    "            pretrained_feature = agent.generator.encoder(perturbed_inputs, timesteps=t, feature=True).type(torch.cuda.FloatTensor)\n",
    "        label_prediction = agent.generator.discriminator(pretrained_feature, t, sigmoid=True, condition=cond).view(-1)\n",
    "\n",
    "        # Backward\n",
    "        out = agent.loss_gen(label_prediction, labels)\n",
    "        out.backward()\n",
    "        agent.optimizer_gen.step()\n",
    "\n",
    "        # Report\n",
    "        cor = ((label_prediction > 0.5).float() == labels).float().mean()\n",
    "        agent.state[\"epoch_eval\"][\"correction_rate\"][-1].append(out.item())\n",
    "        agent.state[\"epoch_eval\"][\"discriminator_loss\"][-1].append(cor.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "AXTbt9sT8gHE"
   },
   "outputs": [],
   "source": [
    "'''Train the encoder and the classifier unit'''\n",
    "#lehet keverni kéne a mintákat\n",
    "\n",
    "def train_classifier(agent):\n",
    "\n",
    "    mem_x, mem_y = None, None\n",
    "\n",
    "    for it in range(agent.params[\"cls_iters\"]):\n",
    "        history = agent.classifier.fit(data, target, batch_size=agent.params[\"batch_size\"], epochs=1, verbose=0)\n",
    "        if agent.state[\"task\"] > 0:\n",
    "            if it == 0 or not agent.params[\"reuse_samples\"]:\n",
    "                mem_x, mem_y = retrieve_mir(agent, agent.state[\"data\"], agent.state[\"target\"])\n",
    "\n",
    "            if mem_x is not None:\n",
    "                mem_history = agent.classifier.fit(mem_x, mem_y, batch_size=agent.params[\"batch_size\"], epochs=1, verbose=1)\n",
    "\n",
    "                agent.state[\"epoch_eval\"][\"retr_cls_loss\"][-1].append(mem_history.history[\"loss\"][0])\n",
    "                agent.state[\"epoch_eval\"][\"retr_cls_accuracy\"][-1].append(mem_history.history[\"accuracy\"][0])\n",
    "        agent.state[\"epoch_eval\"][\"cls_loss\"][-1].append(history.history[\"loss\"][0])\n",
    "        agent.state[\"epoch_eval\"][\"cls_acc\"][-1].append(history.history[\"accuracy\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "'''Run an epoch'''\n",
    "\n",
    "def run_cls_epoch(agent):\n",
    "\n",
    "    print(f\"Running Task {agent.state['task']}, Epoch: {agent.state['epoch']} on Classifier\")\n",
    "\n",
    "    agent.state[\"eval\"][\"cls_loss\"].append([])\n",
    "    agent.state[\"eval\"][\"cls_acc\"].append([])\n",
    "    agent.state[\"eval\"][\"retr_cls_loss\"].append([])\n",
    "    agent.state[\"eval\"][\"retr_cls_accuracy\"].append([])\n",
    "\n",
    "    for i, (data, target) in enumerate(agent.state[\"tr_loader\"]):\n",
    "        agent.state[\"data\"] = data\n",
    "        agent.state[\"target\"] = target\n",
    "        train_classifier(agent)\n",
    "\n",
    "    '''Evaluate the models in epoch'''\n",
    "    if agent.state[\"epoch\"] % agent.params[\"print_every\"] == 0:\n",
    "        print(f\"    Classifier loss: {np.mean(agent.state['epoch_eval']['cls_loss'][-1])}\"\n",
    "              f\"    Classifier accuracy: {np.mean(agent.state['epoch_eval']['cls_acc'][-1])}\"\n",
    "              f\"    Retrieval loss: {np.mean(agent.state['epoch_eval']['retr_cls_loss'][-1])}\"\n",
    "              f\"    Retrieval accuracy: {np.mean(agent.state['epoch_eval']['retr_cls_accuracy'][-1])}\")"
   ],
   "metadata": {
    "id": "xmJWM9GCzym_"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "'''Run an epoch'''\n",
    "\n",
    "def run_gen_epoch(agent):\n",
    "  \n",
    "    print(f\"Running Task {agent.state['task']}, Epoch: {agent.state['epoch']} on Generator\")\n",
    "    \n",
    "    agent.state[\"eval\"][\"discrimination_loss\"].appen([])\n",
    "    agent.state[\"eval\"][\"correction_rate\"].append([])\n",
    "\n",
    "\n",
    "    fake_samples, fake_labels = generate(\n",
    "        agent, len(agent.state[\"tr_loader\"]) , dg_weight_1st_order=0 ,dg_weight_2nd_order=0, boosting=0 )\n",
    "    real_samples, real_labels = [], []\n",
    "    for sample, label in agent.state[\"tr_loader\"]:\n",
    "        real_samples.append(sample.numpy())\n",
    "        real_labels.append(label.numpy())\n",
    "    real_samples, real_labels = np.concatenate(real_samples, axis=0), np.concatenate(real_labels, axis=0)\n",
    "\n",
    "    train_data = np.concatenate((real_samples, fake_samples))\n",
    "    train_label = torch.zeros(train_data.shape[0])\n",
    "    train_label[:real_samples.shape[0]] = 1.\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    condition_label = np.concatenate((real_labels, fake_labels))\n",
    "    train_dataset = RealFakeConditionalDataset(train_data, train_label, condition_label, transform)\n",
    "\n",
    "    real_fake_loader  = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=agent.params[\"batch_size\"], shuffle=True)\n",
    "    train_generator(agent, real_fake_loader)\n",
    "    \n",
    "\n",
    "    '''Evaluate the models in epoch'''\n",
    "    if agent.state[\"epoch\"] % agent.params[\"print_every\"] == 0:\n",
    "        print(f\"    Discriminator loss: {np.mean(agent.state['epoch_eval']['discrimination_loss'][-1])}\"\n",
    "              f\"    Correction rate: {np.mean(agent.state['epoch_eval']['correction_rate'][-1])}\")"
   ],
   "metadata": {
    "id": "K48EQq7VGuI-"
   },
   "execution_count": 25,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "0SyPNSep_K0t"
   },
   "outputs": [],
   "source": [
    "'''Run a task'''\n",
    "\n",
    "def run_task(agent):\n",
    "\n",
    "    agent.state[\"mir_tries\"], agent.state[\"mir_success\"] = 0, 0\n",
    "    agent.state[\"epoch_eval\"] = dict()\n",
    "\n",
    "\n",
    "    for epoch in range(agent.params[\"cls_epochs\"]):\n",
    "        agent.state[\"epoch\"] = epoch\n",
    "        run_cls_epoch(agent)\n",
    "\n",
    "    for epoch in range(agent.params[\"gen_epochs\"]):\n",
    "        agent.state[\"epoch\"] = epoch\n",
    "        run_gen_epoch(agent)\n",
    "\n",
    "    '''Evaluate forgetting'''\n",
    "    if (agent.state['task']) > 0:\n",
    "      print(\"Evaluate Task: \", agent.state[\"task\"])\n",
    "    for i in range(agent.state[\"task\"]+1):\n",
    "        task_loss = []\n",
    "        task_accuracy = []\n",
    "        for data, target in test_loader[i]:\n",
    "            logits = agent.classifier(data)\n",
    "            #loss\n",
    "            loss = agent.loss(logits, target)\n",
    "            task_loss.append(np.mean(loss))\n",
    "            #accuracy\n",
    "            pred = np.argmax(logits, axis=1)\n",
    "            y = np.argmax(target, axis=1)\n",
    "            accuracy = agent.eval(y, pred)\n",
    "            task_accuracy.append(accuracy)\n",
    "        print(f\"    Task {agent.state['task']} forgetting on task {i} : \"\n",
    "              f\"        Loss: {np.mean(task_loss)}\"\n",
    "              f\"        ACC: {np.mean(task_accuracy)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "VhbA5MCFCi4r"
   },
   "outputs": [],
   "source": [
    "'''Run the experiment'''\n",
    "\n",
    "def run(agent):\n",
    "    agent.state[\"classes_learned\"] = []\n",
    "    agent.state[\"eval\"][\"cls_loss\"] = []\n",
    "    agent.state[\"eval\"][\"cls_acc\"] = []\n",
    "    agent.state[\"eval\"][\"retr_cls_loss\"] = []\n",
    "    agent.state[\"eval\"][\"retr_cls_accuracy\"] = []\n",
    "    agent.state[\"eval\"][\"discrimination_loss\"] = []\n",
    "    agent.state[\"eval\"][\"correction_rate\"] = []\n",
    "    for r in range(agent.params[\"n_runs\"]):\n",
    "        agent.state[\"run\"] = r\n",
    "        print(f\"Run {r}\")\n",
    "        for task, (tr_loader, ts_loader) in enumerate(zip(train_loader, test_loader)):\n",
    "            agent.state[\"task\"] = task\n",
    "            agent.state[\"tr_loader\"] = tr_loader\n",
    "            agent.state[\"ts_loader\"] = ts_loader\n",
    "            run_task(agent)\n",
    "            #agent.state[\"classes_learned\"].append(task)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training"
   ],
   "metadata": {
    "collapsed": false,
    "id": "AoBLwork8kVn"
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "id": "L8JvoFreHD1U"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlPHqKTaC41u"
   },
   "outputs": [],
   "source": [
    "encoder_f = '/drive/MyDrive/continual-learning-ait/checkpoints/32x32_classifier.pt'\n",
    "\n",
    "agent = Agent(params)\n",
    "agent.set_models(\n",
    "    _classifier=Classifier(),\n",
    "    _generator=generator.Generator(encoder_path=encoder_f),\n",
    ")\n",
    "#run(agent)"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import pickle\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "1UGcC6rS0f95"
   },
   "execution_count": 27,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "agent.generator.set_score_network(scorenet)"
   ],
   "metadata": {
    "id": "N69g2lSQ3vJq"
   },
   "execution_count": 28,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "run(agent)"
   ],
   "metadata": {
    "id": "jL7eBmbM33Nw",
    "outputId": "d5a183cd-b1d5-43d4-e011-180bd8d12f50",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "execution_count": 29,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Run 0\n",
      "Running Task 0, Epoch: 0 on Generator\n",
      "BCE loss: 0.06476288769094242, correction rate: 0.9845074152542372\n",
      "Running Task 0, Epoch: 1 on Generator\n",
      "BCE loss: 0.02415868822658845, correction rate: 0.9960655105316033\n",
      "Running Task 0, Epoch: 2 on Generator\n",
      "BCE loss: 0.02085156907856275, correction rate: 0.99609375\n",
      "Running Task 0, Epoch: 3 on Generator\n",
      "BCE loss: 0.020070268125352213, correction rate: 0.99609375\n",
      "Running Task 0, Epoch: 4 on Generator\n",
      "BCE loss: 0.01850671491041085, correction rate: 0.9960513902922808\n",
      "Running Task 1, Epoch: 0 on Generator\n",
      "BCE loss: 0.016691895297844893, correction rate: 0.99638671875\n",
      "Running Task 1, Epoch: 1 on Generator\n",
      "BCE loss: 0.012128880593809298, correction rate: 0.99775390625\n",
      "Running Task 1, Epoch: 2 on Generator\n",
      "BCE loss: 0.013780273688098532, correction rate: 0.997265625\n",
      "Running Task 1, Epoch: 3 on Generator\n",
      "BCE loss: 0.012609703063208143, correction rate: 0.99736328125\n",
      "Running Task 1, Epoch: 4 on Generator\n",
      "BCE loss: 0.013398111145943404, correction rate: 0.9974609375\n",
      "Running Task 2, Epoch: 0 on Generator\n",
      "BCE loss: 0.06517889690730953, correction rate: 0.9805106043815612\n",
      "Running Task 2, Epoch: 1 on Generator\n",
      "BCE loss: 0.022361435333732516, correction rate: 0.99599609375\n",
      "Running Task 2, Epoch: 2 on Generator\n",
      "BCE loss: 0.020170275194686837, correction rate: 0.9962890625\n",
      "Running Task 2, Epoch: 3 on Generator\n",
      "BCE loss: 0.019724001036956908, correction rate: 0.9960379481315613\n",
      "Running Task 2, Epoch: 4 on Generator\n",
      "BCE loss: 0.016802752860530745, correction rate: 0.9962890625\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "images = generate(agent, 1, 0.01, 1, 1, 0, 10, 4)"
   ],
   "metadata": {
    "id": "aT_2YcuyLYWN"
   },
   "execution_count": 63,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def disp(image):\n",
    "    image = (image + 1)* 127.5\n",
    "\n",
    "    plt.imshow(image.astype(np.uint8))\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ],
   "metadata": {
    "id": "M2GlqzEzMEod"
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "disp(images[0][1])"
   ],
   "metadata": {
    "id": "yNc1tDejMGoB",
    "outputId": "87c56ccf-d5eb-4b5e-a9c2-645da285e5e0",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    }
   },
   "execution_count": 67,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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\n"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluation, testing"
   ],
   "metadata": {
    "collapsed": false,
    "id": "UiiKIl618kVn"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def evaluate(loader, first_n_tasks=None):\n",
    "    for task, tr_loader in enumerate(loader):\n",
    "        print(\"Task: \", task)\n",
    "        data, target = tr_loader.batch(124)\n",
    "        logits = agent.classifier_model(data)\n",
    "        pred = np.argmax(logits, axis=1)\n",
    "        report = agent.eval(np.argmax(target, axis=1), pred)\n",
    "        loss = tf.keras.losses.categorical_crossentropy(target, logits)\n",
    "        print(report)\n",
    "        print(\"Mean loss: \", np.mean(loss))"
   ],
   "metadata": {
    "id": "r_K9lbNh8kVn"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4I2ZLTm-JnX8"
   },
   "outputs": [],
   "source": [
    "print(\"Evaluation on training set:\")\n",
    "evaluate(train_loader)\n",
    "print(\"Evaluation on test set:\")\n",
    "evaluate(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Utils for development"
   ],
   "metadata": {
    "collapsed": false,
    "id": "vOxdRLeJ8kVn"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<module 'generator' from '/content/continual-learning-ait-experiment/generator.py'>"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "# Reload modules\n",
    "importlib.reload(generator)"
   ],
   "metadata": {
    "id": "LNWS0pbd8kVn",
    "outputId": "b344f5ff-8d8d-463c-de8b-f96797fe29a7",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "59341"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "# Garbage collection\n",
    "gc.collect()"
   ],
   "metadata": {
    "id": "NCdIwGMq8kVn",
    "outputId": "cffd2280-970f-4435-da6b-cb20a1e40a34",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "farFiT8b5CbP"
   },
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "include_colab_link": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "accelerator": "GPU",
  "gpuClass": "standard"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
